{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(threshold=np.inf,linewidth=np.inf) # numpy array를 생략하지않고 전체 출력\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/leesangmin/Desktop/a/train.csv')\n",
    "test=pd.read_csv('/Users/leesangmin/Desktop/a/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info() # 데이터의 NAN 개수를 확인 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 Age의 nan값의 개수 : 177\n"
     ]
    }
   ],
   "source": [
    "print('train data의 Age의 nan값의 개수 : {}'.format(train_data.Age.isna().sum())) # train_data.nan 값의 개수를 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Age'>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='Pclass',y='Age',data=train_data) # Pclass에 따른 나이를 그래프로 확인, 나이의 nan값을 채워주기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-1. Age를 처리하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Age가 nan 값인 데이터를 채워주는 과정. 위의 Pclass와 Age와의 관계 그래프를 통해 집어넣어줌\n",
    "def nanAge(data): \n",
    "    \n",
    "    if np.isnan(data.Age):\n",
    "\n",
    "        if data.Pclass==1:\n",
    "            return 36\n",
    "        \n",
    "        elif data.Pclass==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 25\n",
    "\n",
    "    else:\n",
    "        return data.Age\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 Age의 nan값의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "train_data['Age']=train_data[['Age','Pclass']].apply(nanAge,axis=1) # Age의 nan값을 넣어줌\n",
    "\n",
    "print('train data의 Age의 nan값의 개수 : {}'.format(train_data.Age.isna().sum())) # train_data.Age의 nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info() # train_data의 Age에 nan값이 없음을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-2. train data Embarked를 처리  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train_data의 Embarked에도 두개의 nan값이 있음.데이터가 2개뿐이니 Embarked의 첫번째 값과 같다고 놓았음(S와 같아짐)\n",
    "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace = True) \n",
    "\n",
    "\n",
    "max(train_data['Age']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.854, 10.5]        184\n",
       "(21.679, 39.688]     180\n",
       "(-0.001, 7.854]      179\n",
       "(39.688, 512.329]    176\n",
       "(10.5, 21.679]       172\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fare을 5구간으로 나누기 위해 구간을 확\n",
    "pd.qcut(train_data['Fare'],5).value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-3. 사용할 변수들을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas의 각 열을 제거해서 data로 활용하여도 되지만, numpy array형태로 바꿔주었음. Survived or dead를 분석하기위해 Pclass, Sex, Age, Embarked, Fare, SibSp, Parch를 사용\n",
    "def predata(data):\n",
    "    sex=[]\n",
    "    embark=[]\n",
    "    age=[]\n",
    "    family=[]\n",
    "    fare=[]\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.Sex[i]=='male': # Sex는 문자열 데이터이므로, 정수형 숫자로 변경을해줌\n",
    "            a=1\n",
    "        else:\n",
    "            a=0\n",
    "\n",
    "        if data.Age[i]<=16: # 나이를 5등분을 함. train_data의 Age의 데이터의 최대값이 80이므로, 이를 5등분함\n",
    "            b=0\n",
    "        \n",
    "        elif data.Age[i]<=32: # 나이의 데이터는 0~80까지 넓은 분포를 가지기 때문에 구간을 나누어서 해야만 했음\n",
    "            b=1\n",
    "        \n",
    "        elif data.Age[i]<=48:\n",
    "            b=2\n",
    "        elif data.Age[i]<=64:\n",
    "            b=3\n",
    "        else:\n",
    "            b=4\n",
    "\n",
    "            \n",
    "        if data.Embarked[i]==\"C\": # Embarked는 총 3개의 문자열로 되어있음. 이를 정수형 숫자로 변경\n",
    "            c=0\n",
    "        elif data.Embarked[i]==\"Q\":\n",
    "            c=1\n",
    "        else:\n",
    "            c=2\n",
    "\n",
    "\n",
    "        if data.SibSp[i]+data.Parch[i]+1 ==1: # SibSp는 동반한 형제/자매/배우자를 의미. Parch는 동반한 부모/자식 수 이므로 둘을 합쳐 가족으로함. 혼자 온 사람과 안온사람의 구분을 지음\n",
    "            d=0\n",
    "        else:\n",
    "            d=1\n",
    "\n",
    "        if data.Fare[i]<=8: # Fare은 요금으로,5구간으로 나눠주었음\n",
    "            e=0\n",
    "        elif data.Fare[i]<=11:\n",
    "            e=1\n",
    "        elif data.Fare[i]<=21.2:\n",
    "            e=2\n",
    "        elif data.Fare[i]<=40:\n",
    "            e=3\n",
    "        else:\n",
    "            e=4\n",
    "\n",
    "        ## 빈 list에 값들을  채워넣음\n",
    "        sex.append(a)\n",
    "        age.append(b)\n",
    "        embark.append(c)\n",
    "        family.append(d)\n",
    "        fare.append(e)\n",
    "\n",
    "    ## 사용할 변수들을 추출하여 한 열의 array로 변경해주는 과정 \n",
    "    family=np.array(family).reshape(-1,1)\n",
    "    sex=np.array(sex).reshape(-1,1)\n",
    "    fare=np.array(fare).reshape(-1,1)\n",
    "    pclass=np.array(data.Pclass).reshape(-1,1) # Pclass는 변경하지않아도 정수형데이터로 총 3개 존재하기 때문에 if문을 사용하지 않음\n",
    "    age=np.array(age).reshape(-1,1)\n",
    "    embark=np.array(embark).reshape(-1,1)\n",
    "\n",
    "    ## 사용할 변수들을 모두 하나의 열로 추출하였으니 이를 하나의 array로 합치는 과정\n",
    "    X=np.concatenate((age,sex,family,pclass,embark,fare),axis=1) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 3 2 0]\n",
      " [2 0 1 1 0 4]\n",
      " [1 0 0 3 2 0]\n",
      " [2 0 1 1 2 4]\n",
      " [2 1 0 3 2 1]\n",
      " [1 1 0 3 1 1]\n",
      " [3 1 0 1 2 4]\n",
      " [0 1 1 3 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [0 0 1 2 0 3]\n",
      " [0 0 1 3 2 2]\n",
      " [3 0 0 1 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 1 3 2 3]\n",
      " [0 0 0 3 2 0]\n",
      " [3 0 0 2 2 2]\n",
      " [0 1 1 3 1 3]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [1 0 0 3 0 0]\n",
      " [2 1 0 2 2 3]\n",
      " [2 1 0 2 2 2]\n",
      " [0 0 0 3 1 1]\n",
      " [1 1 0 1 2 3]\n",
      " [0 0 1 3 2 2]\n",
      " [2 0 1 3 2 3]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 1 1 2 4]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 0 3]\n",
      " [2 0 1 1 0 4]\n",
      " [1 0 0 3 1 0]\n",
      " [4 1 0 2 2 1]\n",
      " [1 1 1 1 0 4]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 3 2 2]\n",
      " [0 0 1 3 0 2]\n",
      " [2 0 1 3 2 1]\n",
      " [1 0 1 2 2 2]\n",
      " [1 1 0 3 0 0]\n",
      " [0 0 1 2 0 4]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 1 2]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 3 0 3]\n",
      " [1 0 1 3 2 2]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [3 0 1 1 0 4]\n",
      " [1 0 1 2 2 3]\n",
      " [4 1 1 1 0 4]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 0 2 2 1]\n",
      " [1 1 0 3 0 0]\n",
      " [0 0 1 2 2 3]\n",
      " [0 1 1 3 2 4]\n",
      " [1 1 0 3 0 0]\n",
      " [2 0 0 1 2 4]\n",
      " [2 1 1 1 2 4]\n",
      " [0 1 1 3 2 3]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 1 3 0 2]\n",
      " [1 0 0 2 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 3 2 0]\n",
      " [1 1 1 3 2 1]\n",
      " [1 1 0 2 2 1]\n",
      " [0 0 1 3 2 4]\n",
      " [1 1 0 2 2 4]\n",
      " [1 1 1 3 0 2]\n",
      " [1 1 0 3 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 2 2 3]\n",
      " [1 0 0 3 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 0 1 2 4]\n",
      " [1 0 0 2 2 1]\n",
      " [2 0 1 3 2 2]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 1 3 2 2]\n",
      " [3 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [4 1 0 1 0 3]\n",
      " [1 1 1 1 0 4]\n",
      " [2 0 1 2 2 3]\n",
      " [2 1 1 2 2 3]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 1 2 4]\n",
      " [2 1 0 3 2 1]\n",
      " [2 1 1 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 1 3 1 3]\n",
      " [2 1 0 1 2 4]\n",
      " [0 0 1 3 0 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 3 2 1]\n",
      " [1 0 0 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [4 1 0 3 1 0]\n",
      " [1 1 1 2 2 2]\n",
      " [1 1 1 1 0 4]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 1 2 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 1 2 0 3]\n",
      " [2 0 0 2 2 2]\n",
      " [3 1 1 1 2 4]\n",
      " [0 1 1 3 0 2]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 0 3]\n",
      " [2 1 0 3 2 0]\n",
      " [2 1 0 3 0 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 3 2 2]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 2 0 2]\n",
      " [1 0 1 1 2 3]\n",
      " [2 1 1 1 2 4]\n",
      " [0 1 0 3 2 1]\n",
      " [1 1 0 1 0 4]\n",
      " [1 0 1 3 0 2]\n",
      " [1 0 0 3 2 0]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 3 2 3]\n",
      " [2 1 1 2 2 3]\n",
      " [2 1 0 2 2 2]\n",
      " [3 1 0 2 2 2]\n",
      " [1 0 1 1 2 4]\n",
      " [3 1 0 3 2 1]\n",
      " [2 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 1 1 0 4]\n",
      " [0 0 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 2 4]\n",
      " [2 1 1 3 2 2]\n",
      " [2 0 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 3 2 3]\n",
      " [0 1 1 3 2 2]\n",
      " [2 0 1 1 2 4]\n",
      " [2 0 1 3 2 3]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 0 3 2 4]\n",
      " [3 1 0 1 2 3]\n",
      " [0 1 1 3 1 3]\n",
      " [0 0 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 1 0 3]\n",
      " [1 1 1 3 2 0]\n",
      " [1 1 1 3 2 3]\n",
      " [3 0 0 1 0 3]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 1 3 2 4]\n",
      " [1 1 0 2 0 2]\n",
      " [0 1 1 3 2 3]\n",
      " [0 1 1 2 2 3]\n",
      " [0 0 1 3 2 3]\n",
      " [2 1 0 1 2 4]\n",
      " [1 0 1 3 1 2]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 1 3 1 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 1 3 2 0]\n",
      " [0 1 1 2 2 3]\n",
      " [2 0 0 1 0 3]\n",
      " [3 0 0 1 0 4]\n",
      " [1 1 0 3 1 0]\n",
      " [2 1 1 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 2 4]\n",
      " [2 1 0 3 2 0]\n",
      " [2 1 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [0 0 1 3 2 1]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 0 2]\n",
      " [0 0 0 3 1 0]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 1 3 1 0]\n",
      " [1 0 1 1 0 4]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 1 2 2 3]\n",
      " [1 0 0 1 0 4]\n",
      " [1 1 0 2 2 1]\n",
      " [0 1 0 3 2 1]\n",
      " [1 1 0 2 2 2]\n",
      " [3 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 1 3 2 3]\n",
      " [2 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 2 2 2]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 1 2 2 3]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 1 3 0 2]\n",
      " [1 0 1 3 1 2]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [2 1 1 1 1 4]\n",
      " [1 0 0 3 2 0]\n",
      " [1 0 1 2 2 2]\n",
      " [2 1 1 1 2 4]\n",
      " [3 1 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 2 1]\n",
      " [3 1 0 1 2 3]\n",
      " [1 1 1 3 2 2]\n",
      " [2 0 1 3 2 2]\n",
      " [1 0 1 3 0 2]\n",
      " [2 0 0 1 0 4]\n",
      " [1 0 0 1 2 4]\n",
      " [2 0 0 1 0 4]\n",
      " [3 0 1 2 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [0 1 1 3 2 3]\n",
      " [3 1 1 1 2 4]\n",
      " [2 1 0 1 2 0]\n",
      " [1 0 0 3 1 0]\n",
      " [2 1 0 2 2 1]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 1 3 2 0]\n",
      " [3 0 1 1 2 4]\n",
      " [2 0 0 1 2 4]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 2 2 2]\n",
      " [2 1 1 1 0 3]\n",
      " [1 0 0 3 1 0]\n",
      " [3 0 1 1 2 4]\n",
      " [2 0 0 3 2 0]\n",
      " [1 1 0 2 2 0]\n",
      " [0 1 1 3 1 3]\n",
      " [2 0 1 3 2 2]\n",
      " [4 1 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [0 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 0 3 0 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 1 2 4]\n",
      " [1 0 1 1 0 4]\n",
      " [2 1 0 2 0 2]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 0 0]\n",
      " [0 0 1 1 2 4]\n",
      " [2 1 0 1 2 3]\n",
      " [3 0 1 1 0 4]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 3 1 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 2 1 2]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 1 2 4]\n",
      " [2 0 0 1 0 4]\n",
      " [1 0 1 1 0 4]\n",
      " [1 1 1 2 0 3]\n",
      " [1 0 0 1 0 4]\n",
      " [1 0 0 1 0 4]\n",
      " [1 0 1 1 0 4]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 1 2 2 3]\n",
      " [1 0 0 3 2 0]\n",
      " [1 0 1 2 2 3]\n",
      " [3 1 0 2 2 2]\n",
      " [1 0 1 1 2 4]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 2 1 2]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 1 3 2 4]\n",
      " [2 0 0 1 0 4]\n",
      " [3 1 0 3 2 0]\n",
      " [2 0 0 2 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [0 0 1 1 0 4]\n",
      " [1 0 1 3 1 3]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 1 1 2 4]\n",
      " [0 1 1 3 2 2]\n",
      " [2 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 1 2 4]\n",
      " [2 0 0 1 0 4]\n",
      " [2 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [0 1 1 2 2 3]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 0 2 2 2]\n",
      " [2 0 0 2 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [0 1 1 3 2 2]\n",
      " [2 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [0 1 1 3 0 0]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 1 2 4]\n",
      " [2 0 0 2 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 3 1 0]\n",
      " [2 1 1 3 2 3]\n",
      " [1 1 1 2 0 3]\n",
      " [2 0 1 3 0 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 1 3 1 2]\n",
      " [1 1 0 3 2 0]\n",
      " [3 0 1 1 0 4]\n",
      " [1 0 0 3 0 0]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 1 0 4]\n",
      " [1 1 1 1 0 4]\n",
      " [1 1 1 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 1 0 4]\n",
      " [0 0 1 3 2 2]\n",
      " [2 0 1 1 0 4]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 0 1 0 4]\n",
      " [0 0 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 4]\n",
      " [0 1 1 3 2 4]\n",
      " [2 0 0 2 2 2]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 0 2 0 2]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 3 2 0]\n",
      " [1 0 1 1 0 4]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 0 2 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [1 0 0 2 2 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 3 2 1]\n",
      " [1 1 1 3 2 2]\n",
      " [1 0 0 3 2 1]\n",
      " [2 1 1 2 2 2]\n",
      " [3 1 0 3 2 0]\n",
      " [0 1 1 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [2 0 1 1 1 4]\n",
      " [1 1 0 2 2 0]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 0 3 2 1]\n",
      " [2 0 1 2 2 3]\n",
      " [1 0 1 2 2 2]\n",
      " [1 1 0 2 2 2]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 2 2 3]\n",
      " [1 0 0 2 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 1 2 3]\n",
      " [1 0 1 3 2 2]\n",
      " [2 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 1 1 2 4]\n",
      " [0 0 1 1 2 4]\n",
      " [1 0 1 3 2 3]\n",
      " [1 0 1 2 2 2]\n",
      " [3 1 1 1 2 4]\n",
      " [1 1 0 2 2 1]\n",
      " [2 0 1 2 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 2 0]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 1 2 4]\n",
      " [0 0 1 2 2 2]\n",
      " [2 1 0 1 2 3]\n",
      " [0 0 1 3 0 2]\n",
      " [3 1 0 1 2 3]\n",
      " [2 1 1 2 2 3]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 1 0 3]\n",
      " [3 1 1 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 0 0]\n",
      " [4 1 0 1 2 3]\n",
      " [2 0 1 1 2 4]\n",
      " [3 0 0 2 2 1]\n",
      " [1 1 0 3 1 0]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 2 2 0]\n",
      " [3 1 0 1 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [0 0 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 3 2 1]\n",
      " [2 0 1 2 2 3]\n",
      " [1 0 0 2 0 2]\n",
      " [1 0 0 3 2 1]\n",
      " [2 1 0 1 2 4]\n",
      " [2 1 1 2 2 2]\n",
      " [1 1 1 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 3 2 2]\n",
      " [0 1 1 3 2 4]\n",
      " [1 1 0 2 2 0]\n",
      " [3 1 0 3 2 1]\n",
      " [3 0 0 3 2 1]\n",
      " [1 1 1 1 0 4]\n",
      " [1 0 1 3 2 3]\n",
      " [2 0 1 1 2 4]\n",
      " [3 1 0 1 0 3]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 3 2 2]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 1 2 3]\n",
      " [4 1 0 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 0 2]\n",
      " [3 0 1 1 0 4]\n",
      " [1 1 0 3 2 2]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 3 1 0]\n",
      " [2 0 0 3 2 1]\n",
      " [0 0 0 1 2 4]\n",
      " [1 1 1 1 0 4]\n",
      " [2 0 1 2 2 3]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 0 3 2 3]\n",
      " [1 1 0 3 2 4]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [3 0 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 3]\n",
      " [2 0 0 2 2 1]\n",
      " [1 1 0 3 1 3]\n",
      " [2 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [2 1 0 3 1 0]\n",
      " [3 0 0 2 2 1]\n",
      " [2 1 0 1 2 4]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 1 2 2 2]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 1 3 0 0]\n",
      " [1 0 1 3 0 3]\n",
      " [1 0 0 3 2 1]\n",
      " [0 0 1 2 2 3]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 0 1 0 4]\n",
      " [1 1 0 3 2 2]\n",
      " [1 0 1 1 0 4]\n",
      " [2 0 1 1 2 4]\n",
      " [0 0 1 3 2 3]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 1 2 2 3]\n",
      " [3 1 1 1 0 4]\n",
      " [3 1 0 1 2 3]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 2 0 2]\n",
      " [2 1 1 3 2 2]\n",
      " [0 1 1 2 2 3]\n",
      " [1 1 1 1 0 4]\n",
      " [1 1 0 2 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 0 3 2 0]\n",
      " [3 1 0 1 2 3]\n",
      " [2 0 1 1 0 3]\n",
      " [2 1 0 1 0 4]\n",
      " [2 0 1 1 2 4]\n",
      " [2 0 1 3 2 2]\n",
      " [1 1 0 3 1 0]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 2 2 1]\n",
      " [3 0 1 1 2 4]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 0 3 1 0]\n",
      " [0 1 0 3 2 1]\n",
      " [1 1 0 3 2 2]\n",
      " [2 0 0 2 2 2]\n",
      " [2 0 1 1 2 4]\n",
      " [1 0 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 2 2 3]\n",
      " [2 0 1 1 0 4]\n",
      " [3 1 0 2 2 3]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 0 3 0 1]\n",
      " [1 0 1 1 2 4]\n",
      " [2 1 0 2 2 2]\n",
      " [3 1 1 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 3 2 0]\n",
      " [3 0 1 1 0 4]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 1 3 1 0]\n",
      " [2 1 1 2 2 3]\n",
      " [2 1 1 3 2 3]\n",
      " [1 0 0 2 2 3]\n",
      " [3 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [3 1 1 1 0 4]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 4]\n",
      " [2 1 0 3 2 1]\n",
      " [2 1 0 1 0 3]\n",
      " [2 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 1 2 3]\n",
      " [1 0 1 2 0 4]\n",
      " [2 0 0 1 2 4]\n",
      " [2 0 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 1 2]\n",
      " [1 1 0 3 1 0]\n",
      " [2 1 0 3 2 1]\n",
      " [1 0 1 2 2 4]\n",
      " [2 1 1 3 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 1 3 0 2]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 2]\n",
      " [3 1 0 1 2 3]\n",
      " [3 1 0 2 1 2]\n",
      " [1 0 0 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [4 1 0 1 2 3]\n",
      " [3 1 0 3 2 0]\n",
      " [1 1 0 1 0 3]\n",
      " [2 1 0 1 2 0]\n",
      " [0 0 1 3 2 3]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 2 2 3]\n",
      " [2 0 1 3 2 3]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 1 0 4]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 0 3 2 4]\n",
      " [0 0 1 3 0 2]\n",
      " [2 1 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 2 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 1 2]\n",
      " [1 1 0 2 2 2]\n",
      " [3 1 1 1 0 4]\n",
      " [3 1 1 1 2 4]\n",
      " [2 1 0 3 0 0]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 1 3 2 0]\n",
      " [1 1 1 2 2 4]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 3 2 1]\n",
      " [2 0 1 1 2 4]\n",
      " [2 0 1 2 2 3]\n",
      " [1 1 1 1 2 4]\n",
      " [4 1 0 2 2 1]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 2 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 2 1]\n",
      " [2 0 1 3 2 4]\n",
      " [2 1 1 1 0 4]\n",
      " [1 0 0 3 1 1]\n",
      " [1 1 0 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 3 2 4]\n",
      " [3 1 1 2 2 3]\n",
      " [1 1 1 2 0 4]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 1 2 4]\n",
      " [1 1 1 1 2 4]\n",
      " [0 0 1 3 0 2]\n",
      " [1 1 0 3 2 4]\n",
      " [1 1 0 3 0 0]\n",
      " [3 1 0 1 2 3]\n",
      " [3 1 0 2 2 2]\n",
      " [2 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [3 1 1 1 0 4]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 1 1 0 4]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 1 3 0 2]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 1 3 2 0]\n",
      " [2 1 0 2 2 3]\n",
      " [2 0 0 2 2 2]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 0 1 2 4]\n",
      " [1 1 1 3 0 2]\n",
      " [1 0 0 1 0 4]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [3 1 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 0 1 0 4]\n",
      " [1 0 0 2 2 1]\n",
      " [1 1 0 3 1 2]\n",
      " [2 1 0 3 2 0]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 1 3 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [3 1 0 2 2 2]\n",
      " [1 1 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 2 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 2 2 3]\n",
      " [1 0 1 3 2 0]\n",
      " [1 0 0 1 2 4]\n",
      " [0 1 0 3 0 2]\n",
      " [1 1 0 2 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 3 2 2]\n",
      " [2 0 1 3 2 3]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 1 1 2 4]\n",
      " [1 0 1 1 0 4]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [4 1 1 1 2 4]\n",
      " [0 1 1 3 2 2]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 1 1 2 4]\n",
      " [1 1 0 3 1 0]\n",
      " [0 0 1 2 2 3]\n",
      " [0 1 1 3 2 2]\n",
      " [2 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 2 2 4]\n",
      " [0 1 1 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 0 3 2 1]\n",
      " [2 0 0 1 2 4]\n",
      " [1 1 0 3 2 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [2 0 1 1 2 4]\n",
      " [0 1 0 3 2 0]\n",
      " [3 0 1 1 2 4]\n",
      " [2 1 0 1 0 3]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 3 1 3]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 3 2 0]\n",
      " [3 0 0 2 2 1]\n",
      " [1 1 0 3 0 0]\n",
      " [3 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [0 0 0 3 2 2]\n",
      " [1 1 0 3 1 0]\n",
      " [2 0 1 1 2 4]\n",
      " [0 0 0 3 0 0]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 1 2 3]\n",
      " [1 1 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [0 1 1 3 1 3]\n",
      " [0 1 1 3 2 2]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 0 3 1 0]\n",
      " [0 1 0 2 2 3]\n",
      " [1 0 1 3 2 4]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [3 0 0 1 2 3]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 1 3 2 3]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 1 2 2 3]\n",
      " [0 1 1 1 2 4]\n",
      " [0 1 1 3 0 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [2 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 3 2 3]\n",
      " [2 1 0 2 2 1]\n",
      " [0 0 1 3 2 3]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 1 2 0 3]\n",
      " [2 1 0 3 2 0]\n",
      " [0 1 1 3 2 3]\n",
      " [3 0 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 0]\n",
      " [1 0 1 3 2 2]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 4]\n",
      " [0 1 1 2 0 3]\n",
      " [1 1 0 3 1 0]\n",
      " [3 0 0 1 2 4]\n",
      " [0 0 1 3 0 2]\n",
      " [0 1 1 2 2 2]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 4]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [0 1 0 2 2 1]\n",
      " [1 0 0 1 0 3]\n",
      " [2 1 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 1 3 2 4]\n",
      " [2 1 0 3 0 0]\n",
      " [1 1 1 2 2 3]\n",
      " [2 0 1 1 0 4]\n",
      " [0 1 1 3 2 3]\n",
      " [4 1 0 3 2 0]\n",
      " [0 0 1 3 0 2]\n",
      " [0 0 1 1 2 3]\n",
      " [2 0 1 2 2 3]\n",
      " [1 0 1 3 2 1]\n",
      " [2 0 1 1 2 4]\n",
      " [3 1 0 1 2 3]\n",
      " [1 0 1 3 0 2]\n",
      " [1 1 0 3 0 0]\n",
      " [2 1 1 3 2 2]\n",
      " [1 1 1 2 2 2]\n",
      " [2 0 0 1 2 3]\n",
      " [1 0 1 3 2 4]\n",
      " [1 1 0 2 2 2]\n",
      " [2 0 0 2 2 2]\n",
      " [1 0 1 2 0 2]\n",
      " [1 1 0 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [0 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 1 2 4]\n",
      " [2 1 0 1 2 0]\n",
      " [2 1 0 3 2 1]\n",
      " [1 0 1 2 0 3]\n",
      " [0 0 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [3 0 1 1 0 4]\n",
      " [1 0 1 2 2 3]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 1 3 1 3]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 0 1 2 3]\n",
      " [1 0 1 3 2 3]\n",
      " [1 1 0 1 0 3]\n",
      " [1 1 0 3 1 0]]\n"
     ]
    }
   ],
   "source": [
    "## X는 위의 predata 함수로 추출한 사용할 변수들을 array로 추출한것, y는 target으로 Survived or Dead를 의미 \n",
    "X=predata(train_data)\n",
    "y=np.array(train_data.Survived).reshape(-1,1)\n",
    "\n",
    "print(X) # 각 열이 x_n으로 neural network를 만들기 위함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model(input=6, output=1,) Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 617,153\n",
      "Trainable params: 615,153\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epoch=150\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 32, input_shape = (6,), activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer = 'he_normal')) # kernal_initializer은 weight를 초기화하는방법. 그중 he_normal을 택함\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization()) # 학습 과정을 안정화 시키기 위하여 BatchNormalization을 진행\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 256, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 512, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 512, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 256, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2)) # overfitting이 많이 일어나므로, Dropout을 여러층을 이용하였음\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 16, activation = 'relu',kernel_regularizer=tf.keras.regularizers.L2(0.01))) # L2 regulation을 사용함\n",
    "model.add(tf.keras.layers.Dense(units = 8, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units =1 , activation = 'sigmoid')) # 0과 1을 분류하는 문제와 같으므로(Survived or Dead) sigmoid를 이용하여 분류함\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss and Optimizer (loss= binary CE , optimizer= SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0-1을 분류하는것이므로 binary_CE를 loss function으로 이용, optimizer은 Adam,SGD를 learning_rate를 바꾸어가며 설정 할 수도 있음\n",
    "model.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train (validation=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 23:01:52.213468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.0719 - accuracy: 0.5183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 23:01:55.296095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 4s 112ms/step - loss: 1.0719 - accuracy: 0.5183 - val_loss: 0.8748 - val_accuracy: 0.6425\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.9720 - accuracy: 0.5534 - val_loss: 0.8556 - val_accuracy: 0.6425\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.9187 - accuracy: 0.5969 - val_loss: 0.8325 - val_accuracy: 0.7654\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.9127 - accuracy: 0.6110 - val_loss: 0.8230 - val_accuracy: 0.7486\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.8448 - accuracy: 0.6559 - val_loss: 0.7745 - val_accuracy: 0.7263\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.8248 - accuracy: 0.6685 - val_loss: 0.7911 - val_accuracy: 0.7486\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.8177 - accuracy: 0.6404 - val_loss: 0.7964 - val_accuracy: 0.7430\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.8139 - accuracy: 0.6587 - val_loss: 0.7859 - val_accuracy: 0.6760\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.8395 - accuracy: 0.6447 - val_loss: 0.8081 - val_accuracy: 0.7151\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7788 - accuracy: 0.6994 - val_loss: 0.7283 - val_accuracy: 0.7821\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7893 - accuracy: 0.6882 - val_loss: 0.7168 - val_accuracy: 0.7654\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.7604 - accuracy: 0.7191 - val_loss: 0.6765 - val_accuracy: 0.7654\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.7582 - accuracy: 0.7121 - val_loss: 0.6255 - val_accuracy: 0.8212\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.7355 - accuracy: 0.7233 - val_loss: 0.6963 - val_accuracy: 0.7486\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.7632 - accuracy: 0.7093 - val_loss: 0.7346 - val_accuracy: 0.7709\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.7592 - accuracy: 0.7051 - val_loss: 0.6922 - val_accuracy: 0.7765\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.7584 - accuracy: 0.7191 - val_loss: 0.6689 - val_accuracy: 0.8324\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.7342 - accuracy: 0.7233 - val_loss: 0.6328 - val_accuracy: 0.8268\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.7123 - accuracy: 0.7458 - val_loss: 0.6106 - val_accuracy: 0.8212\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.7199 - accuracy: 0.7149 - val_loss: 0.5972 - val_accuracy: 0.8268\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.7018 - accuracy: 0.7402 - val_loss: 0.5997 - val_accuracy: 0.8324\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6990 - accuracy: 0.7486 - val_loss: 0.5894 - val_accuracy: 0.8212\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7015 - accuracy: 0.7598 - val_loss: 0.5785 - val_accuracy: 0.8212\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6731 - accuracy: 0.7669 - val_loss: 0.5872 - val_accuracy: 0.8156\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6696 - accuracy: 0.7570 - val_loss: 0.5715 - val_accuracy: 0.8156\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6985 - accuracy: 0.7472 - val_loss: 0.5648 - val_accuracy: 0.8212\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6706 - accuracy: 0.7683 - val_loss: 0.5646 - val_accuracy: 0.8045\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6822 - accuracy: 0.7556 - val_loss: 0.5559 - val_accuracy: 0.8324\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.6616 - accuracy: 0.7725 - val_loss: 0.5530 - val_accuracy: 0.8380\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6754 - accuracy: 0.7500 - val_loss: 0.5540 - val_accuracy: 0.8380\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6399 - accuracy: 0.7879 - val_loss: 0.5831 - val_accuracy: 0.7933\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6785 - accuracy: 0.7669 - val_loss: 0.5493 - val_accuracy: 0.8324\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6627 - accuracy: 0.7795 - val_loss: 0.5510 - val_accuracy: 0.8212\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6318 - accuracy: 0.7795 - val_loss: 0.5612 - val_accuracy: 0.8212\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6550 - accuracy: 0.7612 - val_loss: 0.5560 - val_accuracy: 0.8268\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6516 - accuracy: 0.7598 - val_loss: 0.5452 - val_accuracy: 0.8324\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6574 - accuracy: 0.7809 - val_loss: 0.5499 - val_accuracy: 0.8156\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6595 - accuracy: 0.7654 - val_loss: 0.5330 - val_accuracy: 0.8212\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.6394 - accuracy: 0.7837 - val_loss: 0.5462 - val_accuracy: 0.8212\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6308 - accuracy: 0.7851 - val_loss: 0.5490 - val_accuracy: 0.8268\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6487 - accuracy: 0.7753 - val_loss: 0.5398 - val_accuracy: 0.8324\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6426 - accuracy: 0.7837 - val_loss: 0.5295 - val_accuracy: 0.8380\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6262 - accuracy: 0.8006 - val_loss: 0.5275 - val_accuracy: 0.8380\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.6192 - accuracy: 0.7949 - val_loss: 0.5245 - val_accuracy: 0.8380\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6498 - accuracy: 0.7640 - val_loss: 0.5142 - val_accuracy: 0.8380\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6241 - accuracy: 0.7879 - val_loss: 0.5099 - val_accuracy: 0.8324\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6348 - accuracy: 0.7697 - val_loss: 0.5205 - val_accuracy: 0.8268\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6194 - accuracy: 0.7795 - val_loss: 0.5341 - val_accuracy: 0.8380\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.6435 - accuracy: 0.7739 - val_loss: 0.5485 - val_accuracy: 0.8156\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6271 - accuracy: 0.7669 - val_loss: 0.5305 - val_accuracy: 0.8156\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6072 - accuracy: 0.7823 - val_loss: 0.5126 - val_accuracy: 0.8380\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.6243 - accuracy: 0.7837 - val_loss: 0.5158 - val_accuracy: 0.8268\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6080 - accuracy: 0.7767 - val_loss: 0.5103 - val_accuracy: 0.8324\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.5927 - accuracy: 0.7907 - val_loss: 0.4957 - val_accuracy: 0.8436\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6098 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.8436\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6081 - accuracy: 0.7809 - val_loss: 0.4981 - val_accuracy: 0.8436\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5930 - accuracy: 0.7992 - val_loss: 0.4928 - val_accuracy: 0.8492\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5988 - accuracy: 0.7851 - val_loss: 0.4887 - val_accuracy: 0.8492\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5895 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.8436\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5881 - accuracy: 0.7921 - val_loss: 0.4927 - val_accuracy: 0.8268\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.6141 - accuracy: 0.7823 - val_loss: 0.4921 - val_accuracy: 0.8380\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5804 - accuracy: 0.8090 - val_loss: 0.4862 - val_accuracy: 0.8324\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 0.5661 - accuracy: 0.8090 - val_loss: 0.4903 - val_accuracy: 0.8324\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.5698 - accuracy: 0.8006 - val_loss: 0.4880 - val_accuracy: 0.8324\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5708 - accuracy: 0.7949 - val_loss: 0.4889 - val_accuracy: 0.8156\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5871 - accuracy: 0.7823 - val_loss: 0.4964 - val_accuracy: 0.8156\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.5765 - accuracy: 0.8090 - val_loss: 0.4939 - val_accuracy: 0.8324\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5696 - accuracy: 0.7921 - val_loss: 0.5133 - val_accuracy: 0.8101\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5716 - accuracy: 0.7992 - val_loss: 0.5004 - val_accuracy: 0.8268\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5589 - accuracy: 0.8132 - val_loss: 0.4923 - val_accuracy: 0.8324\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5576 - accuracy: 0.8034 - val_loss: 0.4864 - val_accuracy: 0.8436\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.5580 - accuracy: 0.8174 - val_loss: 0.5462 - val_accuracy: 0.7989\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 2s 98ms/step - loss: 0.6123 - accuracy: 0.7725 - val_loss: 0.5017 - val_accuracy: 0.8324\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.6093 - accuracy: 0.7640 - val_loss: 0.4893 - val_accuracy: 0.8324\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.5798 - accuracy: 0.7753 - val_loss: 0.4853 - val_accuracy: 0.8324\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.6088 - accuracy: 0.7654 - val_loss: 0.4850 - val_accuracy: 0.8268\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5974 - accuracy: 0.7837 - val_loss: 0.4794 - val_accuracy: 0.8324\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5540 - accuracy: 0.8146 - val_loss: 0.4765 - val_accuracy: 0.8380\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5625 - accuracy: 0.7935 - val_loss: 0.4677 - val_accuracy: 0.8436\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5599 - accuracy: 0.7963 - val_loss: 0.4648 - val_accuracy: 0.8380\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5532 - accuracy: 0.7963 - val_loss: 0.4632 - val_accuracy: 0.8380\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.5304 - accuracy: 0.8188 - val_loss: 0.4636 - val_accuracy: 0.8380\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 2s 99ms/step - loss: 0.5614 - accuracy: 0.7865 - val_loss: 0.4627 - val_accuracy: 0.8436\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.5508 - accuracy: 0.8048 - val_loss: 0.4629 - val_accuracy: 0.8492\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.5745 - accuracy: 0.7949 - val_loss: 0.4600 - val_accuracy: 0.8547\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5628 - accuracy: 0.8216 - val_loss: 0.4591 - val_accuracy: 0.8547\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5616 - accuracy: 0.8062 - val_loss: 0.4603 - val_accuracy: 0.8436\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5701 - accuracy: 0.7963 - val_loss: 0.4548 - val_accuracy: 0.8380\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5430 - accuracy: 0.8132 - val_loss: 0.4713 - val_accuracy: 0.8380\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5655 - accuracy: 0.7865 - val_loss: 0.4683 - val_accuracy: 0.8268\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 2s 102ms/step - loss: 0.5363 - accuracy: 0.8202 - val_loss: 0.4555 - val_accuracy: 0.8436\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.5557 - accuracy: 0.8048 - val_loss: 0.4608 - val_accuracy: 0.8380\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.5362 - accuracy: 0.8118 - val_loss: 0.4571 - val_accuracy: 0.8492\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5436 - accuracy: 0.8090 - val_loss: 0.4630 - val_accuracy: 0.8492\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.5357 - accuracy: 0.8034 - val_loss: 0.4659 - val_accuracy: 0.8436\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5537 - accuracy: 0.7978 - val_loss: 0.4801 - val_accuracy: 0.8324\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5652 - accuracy: 0.8020 - val_loss: 0.4572 - val_accuracy: 0.8436\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5528 - accuracy: 0.8006 - val_loss: 0.4655 - val_accuracy: 0.8436\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5531 - accuracy: 0.7879 - val_loss: 0.4553 - val_accuracy: 0.8492\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5468 - accuracy: 0.7963 - val_loss: 0.4722 - val_accuracy: 0.8324\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5411 - accuracy: 0.7851 - val_loss: 0.4563 - val_accuracy: 0.8268\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5458 - accuracy: 0.8076 - val_loss: 0.4511 - val_accuracy: 0.8268\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5381 - accuracy: 0.7992 - val_loss: 0.4450 - val_accuracy: 0.8380\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5346 - accuracy: 0.7893 - val_loss: 0.4380 - val_accuracy: 0.8380\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5438 - accuracy: 0.8020 - val_loss: 0.4425 - val_accuracy: 0.8324\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5477 - accuracy: 0.8020 - val_loss: 0.5252 - val_accuracy: 0.7151\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5451 - accuracy: 0.8006 - val_loss: 0.4667 - val_accuracy: 0.8380\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5291 - accuracy: 0.8090 - val_loss: 0.4716 - val_accuracy: 0.8212\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5234 - accuracy: 0.8034 - val_loss: 0.4564 - val_accuracy: 0.8268\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5562 - accuracy: 0.7963 - val_loss: 0.4381 - val_accuracy: 0.8268\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5404 - accuracy: 0.7963 - val_loss: 0.4455 - val_accuracy: 0.8380\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.5474 - accuracy: 0.7992 - val_loss: 0.4351 - val_accuracy: 0.8436\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5333 - accuracy: 0.8048 - val_loss: 0.4380 - val_accuracy: 0.8380\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5361 - accuracy: 0.7865 - val_loss: 0.4337 - val_accuracy: 0.8492\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5322 - accuracy: 0.8062 - val_loss: 0.4367 - val_accuracy: 0.8268\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5400 - accuracy: 0.8034 - val_loss: 0.4424 - val_accuracy: 0.8436\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5340 - accuracy: 0.7963 - val_loss: 0.4366 - val_accuracy: 0.8380\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5218 - accuracy: 0.8160 - val_loss: 0.4267 - val_accuracy: 0.8324\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5597 - accuracy: 0.7767 - val_loss: 0.4479 - val_accuracy: 0.8156\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5315 - accuracy: 0.7978 - val_loss: 0.4354 - val_accuracy: 0.8212\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5259 - accuracy: 0.7992 - val_loss: 0.4469 - val_accuracy: 0.7989\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5124 - accuracy: 0.8132 - val_loss: 0.4283 - val_accuracy: 0.8212\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5299 - accuracy: 0.7851 - val_loss: 0.4297 - val_accuracy: 0.8212\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.5163 - accuracy: 0.8076 - val_loss: 0.4277 - val_accuracy: 0.8268\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5211 - accuracy: 0.8216 - val_loss: 0.4273 - val_accuracy: 0.8212\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5193 - accuracy: 0.8188 - val_loss: 0.4295 - val_accuracy: 0.8212\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5147 - accuracy: 0.7949 - val_loss: 0.4222 - val_accuracy: 0.8156\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.5204 - accuracy: 0.8090 - val_loss: 0.4216 - val_accuracy: 0.8212\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5109 - accuracy: 0.8034 - val_loss: 0.4157 - val_accuracy: 0.8380\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5280 - accuracy: 0.7992 - val_loss: 0.4159 - val_accuracy: 0.8324\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5176 - accuracy: 0.8034 - val_loss: 0.4159 - val_accuracy: 0.8268\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5318 - accuracy: 0.8020 - val_loss: 0.4157 - val_accuracy: 0.8268\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5137 - accuracy: 0.8160 - val_loss: 0.4156 - val_accuracy: 0.8268\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4970 - accuracy: 0.8132 - val_loss: 0.4223 - val_accuracy: 0.8268\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5256 - accuracy: 0.8020 - val_loss: 0.4228 - val_accuracy: 0.8268\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4882 - accuracy: 0.8104 - val_loss: 0.4340 - val_accuracy: 0.8268\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5185 - accuracy: 0.8062 - val_loss: 0.4218 - val_accuracy: 0.8380\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4937 - accuracy: 0.8132 - val_loss: 0.4208 - val_accuracy: 0.8436\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4887 - accuracy: 0.8272 - val_loss: 0.4182 - val_accuracy: 0.8380\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.5033 - accuracy: 0.8090 - val_loss: 0.4139 - val_accuracy: 0.8380\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4940 - accuracy: 0.8020 - val_loss: 0.4385 - val_accuracy: 0.8156\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4923 - accuracy: 0.8272 - val_loss: 0.4232 - val_accuracy: 0.8380\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5044 - accuracy: 0.7978 - val_loss: 0.4224 - val_accuracy: 0.8492\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4877 - accuracy: 0.8048 - val_loss: 0.4206 - val_accuracy: 0.8380\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4989 - accuracy: 0.7978 - val_loss: 0.4208 - val_accuracy: 0.8380\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5148 - accuracy: 0.8034 - val_loss: 0.4196 - val_accuracy: 0.8380\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5060 - accuracy: 0.8006 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5013 - accuracy: 0.8048 - val_loss: 0.4171 - val_accuracy: 0.8212\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4762 - accuracy: 0.8216 - val_loss: 0.4222 - val_accuracy: 0.8156\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4893 - accuracy: 0.8174 - val_loss: 0.4193 - val_accuracy: 0.8268\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=epoch,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train 한 결과중 정확도, 손실을 출력 \n",
    "acc = history.history['accuracy'] \n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291b17eb0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABHH0lEQVR4nO2dd5hUVfK/32JIkjMSJCk5IyCSxAyKCCgCa8IEYsIMq6iYfl9X2V3XVcS05hVdA6KiKIggigGUIEmCKCMoUTISpn5/VF96Qk+enu6h632efm7fc8+9t3qm+3zuqVOnjqgqjuM4TuJSLNYGOI7jOLHFhcBxHCfBcSFwHMdJcFwIHMdxEhwXAsdxnATHhcBxHCfBcSFwHMdJcFwIHCcLRGStiJwWazscJ5q4EDiO4yQ4LgSOk0tEpJSIPCoi60OvR0WkVOhYNRF5X0T+EJGtIvK5iBQLHRstIr+KyE4RWSEip8b2kziOUTzWBjhOEeROoAvQDlDgXWAscBdwC5AMVA/V7QKoiDQFrgM6qep6EWkAJBWu2Y4TGe8ROE7uuRC4T1U3quom4F7g4tCxA0AtoL6qHlDVz9USeh0CSgEtRKSEqq5V1dUxsd5x0uFC4Di5pzbwc6r9n0NlAI8Aq4CPRWSNiIwBUNVVwI3AOGCjiEwSkdo4ThzgQuA4uWc9UD/Vfr1QGaq6U1VvUdVGwDnAzcFYgKr+V1W7h85V4G+Fa7bjRMaFwHGyp4SIlA5ewGvAWBGpLiLVgLuBVwBEpK+IHCciAuzAXEKHRKSpiJwSGlTeB+wNHXOcmONC4DjZMxVruINXaWAesAhYDHwHPBCq2xiYDuwC5gITVPUzbHzgIWAz8BtQA7ij0D6B42SB+MI0juM4iY33CBzHcRIcFwLHcZwEx4XAcRwnwYmaEIjIf0Rko4j8kMnxZiIyV0T+FJFbo2WH4ziOkzVRGywWkZ5Y5MRLqtoqwvEaWDx1f2Cbqo7PyXWrVaumDRo0KEBLHcdxjnzmz5+/WVWrRzoWtVxDqjo7lE8ls+MbsRmWZ+fmug0aNGDevHn5Nc9xHCehEJGfMztWJMYIRGS4iMwTkXmbNm2KtTmO4zhHFEVCCFT1aVXtqKodq1eP2LNxHMdx8kiREALHcRwnevh6BI7jZMuBAwdITk5m3759sTbFyYbSpUtTt25dSpQokeNzoiYEIvIa0AuoJiLJwD1ACQBVnSgiR2P5WioAKSJyI9BCVXdEyybHcfJGcnIy5cuXp0GDBlg+PSceUVW2bNlCcnIyDRs2zPF50YwaGprN8d+AutG6v+M4Bce+fftcBIoAIkLVqlXJbVCNjxE4jpMjXASKBnn5PyWOECxeDGPHwubNsbbEcRwnrkgcIVi5Eh58EJKTY22J4zi5ZMuWLbRr14527dpx9NFHU6dOncP7+/fvz/LcefPmccMNN2R7j65duxaIrZ999hl9+/YtkGsVFokTNVS5sm23bo2tHY7j5JqqVauyYMECAMaNG0e5cuW49dZwirKDBw9SvHjk5qxjx4507Ngx23t8+eWXBWJrUSRxegRVqth227bY2uE4ToEwbNgwbr75Zk4++WRGjx7NN998Q9euXWnfvj1du3ZlxYoVQNon9HHjxnH55ZfTq1cvGjVqxGOPPXb4euXKlTtcv1evXpx//vk0a9aMCy+8kCAn29SpU2nWrBndu3fnhhtuyPbJf+vWrfTv3582bdrQpUsXFi1aBMCsWbMO92jat2/Pzp072bBhAz179qRdu3a0atWKzz//vMD/ZpmReD0CFwLHyR833gihp/MCo107ePTRXJ/2448/Mn36dJKSktixYwezZ8+mePHiTJ8+nTvuuIO33norwznLly9n5syZ7Ny5k6ZNmzJy5MgMMffff/89S5YsoXbt2nTr1o0vvviCjh07MmLECGbPnk3Dhg0ZOjTLwEgA7rnnHtq3b8/kyZP59NNPueSSS1iwYAHjx4/niSeeoFu3buzatYvSpUvz9NNPc+aZZ3LnnXdy6NAh9uzZk+u/R15JHCEIegTuGnKcI4ZBgwaRlJQEwPbt27n00ktZuXIlIsKBAwcinnP22WdTqlQpSpUqRY0aNfj999+pWzdtJHvnzp0Pl7Vr1461a9dSrlw5GjVqdDg+f+jQoTz99NNZ2jdnzpzDYnTKKaewZcsWtm/fTrdu3bj55pu58MILGThwIHXr1qVTp05cfvnlHDhwgP79+9OuXbv8/GlyReIIQdmyULy49wgcJ7/k4ck9WpQtW/bw+7vuuouTTz6Zd955h7Vr19KrV6+I55QqVerw+6SkJA4ePJijOnlJ2R/pHBFhzJgxnH322UydOpUuXbowffp0evbsyezZs/nggw+4+OKLue2227jkkktyfc+8kDhjBCLWK/AegeMckWzfvp06deoA8MILLxT49Zs1a8aaNWtYu3YtAK+//nq25/Ts2ZNXX30VsLGHatWqUaFCBVavXk3r1q0ZPXo0HTt2ZPny5fz888/UqFGDq666iiuuuILvvvuuwD9DZiROjwBsnMB7BI5zRHL77bdz6aWX8o9//INTTjmlwK9/1FFHMWHCBHr37k21atXo3LlztueMGzeOyy67jDZt2lCmTBlefPFFAB599FFmzpxJUlISLVq0oE+fPkyaNIlHHnmEEiVKUK5cOV566aUC/wyZEbUVyqJFx44dNc8L03Ttai6iTz4pWKMc5whn2bJlNG/ePNZmxJxdu3ZRrlw5VJVrr72Wxo0bc9NNN8XarAxE+n+JyHxVjRhHmziuIbAegbuGHMfJI8888wzt2rWjZcuWbN++nREjRsTapAIh8VxDy5bF2grHcYooN910U1z2APJLYvUIfLDYcRwnA4klBJUrw/btcOhQrC1xHMeJGxJLCIJJZX/8EVMzHMdx4onEEgJPM+E4jpOBxBICTzznOEWSXr16MW3atDRljz76KNdcc02W5wSh5meddRZ/RPAEjBs3jvHjx2d578mTJ7N06dLD+3fffTfTp0/PhfWRiad01YklBJ6K2nGKJEOHDmXSpElpyiZNmpSjxG9gWUMrVaqUp3unF4L77ruP0047LU/XilcSSwi8R+A4RZLzzz+f999/nz///BOAtWvXsn79erp3787IkSPp2LEjLVu25J577ol4foMGDdgcWp3wwQcfpGnTppx22mmHU1WDzRHo1KkTbdu25bzzzmPPnj18+eWXTJkyhdtuu4127dqxevVqhg0bxptvvgnAjBkzaN++Pa1bt+byyy8/bF+DBg2455576NChA61bt2b58uVZfr5Yp6tOvHkE4D0Cx8kHschCXbVqVTp37sxHH33Eueeey6RJkxg8eDAiwoMPPkiVKlU4dOgQp556KosWLaJNmzYRrzN//nwmTZrE999/z8GDB+nQoQPHH388AAMHDuSqq64CYOzYsTz33HNcf/319OvXj759+3L++eenuda+ffsYNmwYM2bMoEmTJlxyySU8+eST3HjjjQBUq1aN7777jgkTJjB+/HieffbZTD9frNNVR61HICL/EZGNIvJDJsdFRB4TkVUiskhEOkTLlsP4YLHjFFlSu4dSu4XeeOMNOnToQPv27VmyZEkaN056Pv/8cwYMGECZMmWoUKEC/fr1O3zshx9+oEePHrRu3ZpXX32VJUuWZGnPihUraNiwIU2aNAHg0ksvZfbs2YePDxw4EIDjjz/+cKK6zJgzZw4XX3wxEDld9WOPPcYff/xB8eLF6dSpE88//zzjxo1j8eLFlC9fPstr54Ro9gheAB4HMsuc1AdoHHqdADwZ2kaPUqWgTBkXAsfJB7HKQt2/f39uvvlmvvvuO/bu3UuHDh346aefGD9+PN9++y2VK1dm2LBh7Nu3L8vriEjE8mHDhjF58mTatm3LCy+8wGeffZbldbLL0xakss4s1XV21yrMdNVR6xGo6mwgKx/MucBLanwFVBKRWtGy5zCeb8hxiiTlypWjV69eXH755Yd7Azt27KBs2bJUrFiR33//nQ8//DDLa/Ts2ZN33nmHvXv3snPnTt57773Dx3bu3EmtWrU4cODA4dTRAOXLl2fnzp0ZrtWsWTPWrl3LqlWrAHj55Zc56aST8vTZYp2uOpZjBHWAdan2k0NlG9JXFJHhwHCAevXq5e+uVap4j8BxiihDhw5l4MCBh11Ebdu2pX379rRs2ZJGjRrRrVu3LM/v0KEDgwcPpl27dtSvX58ePXocPnb//fdzwgknUL9+fVq3bn248R8yZAhXXXUVjz322OFBYoDSpUvz/PPPM2jQIA4ePEinTp24+uqr8/S5Yp2uOqppqEWkAfC+qraKcOwD4P9UdU5ofwZwu6rOz+qa+UpDDRAo9qxZeb+G4yQYnoa6aFGU0lAnA8ek2q8LrI/6Xb1H4DiOk4ZYCsEU4JJQ9FAXYLuqZnALFTg+RuA4jpOGqI0RiMhrQC+gmogkA/cAJQBUdSIwFTgLWAXsAS6Lli1p8B6B4+QJVc004saJH/Li7o+aEKhqlnO/1ay9Nlr3z5TKlWHPHvjzTwsndRwnW0qXLs2WLVuoWrWqi0Eco6ps2bKF0qVL5+q8xJpZDGnTTBx9dGxtcZwiQt26dUlOTmbTpk2xNsXJhtKlS1O3bt1cnZN4QpB6drELgePkiBIlStCwYcNYm+FEicRKOgdQvbptf/sttnY4juPECYknBA0a2Pbnn2NqhuM4TryQeEJwzDFQrBj89FOsLXEcx4kLEk8ISpaEOnVcCBzHcUIknhAANGwI2aSFdRzHSRQSUwgaNPAegeM4TojEFIKGDeHXX21SmeM4ToKTuEKgCuvWZV/XcRznCCcxhSAIIXX3kOM4ToIKQTBD0oXAcRwnQYWgTh0oXtwjhxzHcUhUIUhKgnr1vEfgOI5DogoBmHvIhcBxHCfBhcBdQ47jOAksBA0awO+/2yI1juM4CUziCkEQObRmTWztcBzHiTGJKwQdO1rk0F/+AsnJsbbGcRwnZiSuEDRpAlOn2jjBiSeam8hxHCcBSVwhADj9dJg82XoEM2fG2hrHcZyYEFUhEJHeIrJCRFaJyJgIxyuLyDsiskhEvhGRVtG0JyLt29t2/fpCv7XjOE48EDUhEJEk4AmgD9ACGCoiLdJVuwNYoKptgEuAf0XLnkypVAlKl4YNGwr91o7jOPFANHsEnYFVqrpGVfcDk4Bz09VpAcwAUNXlQAMRqRlFmzIiArVqeY/AcZyEJZpCUAdInec5OVSWmoXAQAAR6QzUB+qmv5CIDBeReSIyb9OmTQVvae3aLgSO4yQs0RQCiVCm6fYfAiqLyALgeuB74GCGk1SfVtWOqtqxevXqBW4otWu7a8hxnISleBSvnQwck2q/LpDmsVtVdwCXAYiIAD+FXoVLrVrw0UeFflvHcZx4IJo9gm+BxiLSUERKAkOAKakriEil0DGAK4HZIXEoXGrXhp07YdeuQr+14zhOrImaEKjqQeA6YBqwDHhDVZeIyNUicnWoWnNgiYgsx6KLRkXLniypXdu27h5yHCcBiaZrCFWdCkxNVzYx1fu5QONo2pAjatWy7fr10Dj25jiO4xQmCTOzeOdOeP11W7M+A94jcBwngUkYIXjnHRgyBObOjXAwEAIPIXUcJwFJGCEYMMAmEL/6aoSDFSvaQRcCx3ESkIQRgvLloV8/eOMNOHAg3UERn0vgOE7CkjBCAHDhhbB5M3zySYSDPrvYcZwEJaGEoHdvqFw5E/eQ5xtyHCdBSSghKFkSBg2yJQgyzB1z15DjOAlKQgkBwNChtl79tGnpDgSzi3fujIldjuM4sSLhhKBbN1uC4IMP0h0IJpV5r8BxnAQj4YSgRAk480xbrjglJdUBn1TmOE6CknBCANC3r61VP39+qsJ69Wy7dGlMbHIcx4kVCSkEvXvb1IE07qHjjrM8Q2+9FfkkVRg3Lp16OI7jFH0SUgiqVYMuXdIJgQgMHgwzZ1p3IT1r1sC998LLLxeanY7jOIVBQgoBmHto3rx0UwcGD7aBg0i9gunTbbtuXcZjjuM4RZiEFYLzz4fixWHUqFQZSVu2hObNLU1pegIhSE4uNBsdx3EKg4QVgiZN4IEH4M034fnnQ4WBe+jzz9N2FQ4dgk8/tffeI3Ac5wgjYYUA4Lbb4OST4frr4eefQ4VDhlgX4dprw9npFiyArVttMPm332D//liZ7DiOU+AktBAUKwaPPWYzjT/7LFTYtKkVTp4Ml1xivYHALXTppSYSnpPIcZwjiKguVVkUaNLEBGHVqlSF118Pe/fC6NHw44/WM2jVCjp1suPJydCgQSzMdRzHKXASukcAloiufn1YvTrdgdtvh9deg40bYfFiOO00qFvXjvk4geM4RxAJ3yMAm0uWpkcQMGRIeDWbs84ieWsZqlGK0i4EjuMcQUS1RyAivUVkhYisEpExEY5XFJH3RGShiCwRkcuiaU9mZCoEAGXKwLBh7Chdg+adyvGv0qO9R+A4zhFF1IRARJKAJ4A+QAtgqIi0SFftWmCpqrYFegF/F5GS0bIpM447DrZts8CgzJg2zdYwWHNUS59L4DjOEUU0ewSdgVWqukZV9wOTgHPT1VGgvIgIUA7YChyMok0ROe4422baKwDefde2m0rW8R6B4zhHFNEUgjpA6hYzOVSWmseB5sB6YDEwSlVT0tVBRIaLyDwRmbdp06YCNzSSEKxbB5ddZmkoDhwI5yXaSE0XAsdxjiiiKQQSoUzT7Z8JLABqA+2Ax0WkQoaTVJ9W1Y6q2rF69eoFbSeNGtmk4iByaPp06NABXngB/vIXW+z+jz+gYkXYeLCyRRL9+WeB2+E4jhMLoikEycAxqfbrYk/+qbkMeFuNVcBPQLMo2hSR0qUtMnTVKli50tJU16wJTz1l+xdfDKVKwXnnwcY95eykX3+FZ56Bb74pbHMdx3EKlGgKwbdAYxFpGBoAHgJMSVfnF+BUABGpCTQF1kTRpkwJIocmTrTewSefwPDhcOWVNoh82mnQsCFs31uKPylpIjB8uCUschzHKcJEbR6Bqh4UkeuAaUAS8B9VXSIiV4eOTwTuB14QkcWYK2m0qm6Olk1Zceyx8PbbsHw5DBgQXsJ4/Hgru/rqcGaJTVSn7kMP2c4XX1jq6mIJPzfPcZwiSlQnlKnqVGBqurKJqd6vB86Ipg055bjjwuGjI0eGyytWtGSkAO+8Y9tNVKeurLcewVNPwbJllsLacRynCOKPsSGCyKEmTaBXr8h1atSw7caGXeCOO+DWW61gzpyo2+c4jhMtPMVEiObNbTtypI0RROKwEIybAJeIZSKtWdOEYMSIwjHUcRyngHEhCNGihbmATjwx8zqHhWBTSClEoEePsO/IcRynCJIj15CIlBWRYqH3TUSkn4iUiK5phU/37pCUlPnxChUsW+nGjelO+vlnn2TmOE6RJadjBLOB0iJSB5iBxf+/EC2j4hUR6xWkmdzcvbttv/gi4wnPPAM33QSbYxII5TiOkyNy6hoSVd0jIlcA/1bVh0Xk+2gaFq9Ur56uR9C2LZQrB+PG2SSzyy6DKlVs/OC++yxB3YsvWoRRo0YmHC3S595zHMeJHTntEYiInAhcCISy7iTm+EKNGumEoHhxeO45OOooiyIaNszKf/rJRGDUKOjYER55xAaUzzjDRMJxHCdOyKkQ3Aj8FXgnNCmsETAzalbFMRmEAOCCC+D77+HGGy1f9c6dMHu2HbvySvj4Y8tN9O9/W69h0aLCNttxHCdTciQEqjpLVfup6t9Cg8abVfWGKNsWl0QUgoBzz4X9+y1r3axZULVq2A1UvDgMHGjvP/qoUGx1HMfJCTmNGvqviFQQkbLAUmCFiNwWXdPikxo1bF373bsjHOzWzaYiv/eeCUHPnmlTT9SubWMKLgSO48QROXUNtVDVHUB/LGVEPeDiaBkVzxyeSxCpV1CiBPTpA//7n40RnHRSxjq9e9sEtJ07o2qn4zhOTsmpEJQIzRvoD7yrqgfIuLZAQhAsh5Cpe+icc2xNS8hcCA4ehE8/jYp9juM4uSWnQvAUsBYoC8wWkfrAjmgZFc9k2SMAa+iTkqBSJfYc2zqjC6lrVws3dfeQ4zhxQo5CQFX1MeCxVEU/i8jJ0TEpvslWCKpUsUHjSpW48JIk/vwTpqbOv1qyJJx6Knz4oYWRZpbYyHEcp5DIkRCISEXgHqBnqGgWcB+wPUp2xS2BayjLpZPfegtVmFPDlirI0N737QvvvmthpG3bRtNcx3GcbMmpa+g/wE7ggtBrB/B8tIyKZ8qUsajQ7PLM/f67ZZbYujWCaJxzjinDu+9GzU7HcZycklMhOFZV71HVNaHXvUCjaBoWz9x2m7l7Pvww8zqLF4ffL1uW7mDNmpbmdPLkaJjnOI6TK3IqBHtFpHuwIyLdgL3RMSn+ufFGW8Bm1CibMByJLIUAbBzh++/hl19s6bNRozz1hOM4MSGnQnA18ISIrBWRtcDjQMKuxFKqFDz2GKxcCRMmRK6zaJE9+Jctm4kQ9O9v21tvtRQVjz0Gc+dGy2THcZxMyWmKiYWq2hZoA7RR1fbAKVG1LM4580xbpnjGjMjHFy+GNm2gWbNMhKBJEzv4v//Z8mhlysALL0TTZMdxnIjkas1iVd0RmmEMcHMU7ClStG4NS5ZkLD94EJYutePNm2ciBADXXGNq8dFHcP758Prrlr/CcRynEMnP4vXZBsCLSG8RWSEiq0RkTITjt4nIgtDrBxE5JCJV8mFTodKyJaxdG55IHLBqFezbZ2188+aWjTpiRonrr4eFCy0H0bBhsGOHDyA7jlPo5EcIshzZFJEk4AmgD9ACGCoiaVZkUdVHVLWdqrbD0lzPUtWt+bCpUGnZ0rZLl6YtDwaKgx4BwPLl2VzspJOgfn149lk4dMjK9u6F1asLzF7HcZxIZCkEIrJTRHZEeO0Eamdz7c7AqlC46X5gEnBuFvWHAq/lyvoYEwhBevfQ4sWWdLR587AQZOoeCihWDK66ynIQHXcc/OUvcPTR0LSpRRalRhW++sqjjBzHKRCyFAJVLa+qFSK8yqtqdrOS6wCpV3RPDpVlQETKAL2BtzI5PlxE5onIvE1ZTuktXI491iKI0gvBokU2FnzUUVanePEcCAHAmDE2TtCwoU1S6NXLegezZqWt9+GHNg/BE9c5jlMA5Mc1lB2RxhAye4Q9B/giM7eQqj6tqh1VtWP1IMdDHJCUZE/86YVgzRoTArDM1I0b51AIkpIslPTTT2HbNptfUKlSeLWzgJmhxeFcCBzHKQCiKQTJwDGp9usC6zOpO4Qi5hYKaNkyoxBs2AC1aoX327SBb7/NgyenWDFb7CZ9Pos5c2ybXiAcx3HyQDSF4FugsYg0FJGSWGM/JX2lUEK7k4AimXinZUtYt84CfsBWqty8Oa0QnHkmrF+fx6WKe/aEFSvC6U737IH58y2L6TffeLip4zj5JmpCoKoHgeuAacAy4I3QwvdXi8jVqaoOAD5W1UiLP8Y96SOHgvY6tRD06WPbDz7Iww169LBt0Av49ls4cAAuv9xU5+uvLcXp229nnu/CcRwnC6LZI0BVp6pqE1U9VlUfDJVNVNWJqeq8oKpDomlHNAmE4IcfbLthg22PPjpc5+ij4fjj061LkFOOP95GnQM3UCAIt91mGUxnzYJnnoHzzrNtZixebL0Jx3GcdERVCBKBhg2tnQ7GCQIhSN0jADjrLEsltGVLLm9QsiSccEJ4nGDOHFOfRo1sLYP33oM777Rjb74ZPu+zz8IN/+7d0KmTiYfjOE46XAjySbFiFiG0cqXt//abbdMLwdlnmwfn44/zcJMePWDBAhOBL78Mu4tOOsnGC7Ztsx7B7NlmwKxZcPLJ4R7CkiXmNnrhBfjjjzwY4DjOkYwLQQFw7LEWMgrhHkGwpGVAp062ulmexgkuvBCqVTMB2LEDuocygvcMLRg3ciSMG2dhSW+/Dffea+Xz5tk2mOq8Zw/85z95MMBxnCMZF4ICoFEjE4KUFHsgr1bNPDqpKVYMTj89j6H/TZvaDf7f/7PG/8wzrfzss+Hhh628ZUvLZvp//2fzDEqWtPUOwISgTBkTkMcfD6ewcBzHwYWgQGjUyDwvGzZknEOQmo4d7fjvv+fhJmXLwl//am6fatWsrFQp8/tXqGADx4MGWYa7mjUtod3y5RZeumiRCcWoUfDTT/D++3n+rI7jHHm4EBQAjUKLdq5ZYw196oih1LRrZ9uFC6NkyODBJgijR0PXrvbkv2iR9Qhat7bFcKpVyzrDqaqNRzzwgK+p7DgJQnb5gpwckFoIfvvNPDSRaNvWtgsWwBlnRMGQli3hxx9t0GLtWiv76COb4damjSU9OvFES1gXsGEDlC4NlSub8QMHhldKq1kT+va11BeO4xyxeI+gAKhf38YAVq+2tjSzHkGVKlCvXth1HxWOO856BQ0aWJ6il16y8tatbduli7mMtm2zQY0TTjCjbrnF3i9caOMIEyaYDyt9egvHcY44XAgKgJIl4ZhjLEhn//7MxwjA3EMLFhSCUSJ2syCcKbUQgM1Inj/f8mM0aQL//KfNWJ49G669Fi65xAaYX3897XV//z3rXBlLlphrKiWlwD+S4zjRwYWggGjUKOxRyUoI2re31EG7CyOhRocOtq1Z02JXweJYixUz99D779v7jz+2ZdUWLbKZzGCD0337wltv2dqbAZdeah8is1nMTz1lkUxRGwhxHKegcSEoIBo1Cs/Vysw1BPaQrhpOSRFV2re3bdAbAChfHlq1MiH44APrIVStah8giEYKGDwYNm0Kr4fwyy8mGpUrw/Dh8NBDGe8ZqOGMGZFtWrfOBq3zFDrlOE40cCEoIIIBY8jeNQSF5B4KhKBNm7TlXbqY73/+fJuLkBl9+ljP4LVQhvCXXjIV+/JLC1W9805r2AP27g1/sOnTI1/z1VctGmnChDx9JMdxCh4XggLi2GPD77MSgvr1oWLFKA8YBzRrBldeactepqZLl3AeoqyE4KijbFbz889bw/7CC7ZqWpMm5v5RTesimjfP3EjHHWdjDUE21O3bw3U++si2Tz9tAyqO48QcF4ICIugRlCkD5cplXi8Ywy0UIUhKsoY68PsHnHiibevWzdhbSM/48SYo/fpZWNRll1l5gwYmIs88E27QA7fQmDHWO5g7F/7+dxujWLzY0mN88YXZ89tvWc9ncByn0HAhKCACIahVyxr7rOjc2YQg9YNyodKkCdSuDQMGZG9s+fK2ZGaJEvb+vPPCx665Jm2DPneu9QbOP98GoZ96CsaOtZ7BP/9p4wYHD8Ijj1jaVncPOU5c4EJQQFSpYpkesnILBZxzjkVqTpsWfbsiUqyY+fIffjhn9Zs0sbTWkyfbmEHAmWdag/7YYxYuOneu9TYqVjS1mzTJYmvPO8/GBl580cSke3dLlDdrVnhFH8dxYoYLQQEhYm1gMBicFV27WqBOTDM4VK9uM4pzSvv2cMopacuKFbM5A198YY3977+H3U6nnWbbhx+GBx8099G771p5iRIWhlqsGPz3v1Zv7VqLWoqZOjpO4uJCUIBMnWoPx9mRlGQh+lOnWs+gSDN8uCXDC9xDgRBcf725hq66yrKn9u1r5b1727ZGDTj1VOs1qNrg8ZYt5jZyHKdQcSEoQIoVy97lHnDuuTbvoMhncBCxJ/477zR3UKtWVl6jholEsdBX7K67bD5Dv37hcwcPtgHor7+2dRJKlbJxhOXLC/9zOE4C40IQI844w9q9IyLBp4hlK/36a0tsF4nOnW3mcurZdgMGWP2rrjK30oQJNqaQ30Hka66B22/P3zWyIiUF3njDJ8U5RwwuBDGibFlzl7/zTtoMDglFlSo24PzDDxbKesklNlHtxRdh1y6rk5JiCfHuuMNmNWe3qE6wJGcwCS4aTJ9uvZn69WHECNi3L+2x1PuOUwSIqhCISG8RWSEiq0RkTCZ1eonIAhFZIiKzomlPvHHllTYx99VXY21JDBk82LZXXGG9g2uvtfkGQdbUmTPhH/+wldfOPNMEISu++srmMCQnR++JffVq2/bvb2Mbb7xh+4sX2zJ0t90Wnfs6TpSImhCISBLwBNAHaAEMFZEW6epUAiYA/VS1JTAoWvbEI+eea8E499+fwL2CQYPgnnvghhtsv0sXS4z36KPWG3jmGctttGmTRSZNmBBO6hSJ1Kkt5s+Pjs0//WR+vVdesVDZL76w8tmzbTthQiHlEHGcgiGaPYLOwCpVXaOq+4FJwLnp6vwFeFtVfwFQ1Y1RtCfuELF15levtiUAnnrK1qBPqAzOpUvbh65SxfZF4OabYeVKc/G8/baFmlarZr2BXbvCaS2+/dYmtKVmxgxboEfEUl5Eg7VrzS1UvLjFAgdC8MUXNkhetSpcd51FQzlOESCaK5TVAVJlJCMZOCFdnSZACRH5DCgP/EtVX0p/IREZDgwHqFevXlSMjRV9+9paxjfdFC6rUiX8gJyQnHeeLfAwcqTF1151lZV36GC5joIJbH/9q6W/mDfPcnvs2AHffBNeDyGaQtCggb3v1g0+/NAW+pkzB04+2SIBrrjCQmoHDIiODY5TgESzRxApkDL9I1Jx4HjgbOBM4C4RaZLhJNWnVbWjqnasHuTVP0IQsQfcO+6wdqtPH2vfAjd0QlKihCnh/v3W0LZI5VG85Rbz/48ZAyedZKGmgYrOnm2DyaeeaupaWEIANh9i3TqbNX3JJRb9lHpJUMeJY6LZI0gGjkm1XxdYH6HOZlXdDewWkdlAW+DHKNoVd7RrF56R/PTT5tm44gr49NNwGH7CcdVV5oMfky7G4Kyz4IILTBzuussU9G9/s3GElSvN1dS1qw3cvvwyrF9veZUKit27bbwiEILOnc1FNH687XfvbvuNG/t8CKfooKpReWEiswZoCJQEFgIt09VpDswI1S0D/AC0yuq6xx9/vB7pPPusKqg+84ztT5+uetppqhs3xtauuGT/ftXeve0PBqpnnGHlc+bY/pQpmZ/74ouq/fqp/vlnzu+3ZIld97//DZd16mRl5curHjxoZeedp9qkSe4/j+NECWCeZtKuRu15U1UPAtcB04BlwBuqukRErhaRq0N1lgEfAYuAb4BnVbUw1u6Kay6/HHr0sDlR335rD8DTp8OTT+buOikpFpCzYkV07IwLSpQwH/3WrRZq+sILVt6unXWnMnMPHToEd98NU6bkLq3F2rW2DXoEEHYPde1q+UPAxi5Wr/Y1F5wiQVQdD6o6VVWbqOqxqvpgqGyiqk5MVecRVW2hqq1U9dFo2lNUEIGJEy1ApmtXa7M6dzYhyE27snQp3Hdf5ssLH1FUrmwDyUH617JloXnzzP30H34IP/9s+cPvuy/nbpyshKB793BZs2b2j0vowR6nqJCoHui4p0ULc48fOmSu7vvus0jJYO5STgiiGqMVTh/39OsHn3wCP0YYcnriCRs7mDXLROOKK8IrqmXF2rU2h6BmzXDZaafZKH8wOQ5MCCDv4wSq2c+idpwCwoUgjrn3XgtEOecci0hs1szmWeU0PH3OHNvOn59gcxMCRo2yRjv9ugurVtmSmcOHW2qLJ56wdZgvuMC6XHv2wC+/RL5mMIcg9Sh+pUqWSrZx43BZ06a2zasQnH++zVL2uQhOIeBCEMeIQJ064fejRlmj/s9/5uz8OXMsinHnTmv7Eo6aNe1J/6WXzEXz6KMWWtqtWzjZHcDQoSYGU6bY0p1Vq9oi1EuWZLxm6tDRrChf3v55eRGCXbvg/fdtzCNYryHgxRdt1TfHKUBcCIoQV1xhc61uuQUeesjapG3bItf99Vc7Hqxbn7Duodtus6fqli1tvsG2bZaz6I030oaVXnONiUFSkglEmTKRG9ycCgFYFy4vQjBzpvVMqla1iIEgAd/MmfYleOghmzwHtobD11/n/h5gLjPvcTgQvfDRaL0SIXw0K/bvVx00KBwtmZSk+sorGeu9/rod//JL1dKlVW++OeN1UlIKx+aYc+utqp07q06blvNz7r8//AcM2LXLyv7f/8vZNa67TrVCBftD/+9/qrNnZ/5H37MnHMZ69dWq5cqpfvaZ3W/QINVXX1WtXl21YkUrmzrV6l51lWrJkqq7d+f8s6mq/uc/dp1nn83deU6RhSzCR2PesOf2lehCoKp64IDqu++qPv+8arduqkcdpbpgQdo611+vWqaMNfgnnKB60knhY1u2qNavb2Xr1xee3UWKnTtVa9ZU7dpVdeFC1b17Vb/+OuMcgqx4/HGrf999YeU+9lj756WnSxebA5GSYv+cc8+18htvVBWxcytUUP3uO9USJVRvv1310CGzEVRnzsz5Z9u2zUQFVGvVMoErCmzbpjpmjImmk2tcCI5gfvtNtU4d1YYNVX/4IVzevr3qKafY+2uvtblOhw7Z/kUXqRYvbkJRs6bq3LmFb3eR4Jlnwg146tfXX+fs/OnTw+ecfrpNYGvb1rpxb74ZrvfHH+HG/rbbbDtxYvj47t12z19/tf1u3UzdA2EC68Goqm7dqvr++1nbNWqU3S8QquDcaDFnjuo77+T/OkEvJvXfzskxLgRHOHPnqpYta//Nnj3tJaJ69912PPj9LF9uD6Ngx374QbVRI9V69ewB2InA8uXWA7j/ftV//lP1jTdy7lNLTrY/dqNG1g1TVd2xw3oZSUlh984nn1i9GjXCDfvPP2d+3bFj7fwbb1QtVsz+gb1727GbbrLzlyzJ/PMkJamOGGH7AwaYG2r4cHMzLV2as8+WG7p3t25r8DfIK8FnGzWqQMxKNFwIEoBNm8x13aqV/e4uvzzclixaZP/pVq1svKBNm7A7+osv7NjNN6vu26f6wAPW1qUmJcXE5ttv829nSorqsmX5v06R4V//Uv3xx7RlO3aYi+jkk20/GI/46ivz97dsmfU1g55GyZKqPXpYo16hgvkBa9WyY2PHRj73llusO/jbb7a/YoV1KWvWtKeJqlVz3uPJCQcOWNcTVB9+OH/XOvVUu0779gVjW4LhQpDgHDig2rSpavPmNn75009pj48YYQ+WzZvbN6JaNRMFVXtobdnSyo86Kq37KS+8/LJda/r0/F0nFuzebZ2CAwcK4GJjxliDvG2b6tlnq7ZoYeXvvac6a1b2hpQoEW5cX3rJ3j/6qB7OeXTssRl7Lvv3W69jwIDI1121ynyMZcuqfvihlR08qDppUtgtlZqUFDvWqJFq48aqDz1krqnUBE8hpUtbz+XAARu879Mn7KvMCSkp9sUsVsy6u3/8kfNzHVV1IXCyYds2e5CsWVN19Gj7VkyapLp9u2qVKvYbf/xxa0Natsx9gErAoUNhsRkypEA/QqEwaZLZPmNGAVwsSIo3aZI9hV9+ee7O797dzl+2THXNGntfsaK5eQLf/zff2H0GDbKogMAvGGmwOmD9ehvHKFbMeirBfZo2Vd28OVzvwAHVs86yY+3aWc8EwgNTAc89Z+UPPWTboF5uff0bNtg5556raaKmnBzjQuBky8aN1vAfOqTaoIF5LYJgl8AlNG2a7V91Vd7u8c47dn7jxqqlSmV8eIx3Hn7Y7J8woQAudvCgCUCXLnbRp5/O3fnPP28ZTlNS7BW4hC66yJS9ZEnraVSoYOUdOtg4Qo0a1jPIip07ww1uhQo2oFSqlI1tBBE7d9xhx8ePD2dcDRr7hQvD1xoxwgRq/36LhgILaWvc2GyKNN7yzTeqI0emFZ7gy/fBB9aTGjMmd38vx4XAyR0PPmjfjLJlw1GMAbffbscCz0FOSUmxUP5Gjex3XmANaiFy/fVasGOVF18cfjpetCh/1woml3zwge3372/7xxyj+tRT9oQPNkaQEw4dskHyYKDpjTfMJdO4sepdd9n7K65Ie86WLeY/vPLKcFmHDubbV7XG/JFH7MsQ9BQ++MC+TE8/bV3NH380gQx6IWvW2LmPPGJlmzebeHbtmve/VYLiQuDkivXr7aEr/cOdqoXTN2+uWrdu7ty0wfjmk09aO9CmjaXxL0oEbWsQoJNv3nhDD/v0g6fqvDJ5smqvXuGn/Vmz7A8cjMxPnGgN7PLleb/H1KmqrVubzS1aRPYRXnllOEJo797Mn97//NNEKhAosC9Vw4Y2FvDSS6qVK6sefbTq77+baNapY+fefruNkURzPsGWLWl7JEcALgROrrnlFotOjMRXX9nvd+BAm8iWXTRlSoq5hmvXtrZB1QZdIf+Dz4XJ8cebzQ0bFtAF//jDGsrgiTna5FdsVK2nMHWq6rp1kY8vXKiHxwS++srev/VW5LpvvWXuq0mTVD/91HoPRx0Vns29YIH9fa6+2sYh+vSx8qlT7brXXpt25H7fPouGWLky959r376wiKakWGRSx465v04c40LgFDj33ht+kGvYUPXvf8+8hzBjhtX797/DZRs32m88p56KeCAI8xcJC1q+eeKJohlClYoNG9L9708/3f65p51mf7BffsnZhQ4dyvgluuEGe+ooXtwiGYJ6wZyC008PT4L573+trH//3H2AlBRr9Hv3tvfvvx/+cn//fdq669dnnMZfRHAhcKLChg3m6u3Z075JNWtaWWqC3kCdOhkbzwEDcjZ2GQ/s26eHPSIF4dI/kmjfXvWyy1IVbN9uT+/BlyI/Sa02b1atVMmu9eqraY8Fa7qOG2f7wTwDyF1j/eWX4fOee071xBPNTVWyZMZu8eDBlp6jCCbqciFwos6cORZYMnBg2t/IRx/Zt+zxxzOeM2WKZhvNGC+sWqWHB4rBcsg5RsWKNn6bhoMHrduYuhuYVwI/4ooVGY8NGGAGfPedHp4ZWbGifRHfeMOiqZo3t5H+YNb0li2qQ4dao6+qOmyYhd127WrzHcB6auefb+MVwezLlJRwbqfANbZnj+ratfn/jIWAC4FTKATRg8HM5N27LUrouOMiu1IOHLDfVf/+5hF45RWLfIxHZs60zxaI1wMPxNqi+ODPP+3vEYzjRoWUlIyzswO+/94MqF3bfHa//GLhrsET/vHHm8vnqKPsSWXsWPtCgg04f/qpHRs+3ISmdGn7Uu7dG3YRTZ5s91q5MnzdIDrrzjttsD+vk2tSE+Vkei4ETqFw4IAFqlSubGJw6632Dfvss8zPufVWS31TvrzVPe441cWLC8/m1Myfb67nSGOqL75o9v34o3kNLr648O2LR379VQ+Pm8TMxTdggKYJ59q61ZLy3XVX2KjffgvXq17dZnDXqWPun9STZT77LJxiI3hSCWKog6RdEE5F3rWr7X/0Uf4+w7JlFq/9t7/l7zpZ4ELgFBorV5rPOPi9ZDf57McfbZxg6FDrERx9tP0eCjLdTU4ZONBsfumljMceeMCO7dljrujOnQvfvnhkwYLw/zp96pJCY+FCe6oPntIzIyXFEvwlJ9v+jBmmYO3bZ+7zv/12e1JJTraBkCpVLFXGkCE2cBQISfoFP3LLyJF2nWLFrJcSBWImBEBvYAWwChgT4XgvYDuwIPS6O7truhDEPwcOmFv37LNz7+r59Vd7CDvjjGhYljl//GGegyAKKnALB4wYYe5iVdVrrgmvN5PoBIlTIfsUSVEl/T8sp0yZknUXNBgcGjfOJtP162ev5s0tEyOYCLVqlbf7q9qPpEwZ1QsusOvWqBGeSFeAZCUEUVuqUkSSgCeAPkALYKiItIhQ9XNVbRd63Rcte5zCo3hxuPFGW3a3UqXcnVu7tp378cewYEHB25YZ77wDf/4J99wDP/0Ezz6b9vi6dXDMMfa+aVNbKfL33wvPvnhl06bw+3XrYmcHJUvm7bxzzoFWrTI/fuyxcMYZ8PjjsHIl9Ohh61qvWGFLhwKMHAk//ADr14fPW7XK1pTdvTvt9T7/3JYgXbw4XPb887BnD4wZA2++Cfv2Qbt2tj61PTBHnWiuWdwZWKWqa1R1PzAJODeK93OOEK6+2tZ+f/hhW7r3f/+Dt9+2305KSnTu+dpr0LChCUGPHnD//bYccEBqIWjZ0raffRYdW4oSqYXgl19iZ0dUGTkSNm+29z16QNu29kV87jmoXx8uucSOffJJ+JzbboN//MOeagIOHYIbboCtW+Gxx8Jljz8O3bpB+/bQogUsXGj3GDbMxKAwyKyrkN8XcD7wbKr9i4HH09XpBWwBFgIfAi0zudZwYB4wr169egXeZXLij1tvNXfpMceEXQ9gWRSCVPr55csvLcDks8/MDXzHHVY+b565iU46KexxqFTJJrKq2mByy5Y2sF0U5kBEk7Fj7f9UubJNAD4iOXDABpaPOsq+ECtWhL+QQ4eGlwz9y1+s/rJlNvbQsKHVmTTJyp9/Xg9HRJQpY/7IYAA6/SIgBw/a+X37FtjHIBZjBMCgCELw73R1KgDlQu/PAlZmd10fI0gMkpPND9+li2UUmD/f0u2XLm2RgunH01JSLGPB3/5mET7ZhXbPn2+h46lFJrWr+JVXrOzKK20dmSBrQkAQWRhpfkQiMWKEBeG0a2djQkcsb71lA1+q1kgHi+089piVXXSRDSSvWWPJ+EqXtgGvLl0s+uHCC21OwwknWIQS2DyLatUs8ijS2gxXX21f0ryOf6QjVkJwIjAt1f5fgb9mc85aoFpWdVwIEoc//8w4ILtgQTgM/KKLLL5/7txwavzgVaGCDWRu22bLAA8ebA9mS5faBLYaNSz44/vvTWAefDDj/e+8064VZEpIvWZ9Sor1TqpXzzibOpEYONBmW/frZ/noEobOne1LMW+e7c+daxPZKlSwSKJrrrHyX36xXkPNmtbt/OILK+/Y0c5PSsqY2THg7bc1zSj8Qw/la5nAWAlBcWAN0BAoGXL/tExX52hAQu87A78E+5m9XAic3butkQ4W6QoCNx591Hrb339vjVLx4vbAJWINdmqhqFYt+yUzU1IsWCQ45/PP0x6fN89+8xUqWE9k5kwTqtwsvFXU6dHDXGjXXWftYMIwcqRNfkntG1yzxp74S5VSXb06bf2UlLR5lIL0GDfdlPk9tm0zv9vYseGZ03fdlWeTsxKCoBGOCiJyFvAokAT8R1UfFJGrAVR1oohcB4wEDgJ7gZtV9cusrtmxY0edN29e1Gx2ig6//mrBG3/8Accfb+N2ATt2wMUXw7Zt8M9/WhDGF1/YgGaDBtC6NVSsmLP7vPIKPPooTJ+eMQpqxQq4+WaYOjVc1r8/vPwylCuXn09XNGje3IJuOnWC0aNh+3aoUCHWVhUCmzfbF7Bt27TlBw/asaOPzvr8/fstWuiii6Bs2czrde1qA8rVq8OXX1pIW06/uOkQkfmq2jHisWgKQTRwIXDikR9+gI0b4auv4K67rHF89llrIOOJDRvMvvHjcx/aG4lq1eCCC6BnTxg61P4OQVSVUwCMGwf33mvv/+//LMQ0j2QlBNEMH3WchKFVKzjlFLjjDusdrFsHnTvDiSemDRmPNQ88YFGP//tf/q918KCF2FavDvXqWdkRG0IaK04/3bY1a8L110ftNi4EjlPAnHkmrF1roeJr19qcpa1bC/YequYxyA0bNpgIgE32y4wvvrDJddkRzLNILwR799r8KKcAOOEEez38cNYupHziQuA4UaBCBXuAmzLFGuCLLirYyXBjx5pr58YbTWxywj/+AQcOQJ8+Nt6xb1/GOvPmQffu5oXIjmAyWfXqUKsWJCXBW2/ZxLyzz87hB3Gypnhx8zcGk9aihAuB40SRTp3gX/+CDz8019HkydYY54fdu+GJJ6BKFdu2bx+e+JoZP/4ITz4JQ4bY5NY9e2xmtCp8+224dzFxYni7f3/W10wtBElJUKeOTa7dt8+u/dVX+fmUTmFSPNYGOM6RzogR1qiOHw8DBkCZMhYMUrmyRTeVK2eRTGXLmkumeXMbgD3qqMjXmzTJonPee896Hh062BP83/+ese6qVdZrmDoVSpeGO++ERo3Mhvffh++/t3GNO++0rAivvWb3X7bMxhEuvDDzz5VaCCCciWH0aGjc2Hogb7yRn7+cU1h41JDjFBIHD1qD/MknMGeOPTlXqGBisHat7RcvbvWqVIG+fa3RPnTIonGOOcYa/J49re7ixSACl18O//2vhbK+/LI1vrfcYvnS+vcPp7gZMcKS+oGVz5wJO3eaIG3fDpddZpFOX39trqyqVWHu3Mw/zxNPwHXXwW+/2VhmakaPNuFbvdpEzok9WUUNRW1CWbRePqHMORJJSQm/Zs60VRLr1LHJcMWK2WxqEcuEnD61xc8/28S2qlX18GphwSS4446LvLjXM8/Y8Q4dbD322rVtP0jN/69/2f7s2ZnbfM89VufAgYzH1q2zCX3pl/x1YgexSEPtOE7OEQm/evUyt0xysvnyd++2DMhTptjTd9myNlkuoF49e+Lfvt0SWf7yi7mPRoywJ/rGjTPeb9AguOYaePddG+h95hkrv+Yas2HYMOs99O5tvYxIbNpkPZfiERzMdevCeedZ8sycRCA5scVdQ45ThFi71mZLt2+ftjwlxUJUq1XL+7XXrLGIHxHb37DBJonNmgWjRpnPv1iqR8cLLoBFi2D58sjXmzbNhOTNN00UCgLVsH1O7vAJZY5zhNCgQUYRAGug8yMCYOMRqRvZWrUszHTUKIt8Gjo07dP9pk3hgeJInHaa9SqClPpbtpjY5JWvvrLxjO++s/2NG20wOzk579d0DBcCx3EypXhxy9X0yCM2CD1gQFgMNm7MWgiSkmzQ+cMPba2VTp0s51N2K5lt3WqD6umdFS+9ZO6v226zY2PG2CD5k0/m6yM6uBA4jpMNInDrrfDUU9aoDxpkbqGlS7PPK3TppRYFdeKJJhyHDtnYRWYe6WXLTDDOPtvODUQnJcWWE61YET791FaQe/55W6HylVeit3JdflG13HRxT2ajyPH68qghx4kdjz9ukUIlS9oaDjlZoa1TJ0sZ/vHH4Wik4cMtVfjRR9tCQrt3q06YYCm9a9Sw1eDAUlzv2WNp/MEW+WrUyN7XqqX61FP2fubMKH/wPDJpkkV9zZ8fa0uyjhqKecOe25cLgePElmnTVJcvz3n9n36ydPqqtlZDt27hUNUTTrD3pUvb9sQTw6vLvfyyHk7Zf8stJj7bt9uqjqD66qsmIOXLq152WYF/zCx5+WVbGOngwazrDR1qtl54YeHYlRVZCYFHDTmOU6hs22Yhrm3amOvk2WdtIHjYMFsbPvWA9bXX2hhAxYo2G/uDD6z8t9/CKf+vuMLGL/79b3MttW0LZ50VTrO9apWdd9ZZkUNpc0tyMjRrZmG9zz1nE/oikZJiE+3++MP21661NByxwieUOY5TJNm1K7w06bPPRq4za5YenkBXrFh4W7266jHHhI/VqpVx4bC8cP75tiJe69Z2zZ07I9cLlia+/36zZ8yY/N87P5BFj8BzDTmOE7eULWuRQWPHwsCBkev07GnpMqpXhyZNYP58+Ogj6zXs2mWr17VuDYMHW3r/J56wsNYWLSJPhotEcrKlBlm1yuZFPPigTfzr1s3ejxsHpUqlPWfaNNsOH25RUxMnWv6oevUsw+uxx+ZsTsTSpfbZsorQyi/uGnIcJyH45hs49VQTB7A0/1OmQI0aWZ/3ww923saNtt+5M8yebQ3/BRfYLPBixUxYLrrIMkbXqmUCtWuXzXtYtMjyO/30U/i6tWqZMKSkwHHHmasseDVvHo7Wevxxi44aMsTmdHTokLfPn5VryHsEjuMkBJ0724S25cstYd+tt0KXLuHVHw8dslexYlCihL0OHbLjJUqYkDRtCuXLh5/kX3zRGvjly61XMmYM3H23Jf2bO9fuAda4r1lj4bCrV1ua7q+/NhFQtYSBEyaE14hISrLJc5s327oWqvDCC5Z4MK9CkBXeI3AcJyH55hvo1w9+/z3renXqWCOfk4HmH380N9Frr9n+zJnmQsoJhw6Z62nhQutBrFplM6fPOceO79hhwpHXtaZ98XrHcZwI7N1rqTKSksKvlBRbPCh41a1r6zfkho8/thxN996b83GIaBMz15CI9Ab+BSQBz6rqQ5nU6wR8BQxW1TejaZPjOE5AMHhb0Jxxhr2KClFLMSEiScATQB+gBTBURFpkUu9vwLRo2eI4juNkTjRzDXUGVqnqGlXdD0wCzo1Q73rgLWBjFG1xHMdxMiGaQlAHSJ1nMDlUdhgRqQMMACZmdSERGS4i80Rk3qZgoVTHcRynQIimEESaKpF+ZPpRYLSqHsrqQqr6tKp2VNWO1aM5q8JxHCcBieZgcTJwTKr9usD6dHU6ApPEgnKrAWeJyEFVnRxFuxzHcZxURFMIvgUai0hD4FdgCPCX1BVUtWHwXkReAN53EXAcxylcoiYEqnpQRK7DooGSgP+o6hIRuTp0PMtxAcdxHKdwiOo8AlWdCkxNVxZRAFR1WDRtcRzHcSJT5GYWi8gm4OdcnlYN2BwFcwoSt7FgcBsLBrcx/8SbffVVNWK0TZETgrwgIvMym1odL7iNBYPbWDC4jfkn3u1LjS9e7ziOk+C4EDiO4yQ4iSIET8fagBzgNhYMbmPB4Dbmn3i37zAJMUbgOI7jZE6i9Agcx3GcTHAhcBzHSXCOeCEQkd4iskJEVonImFjbAyAix4jITBFZJiJLRGRUqLyKiHwiIitD28oxtjNJRL4Xkffj1L5KIvKmiCwP/S1PjEMbbwr9j38QkddEpHSsbRSR/4jIRhH5IVVZpjaJyF9Dv58VInJmDG18JPS/XiQi74hIpXizMdWxW0VERaRaLG3MKUe0EOR0cZwYcBC4RVWbA12Aa0N2jQFmqGpjYEZoP5aMApal2o83+/4FfKSqzYC2mK1xY2MozfoNQEdVbYWlWhkSBza+APROVxbRptD3cgjQMnTOhNDvKhY2fgK0UtU2wI/AX+PQRkTkGOB04JdUZbGyMUcc0UJAzhfHKVRUdYOqfhd6vxNrwOpgtr0YqvYi0D8mBgIiUhc4G3g2VXE82VcB6Ak8B6Cq+1X1D+LIxhDFgaNEpDhQBsvAG1MbVXU2sDVdcWY2nQtMUtU/VfUnYBX2uyp0G1X1Y1U9GNr9CstoHFc2hvgncDtp0+7HxMaccqQLQbaL48QaEWkAtAe+Bmqq6gYwsQBqxNC0R7Evc0qqsniyrxGwCXg+5L56VkTKxpONqvorMB57MtwAbFfVj+PJxlRkZlO8/oYuBz4MvY8bG0WkH/Crqi5MdyhubIzEkS4EOVkcJ2aISDlsmc4bVXVHrO0JEJG+wEZVnR9rW7KgONABeFJV2wO7ib2rKg0hP/u5QEOgNlBWRC6KrVW5Ju5+QyJyJ+ZefTUoilCt0G0UkTLAncDdkQ5HKIubtuhIF4KcLI4TE0SkBCYCr6rq26Hi30WkVuh4LWK3jnM3oJ+IrMXcaaeIyCtxZB/Y/zZZVb8O7b+JCUM82Xga8JOqblLVA8DbQNc4szEgM5vi6jckIpcCfYELNTwJKl5sPBYT/YWh305d4DsROZr4sTEiR7oQHF4cR0RKYoM1U2JsEyIimG97mar+I9WhKcClofeXAu8Wtm0AqvpXVa2rqg2wv9mnqnpRvNgHoKq/AetEpGmo6FRgKXFkI+YS6iIiZUL/81Ox8aB4sjEgM5umAENEpJTYIlONgW9iYB8i0hsYDfRT1T2pDsWFjaq6WFVrqGqD0G8nGegQ+q7GhY2ZoqpH9As4C4swWA3cGWt7QjZ1x7qFi4AFoddZQFUsYmNlaFslDmztha0cR7zZB7QD5oX+jpOBynFo473AcuAH4GWgVKxtBF7DxiwOYI3VFVnZhLk7VgMrgD4xtHEV5mcPfjMT483GdMfXAtViaWNOX55iwnEcJ8E50l1DjuM4Tja4EDiO4yQ4LgSO4zgJjguB4zhOguNC4DiOk+C4EDhOlBGRXkEGV8eJR1wIHMdxEhwXAscJISIXicg3IrJARJ4KrcewS0T+LiLficgMEakeqttORL5KlRu/cqj8OBGZLiILQ+ccG7p8OQmvnfBqaKYxIvKQiCwNXWd8jD66k+C4EDgOICLNgcFAN1VtBxwCLgTKAt+pagdgFnBP6JSXgNFqufEXpyp/FXhCVdtieYU2hMrbAzdi62I0ArqJSBVgANAydJ0HovkZHSczXAgcxzgVOB74VkQWhPYbYWm4Xw/VeQXoLiIVgUqqOitU/iLQU0TKA3VU9R0AVd2n4Zw436hqsqqmYOkRGgA7gH3AsyIyEEidP8dxCg0XAscxBHhRVduFXk1VdVyEelnlZImUajjgz1TvDwHF1RZZ6Yxloe0PfJQ7kx2nYHAhcBxjBnC+iNSAw2v41sd+I+eH6vwFmKOq24FtItIjVH4xMEttTYlkEekfukapUI76iITWo6ioqlMxt1G7Av9UjpMDisfaAMeJB1R1qYiMBT4WkWJYRslrsQVvWorIfGA7No4Alqp5YqihXwNcFiq/GHhKRO4LXWNQFrctD7wrIqWx3sRNBfyxHCdHePZRx8kCEdmlquVibYfjRBN3DTmO4yQ43iNwHMdJcLxH4DiOk+C4EDiO4yQ4LgSO4zgJjguB4zhOguNC4DiOk+D8f7gRpMj46M8NAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=np.arange(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Acc plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291b341c0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABXfUlEQVR4nO2dd3iUVfbHvycBEnoLPSihSECFAAERUFBUUJRiBRGxrIiCddUVK666P1ddyy4iootiRWyALkpRARWRhN57ICH0mmASUs7vjzM37zsz75SEmdTzeZ55Zt5+33dm7veec+49l5gZiqIoiuJJRGkXQFEURSmbqEAoiqIojqhAKIqiKI6oQCiKoiiOqEAoiqIojqhAKIqiKI6oQCiKoiiOqEAoSoggokVEdIyIokq7LIoSClQgFCUEEFErABcBYACDS7c0ihIaVCAUJTTcCmAZgA8AjDYriaglEX1NRIeI6AgRTbJtu4uINhFRBhFtJKKuJV9sRfFNldIugKJUEG4F8BqAPwAsI6ImAA4D+A7ATwBGAcgHkAgARHQDgIkAhgJIBtAGQG5JF1pR/EGai0lRzgwi6gPgZwDNmPkwEW0G8A7EopjjWp/nccw8AHOZ+c0SL7CiBIlaEIpy5owGMJ+ZD7uWP3Wt2wtgt6c4uGgJYEcJlU9RioUKhKKcAURUHcCNACKJaL9rdRSAegAOADiLiKo4iEQqxK2kKGUWDVIrypkxFBJb6AggwfXqAOAX17Z9AF4ioppEFE1EvV3HvQfgESLqRkJbIjq7hMuuKH5RgVCUM2M0gPeZeQ8z7zcvAJMAjABwDYC2APYASANwEwAw8xcAXoS4ozIAzALQoOSLryi+0SC1oiiK4ohaEIqiKIojKhCKoiiKIyoQiqIoiiMqEIqiKIojFWocRExMDLdq1aq0i6EoilJuWLFixWFmbuS0rUIJRKtWrZCcnFzaxVAURSk3ENFuX9vUxaQoiqI4ogKhKIqiOKICoSiKojiiAqEoiqI4ogKhKIqiOKICoSiKojiiAqEoiqI4UqHGQShKRefYMeCdd4A//wTq1QMeeACIjCztUikVlbAKBBENBPAmgEgA7zHzSx7b6wL4GMBZrrK8yszvu7alQPLk5wPIY+bEcJZVUcoDY8YAX35pLbdvDwwaVHrlUSo2YXMxEVEkgLcAXAmZbWsEEXX02G0cgI3M3BlAPwD/IqJqtu2XMHOCioOiAHPniji88AKQnQ3UqgXMnl3apVIqMuGMQfQAsJ2ZdzLzaQAzAAzx2IcB1CYiAlALwFEAThO8K0pA8vKAP/4Afv8d2LevtEsTWk6dAu69F+jQAXj0USAqCrjySmDOHKCgoGjn2rlTntHy5UB+fuD9jx0DTpwoXrnPlNTUot9feeXgQXEdliXCKRAtIBOzG9Jc6+xMgszfmw5gHYAHmNn8HBjAfCJaQURjfF2EiMYQUTIRJR86dCh0pVfKHTfdBPTsCfTqBbRrJxVhReHvfwd27wamTAGquWzsoUOBAwdEFIPlyBGgY0d5RhdcANx5p//9s7Jkv5tvLnbRi82WLUBcHPD11yV/7ZImPx/o1g24//7SLok74RQIcljnOb/pAACrATSHTPY+iYjquLb1ZuauEBfVOCK62OkizDyVmROZObFRI8eEhEolYPZsqUgefhiYNQuIiJAWd0WYUXfdOuC114A77gAutv0LrroKqFKlaG6m//0PyMkBpk4Fxo4Fpk8HfvrJ9/7/+AewbRvw668l35L/+mupOFesKNnrlga//w6kpck95+aWdmkswikQaQBa2pZjIZaCndsBfM3CdgC7AMQDADOnu94PAvgG4rJSFC8yM4H77gPOPx946SVgyBDx08+bB8ycWdqlOzMKCoC775YeSy+/7L6tXj2gXz8RxGCZNQto0QL4y19EdNq0EaHIzvbed9Mm4J//BJo2BU6eBLZuLfZtFAtzX5s3l+x1SwNzr8eOAb/8UqpFcSOcApEEoB0RxbkCz8MBzPHYZw+A/gBARE0AtAewk4hqElFt1/qaAK4AsD6MZVXKERMmAHXrWq8mTcRX/c47QNWqss+4cWKyP/SQxCbCQUEB0L8/MGNG8c/xwgvANdf4LuN770nr8tVXgYYNvbcPHSqumJUrnY8/eVKE87vvxL/9ww8ioERA9erA22+LhfDvf1vHXHutPNcuXSQQ/sknsj4pqfj3GQzr1gFduwLLlgHp6RIjASyByMkBEhOBTz8NbzlCyd69QPfu8vx9wSwCcdFFQHR0Get4wMxhewG4CsBWADsAPOlaNxbAWNfn5gDmQ+IP6wHc4lrfGsAa12uDOTbQq1u3bqxUbE6fZq5fn7lbN+YHH7Ren3/uve/HHzMDzGvWhKcsS5fK+e+5p3jHL1/OTCTneP117+379zPXq8fcrx9zQYHzOY4cYY6JYb7wQub8fO/tP/wg52/WjPmjj+Tz/Pnu+/TuzZyQIJ/37JF9Lr9cnuvSpcy5ucw1ajDfd1/x7jMY8vOZe/aUa597LvObb8rnwYOZq1aV7/2PP2RdvXrybMoD114rZW7alPnYMed91q+Xfd5+W+73rLN8f9/hAEAy+6rDfW0ojy8ViIrPjz/Kr/brrwPvu2WL7Pvee+Epy9/+Jue/4YaiH5uby9yli1Tcl13GXKsWc2qq+z4338xcrRrz5s3+zzV9upRjyhTvbc8/L9uImKtXZ65blzknx32fV16RfVJSmP/zH/nsec2LLpIKPFy8/bZc99Zb5b16dea2bZk/+ECWt2xhnjRJPkdGMo8cGb6yhIpvv5XyjhzJHBHBfO+9zvu98ILst3cv83//K59Xriy5cqpAKPzpp8w33iivjz4K33WOHZM/grmW/TVqlHNl9+qr0jr0ZPp05v/9z33dffcxR0czZ2YGLkt+vlSId98tyzt2MD/yCHN2dlHvypn27eUfdMklRT/29dfl2JkzmXftkgrxvPOsZzV0qGx/5pnA5yookDLUqSPH3nqr1cIePFjKOX68nO/mm72P37pVtr35JnP//szx8d77PPywPPfTp723/fijVe6XXvJu/e7YwTxxorOFw8x84IB8T5deKseaVvcjj1hWw+zZzKNHMzduzPz007JuwYLAz6a4rF4t1/FV5kD8+adYAh07iiDff7+I9HXXMY8Y4W7Vdu/OfMEF8vngQRGTbt3c/ztffHHm9+QLFYhKztq1zFWqSGu1dm3m888P37Xuukt+4PHx3q+aNZm7dpXWs2H3bvkVjh7tfa5mzdwrq4IC+dMNHhx8efr3l2syi8sEkMrqTNm0iQtb5kV9nnv2iMVw5ZVWZfrhh1KZ2J/XsGHMWVnBnXPrVuZeveQ4QCpqZnmGt9zCfOKEXO+XX5yP79hRnlOVKsyPP+69/bPP2GfLtndvuZ9WrSzRs/Paa7J+3Trna//737J97VpZTkuT723jRubjx2XbP/8pZRw0SJ5Ju3ZiYQT7fIrK3XezT6ssGL75Ro6fO1eWT5xgvuoq+X4iI5kfekjWZ2fL/+XJJ61jx41z/x00bRqcJVlcVCAqMfn54p9u2JD50CHmO+5gbt48PNf69Vf5RT38sPP2GTNk+xtvWOtM5eDpvjhxQtbb3R0rV8ryf/8bfJkef1wqvawsqwKrVk1cFmfC//2fnGvAAKmEi8LQoWIx7Nx5ZmXwRbdu8jzT0rjQMgjEE09Yz/v33723b98u2955x339/v0ikhMnurvNjh+39vnHP+TYadOcr33ppcwdOvguW9Om4sYz12EW6wGQVn446NqVzyjeMXq0xMqcLK7OnUUsmJk3bJDrfPKJ73MFE4s6E1Qgyjh5eRI49GXOFhQwL1zIfOpU0c/9zjvyLb//viw/9phUkOaHtnev75Yds1TUS5YEvs7p0+IiadmSOSPDeZ+CAuaBA9397Zdeav0R7T/+5cutCuuf/5R1zzwjra2DBwOXx/DVV1bFBohPvm5dafVOm2a9Zs50fv4//+zts2eWCrhbNxGgqlWtsicluZ932jSxGAyzZ7NbCz8cPP+8VKbGr790aeBjjCunaVPn51BQwNygAfOdd7qvf+89OW71allOSpLvaPx4a59nn2WfwfyjR6VFPWGC77L16yfuLcDd5XjLLfLsN20KfH9FIStLGhXDhsn5ndxy/sjNlQbZqFHO22+6ibl1a/lsfp8rVvg/55Qpst/06UUrSzCoQJRxFi5knz1ZmCUgC0irtaicfz5zjx5WBfbyy3KukydlefRo+THb3T52rr02uErZtKhnz/a/344d8me/9lqrcoiJkWPtLbUPP5R1pofO8ePSMu3XL6jbLiQ1Vc4TGyuV5v79YoGY3kP2l2fvnnXrZP0HH7iv/+UX6/t49VX5fOKEbIuN9T7v2WdLzCQjQwT0vPOcW5ahYu1a656rVBF/eCDy85nPOce39cfMfM018n0cOWKtu/pquT+7uN9+uzRCDCaYn5jofU7Ts2rZMt/XHTvWepb23+GBA9K7aty4gLdXJJYtk2t99ZU0Spx+G/5YtEiO+fJL5+3PPCO/v6ws5hdflH19NaoM+fkSq2jbNvRWhApEGefTT+WbqFnTvbXJLBV5ixay3QSygqWgQM75wAPWOtNLYtcuWTYt+J9/9j5+zhzrj+kZLLazc6e4TIYODa5cRkxGjJD3v/9d3hctsvZ54gmp3J5+Wv5MN94o78uXB3cNQ0GBtIoBsRoM+/dLr52UFPF1G+vCzrvvcmGw1JCTI75wU+mbXjY7dkilTySxDnNu05Pl0Uel8gWYf/utaPdQVAoKpIUKiMsnWLKzxZr1xZo1Iuh/+YssZ2QwR0W5/76YrZ5TptFhYj9Vq3p3ELjuOhF+f8HgN96Q41u18t7Wr59UnKHE9ORKTbXiHW3aBCe0zHK/UVG+K33zf1+7VqyM2Njgzjt5shy3YUNw+weLP4HQCYPKAMePy3tOjnculqeflkFDQ4dKzp10z7Hofjh6VJK8tWplrYuJkffDh+X9wAF59xyNm5kJjB8PxMfLoCpfg6SYZVBaZKT7YCt//PWvwLnnAp99BjRvDtxyi6y3j5jdvFlG+d5wg1xj5ky5TvfuwV3DQGQdM3Sotb5JE+Dss+XVoYOkzfa8R7NsL9e//gVs3AhMmgTUrOn+PA8ckLJ26GCd++qrJd/Ra68Bb74p6bp79SraPRQVIutei/K8oqL8zy3RqZMMPHzvPeD77yWzbE6O+3MFZLAXYI3OzsmR99xcYO1a+Xz0KLBnjzVwL8JPTRQf7/teuncH1qwBTp8OeHsAZHBjoIGTSUkyerxFC7mXyZOBHTuA556TJJCBXrNmAZdfLoMMvU6clVV4P5s3yys+NlMeSAAGD5Z3z//q/v0yIDIs+FKO8vgqrxaECeJNnCjvs2bJ+uRkq/+0fTBNsCQnyzHffGOt++03Wff997Js3DueboK//tVq7ZreI07MnMl+3WO+MAHte+6R1mP16lbPDma55pAhUqY2bbwDn0XBmPFbt/re55ZbvIPNXbrIcW3bynJGhpRz2DBrH+OO+N//rM/ffut+nsOH5Tk3bixutZLAuMGKEtAPhsxM6UlmLMsGDbzdk6bjwaFDsnzHHWI9AMxvvSVupYgI6xw//OD/mmbw3r/+5b3N/P6SkgKXvaBAfscXXODfxRcfL+40OyNHWuUN5uU19iY1VW761Vc5M9OynOvUKeDx1d5x//H7oUcPedm5916J4RXXbQk/FoTOKFcGOH5cWm9PPCGtsvvukxw7d98NNG4sCdPq1AHatpVh+GPHBnfelBR592VB5OVJds+zzpJMoWvXAp07A6tXA2+8Adx1l7R2u3eXFiOztE4NJ06IxdOli1gbRaF3b+Dnn4HzzpPWY/v2Vks9L0/SP1x9tVxv1ixJSle3btGuYbjvPuDCCyXDqy+6dwc+/lhSI7RoIVlM166V72XnTmkFr1gh6//yF+s4+/M0LeUWHjmLGzYEfvtN7qV+/eLdQ1Hp3Vvmj+jfP7TnrVkTWLJEWv4AkJAg340dY0GY55GdDbRsKVbp3LmSOiQxUZIP1qkjrW1/tGwJLFwo36EnxqpYvlzO6Y+PPpJkhYD8vh991HufkycldYln9tp33pFyOuWs8iQ6Ghg+3GPlokVivixfjpp/lf/cokXAyZOEeKwBtu0JfGKItfbEE9bvlFnqhEsusdLMhBRfylEeX+XVghgzhrlJE/lsWvgdOsj7jBnWfn/9q7TETEA0ECaAah/if+SI1eLft08+P/us1YUwL09aKI0aWcFIM4J19273848bV7y4gBPDhzPHxclnM3DLV7fIcPD77+7WlkmjccMN8r5+vTXi2B4oPXbMat0a33V5SQMRLszI7u3bZfm66+T3PGgQF8YiQuVHLyiQ3+ptt/nfz1hxPXuKdVCjRgGnpHjv99NP7hZ2yPjLX+TE55zDzMxXXCHxHIB5IS5l7tQpqNOYbrGTJ8ty0h/5Z9y7CRqDKF2Sk4FRo3xPznL8uGTmBKTFfvfdkklz4EDgxhut/YYOFT9u166SiG7ePPfzMMuxn30myykp0uo25wbkc0SE5TMHJJlb797iX+/YUVpjr78ONGgg200rLSlJXj17iqUxebJYDkWNCzgRHy/lzcqSFpxZV1KYlrBJEGfiD6NGyfvmzbLu7LMBe1b5unXFb3/4sMSHqlZ13x42/vhDTJPU1MD7pqbKj6OE8LQgcnJknfmdPPaY/M5CgYkxJSXJLd57r5VcEJC4QefOYuUePy5pzidNAij3NC5sexCd22dh3Djr8fz2m7wHskaKzKJF8r5tG5CZifh4qz6Ix2YJyARBhw5iCX/xBYDHH8esQe8iMpLDNu2sCkQJMG+euC98xaHsAgFIyupHHpEfs92lc+GFUiGff76ca/RoK8ANAB98IMe8+64sp6S4u5cAEYeGDd0FokkT4Nlngcsukz/uxInuJnbnzlLx/fYbcOut4o5q3VrE6IUXivFAHIiPlz/p9u2Wq6l9+9CcOxiio+W5GmFISgKaNRPTHbAEwlMMicTNdPiwmP3NmvkPuAbNsWPA0qW+ty9dKj8Cf5M5ADJNWZs27rVmmHEKUkdFidjefz/w5JOhvV737tKgmjJFstN++KG17d13gYwMaVBNmybf8VktGZ/VGYsL8n5Dg+1JmDxZ3E8HDkgj6dJLLddhSNi7V37Yl1wiP/I1awobP7Wq5aA50uWPHESkmUg6Ovz8MzB7xp+Ydbg3LqqzBg3rhillsS/Tojy+yqqL6ZFHxCz0NXK2Rw8ZkVsUVqyQmNfYsbJ86JCMZwAknUZ+vvS3d0pL0aGDmP2mD7q/4K0hMVG6nYbF/GbmVavk3DNnymCsxo1Df41AjBljDdg75xzr2bVsKd8PYA3as3PuuczXdt/Dl/XMCF1CuyefFF+Mr1wS990nBRozxv95jO8skA8mhJgMsqY770UXMfftG77rffedXM/8Ps8+W9afPCnL//iHxwE7dsiGJ5/k/E4JfGHV5RwTI50iwjHwjj/5RK5n+o3/5z+FSSe7NXCVxfgxg+D0aebzOuZzDA4ywPwG7j+jVLtQF1PpYlr5mZm+t9stiGDo2hV44AEJnj3wgHQHPXFCLI+MDHHTOFkQgNXiNRZE48aBr9e9uwSPb7xRXF+h5pxz5H3yZODHH0vWejB07y7fxfjxMjmOsRbi4yVICgA9HKatiqmfh8NJu7B380mvAHWxWb9e/Im++jXv2iXvv//u/zx798q7P2skxDi5mKKiwnSxCRPQPU+eATNw/fVi4f75pzXBkZercvFieR8xAhEjR+Cd3Dtw/Dhj9myZayQo12ZampjwmzYF3nfxYvFFXnWV/PlWrSq8RjxtAWrXloXdu4O4sFjz74xfh8MQX+aQOxvJNXxVMGeACkQJYAQiI8P39qIKBCDzFCcmiltp+XLg//4PuO022TZvnvxeAglEVJT0JAnEkCHyx3n99aKXMxhq1BAX17Jl0q/7yivDcx1/9O8v8YNp0+T7MELYvr34i4nEVQFAKm+X4zoGh3EYDZF+qi6aNw/yYv/6F3DPPb63m0CMqeA9MRNur18vLQM79o7+RmC2brUGv4QZIwZ2F5MRjZBy7Bjw0kto/MOHuOwycY2amN3WrTZXZTuPuVIXLZI/QceOQLt2OB/r8eI9e9G3rwhEUHz8sfiyLrgA+PZb//suXiyzAUVGSrBr1So0aybTx16VMwvo21f2CzIOAQC9sn/Co3gZ11yRjVbvTJAGgNfAizNHBaIE8GdBMBdfIGrVEmHIypIBcY88IpV4zZquIBZ8C8SRIyIQTZq4xzl8MWCANJaCrgCLwYIFci9ZWUX4o4aQuDhx2WdlSd1jApWFrb14V2MvOxuIjS0cGRiTuRt7cBZO5NYM3oKYM0cqGafgcW6u+KwBaal6wizm4fnny+c//rC2bd9u/TAAd4FZtkzed+yQmwwTJWZBrFsn7wcPYsEC4Kmn4DUILZLy0eYVj37hixdLpUxUaLo+duEvWLSoCEK2eLH8YM45R1pPq1c777d9u4i9EYEuXYD160G5p7F4zgncnDkV6NNHekgUQSCQnIyXY/+DOfOiRXhq1gz+2CKgAlEC+BOI7GwZBVrcPv6eREZKK9d4FPxZEPv3i0Ao/vEayfvHH6Ik77wDMCPm0CZkQtwEQQtoaqr8IJx6Ie3caVkBThbEwYPiQxk+XCo5u5vp55+lRjbR9vR08SFWqSI/im3b5IYuuMCyQkKMZ5A6OzvMAmF8pZAePkQugVifh9a8A1GrllnHpKSIK8dU2G3ayAFFmXA7Lw/49Vcxc+fNk14JZvLzggIR/1OnZPkf/5AHMnKkLHfpIg2ATZtEqE2hY2OLJhBJSWHoauWNCkQJ4E8gzLbiWBC+sPe08SUQeXnSuKmUArFvn3TBuu026Vbz55/O++XnA889h/OaHELVquISAGB1Wdy0CVi6FDH71hUeEpQFUVBgVfwbN3pvN+4lwNmCMBV7585iRdjjC0YYzD7p6VIJduki+734oohFaqr8UOzWR4hwcjFFRUEqwKefDj4vRiBsFoQhOloa9ps3A5tXZ0kX0pQUy1Iz8Yd+/awDWrYU4QSAVatkAnB/3YJXrpQ/c9++0iXw4outiaS//FIsipEj5Q/24YfS7ahZM9nepYt1DmMltmkj/aeDjEHg+HEpbyj6lwdABaIE8BeDMO7jcAhEnTrO5zVd+HbtCi5AXeGYNUsCNz/+CPznP9LH0Yk1a4CJE9Hk+w+wZQtw++2u9YsXy5+6alXg/vsRU2C1YJs3LXA+l51Dh6xK0kkgjPO8aVNnC8IEqOPipO/zsmUiOoAlEGafvXvFrOnVS/b7+GMZip+UJD+QUaOCGx7sxKefAo8/7rXa1zgIPP+89It+9dXiXc8TBwsCkJjRxo3AttRoEYiMDPEZAjIMvEEDSQZmaNfOEoiXX5Yh1l9+6fu6poFgWgxDhsgFt2+XXhbVq4tg9O0rYvy3v7lfq3lz6ZNuLIjWrWVodbAWRHKyvKtAlH9MjAEoeQuiVSvn+IIRCOZKakHs2iVN2t27JWg4ebJzi9G0wpOTERfnGt+QkyMunWuukSj2ypVoGHG88JAWtU54n8cTu1tpwwbv7Zs3izh07GhZEMxWP3lTrlatpOI/eVLygmRlSdDa3CMgFkSLFiIkOTkiao89Jnlbpk6VivGf/wxcZif++1851m7xwIcFgWwZi1GtmghFIPfW8ePWd5KZKd32nnnGEkJmEQgiuX+byMXHy6ac/KpoD5fryLTOV68W14x9sMo554iLidmyMB54wPe4hMWL5SJNm8rykCHy/n//J9uefVby1KSny7vd7xgZKYKxZImIdZMmEtg66ywR87w8cU/5s7KMQJR3FxMRDSSiLUS0nYi8mhpEVJeIviWiNUS0gYhuD/bY8sKff1ru5JISiLg4sXyd3EuA+yCgSisQrVpJJXHvvVK5OnUDNZWsPc3r8uVSGfXtWziaMCZeHmhtnETtnCB6ChmBqF/ft4spPl780saC+OwzcVPs3SvlatpUun4NGCD38eWXYvHk5clxO3fKD+7kSamgeve2RlkZd8fllwMjRoifvCg+eIOxdKZMcVvtGKTesk4E7KuvpFVtH77siellZPoWr14trp/nn5fKOCNDKvyMDKuStLmZ7N1U47u7evYYN9OWLTIc2U67dvJHXLZM3I933ikBuqeesvbJzpZyZWdL/MHEMAD5LXXuLN3fqlWTJFOTJskoveef976/u+6S72/jRrFEARGI/HyxIrp0sWIWgKwz1kVWFjBjhohaCST2CptAEFEkgLcAXAmgI4ARROQ5wH4cgI3M3BlAPwD/IqJqQR5bLrCPdC4pgSAS6//vf3feXukFYudOUVFAKvk6dWQIrtN+gFTIpovo4sXygC++WPIvx8Qg5nLxKzdHunQPC4QRiMsuk0rCXlEyS2yjfXup6NPTpeJYtEhaG599JuUx5W/SRM7z6adWz6UbbhBhMNZE8+Zyrt9+87YWXntNXCL33muV47vvxA2Xm+v7HjIypGxVqoi7xBbHidqXAgDI/v5n5L/xH+TlQQLFPXtKBsYXXpBsf565YgBRk7Fj5Z6XLJF1xpX0xBOSNXLCBGudyUZoczO5CcQdveVDSoqI66lT3oNsTBbH996T90cflecxaZJ0YS0okA4Bl1wiz/LkSXeBACwr4sYbpa90tWqS1dHpj129uuV2sgsEIM9m2zYR/NWr5VoXXijW5FdfiXitXSuusJLA1wi6M30BuBDAPNvyBAATPPaZAGAyAAIQB2A7RLQCHuv0KosjqU2absB7ukZma1rI9PSSK5N9vucffwzTRbKymO+/35qZqCxRv777/Jf33SdToO3b577fgAHew8f793dPrHbsGJ88mssA86VY6J3r24lHH5UZZUwWRDP/KrNkAjTZFN96y/pxJCbK5y5dZKjwyJHWMWbWIjPDvZmC0GRrDPQlm+t8/LGU30y316yZe654O0lJso+ZDcieV/yOO7gKTvMEvMinUJ0B5pfwmJVRLidHcoZfeKH39GgvvCDnq1XLyjF/zz0yT2xBgSS9q1ZNclwD1uTUtud+4ICsisFB+bHXqiWzGpl9f/rJ/Zpbtsj6GjUka2ZBgczv262bHDt6tGy//36ZQq9lS+8pFjdvlucVaO5Qw59/ynSPJiOlmbUKkN9X3boy7eIDD8j30amTtf3FF4O7RpCgNGaUA3A9gPdsy6MATPLYpzaAnwHsA5AJYFCwx9q2jQGQDCD5rLPOCumDCwVm3gNA5qL1xMyuFuxsVaGgoMDKzx/k6P6iM3++XOCyy8Iz07oTX3wh8136w6RffeUVa93WrfJARo923/eccyTtpknef+qUTAjhkdagoIC5WrUCvgUfWpN/+2P4cJnk4uef5dzz5lnbzEQO339vTWC9dKkIismlAjA/9ZR1zIkT1qTN11xj5S0ZOlTeA+WOMCl8Y2KkQuzWTUTmnHMkj4gTJk/Lhg2yj5lPtKCAuUULrlXlT374Yeajf2wVvTv3XfcfuWkZ2efy/PlnuY8bbxQBbNFC1vfpY00HuHOniDaRTDG3a5e7QOXkcMFnM7h+xDHuU2uVrDvvPMmjYQR57173ezl92kqtav+TpqVZ0xHeeWd4f8cZGdZ3O2eONdepmRAmO1vE4qGHQl4OfwIRzhiE0/ArT6fjAACrATQHkABgEhHVCfJYWck8lZkTmTmxUYmk0SwaxoVE5NvFVK1amEaa+sAkmAPC6GIyfvuFC8VnWhJ8+CHw/vu+Rx8D7j2ADO3aSeB2+nSrh0pBgbglEhLEJZGcLOMesrLcU+xCnuf4Mbm4ETODG62cmipdK01K040bxbWycqXldzcuJkB6W+XkSI8hE1y1l79OHQmaA9JDwWz79Vd5D9T3NjJS4ghHj8ogu1mzgGHDxFe+YYMVKM/IsAK3W7bIcW3biislOVlcY5s2AXv3IiqakJ0N5Jwl7puocX8R14rh9tvl/p59VibaeP11cZXFxclkDV26yPd48KC4k84/37rvW2+VqvT8861ueMbFNGgQaMRwPFDnfdw5xjU93tlny3e5ebMEhE0MxlC1qhWws7uOWrQQV9hTT0lHhmBGlBaXWrXkT9mli7jhHnxQytqokXRNjoqS5/Laa+EthwfhFIg0AC1ty7EAPBPL3A7ga5eQbQewC0B8kMeWC0w31qZNfQtEvXol+p0DkN9iZKSV0jvkJCVJ973u3WWeSnswJlysWiXvpieKEyau0Lq1+/onn5R1Y8dKZZyeLj1J4uLkHpYtE7/vJZfIyFcP/vXvqrim2vzgBSI2Vv78DRtKJdStm7yee87q1WIq9u++k/crr5RUo07lv/VWee/VS0ZdNmggZalVy8r1448uXSQmsGSJJUwDBsj7ggXyfs01KMwrvXmzlKFaNeCmm0S4PvusMK4QXasKcnKszkVeA+XMDFlm9qCHH5ZzL1smFbgZL/Ddd/In6tTJOvbJJyX2kZgogfpatURIcnIku+299+LZw/fjtn+5RKVVKwlqb95szaHriYlDeMYWOneWQHO1aoGf4ZkyY4a8zMxSCxbI/YQyQFlEwjmjXBKAdkQUB2AvgOEAPOZpwh4A/QH8QkRNALQHsBPA8SCOLReYejE21nkcRHHTbJwpDRtK/RSS1NROJCVJIPeBByQ4+eWX7lOxhZrDh62W7qJF3lOCGZwsCEBat2+8IYHn2bOtLoytW4tQfPyxLJvJNjwhkocaKEidny8t45Yt5Zhzz5VKtUED6QUTEyNli4yUL6hqVQk+R0eLVTFmjFgGnhMqDBokFkhCglXuo0eDHLnn4rLL3JfPO0+ew7x5UmEb4d2716psAanQL71UurG2awfExyPqdBWxIFw9mRwt5LvvliBtTo6kiujXz/pBmvuYPl3ejQVh7m3dOnmGgJjBBw6IVVNQIL87++TarVrJH23FCvicOKFnTxnH4NnDqSTxnP7vggtKpxw2wiYQzJxHROMBzAMQCWAaM28gorGu7VMAPA/gAyJaB3Er/Y2ZDwOA07HhKms4MQLRooVzj8bSEohOncLo1tq3TyqR7t2lVRwREfwo0eJicuE0aOBtQSQnS5/9//xHBKJePeeHfuWVsn7ePGsQVFyc1QK/+GJrBK4TJoeJPw4cEJEwldt114lQTJvmbRVEREivmd275QurUkV6KF19tbu7BpBzmFa3KXdy8pklzyICrrhCWvG1a8v18/LEBbVtm3ta35EjxW20axdw332IXgg3gXBMtRERIed3okEDcQ2Znkznnee+3d5VqXFjea7mD+YpnmefLe/HjvlO1fr00+LCK2lTvowT1nEQzDyXmc9h5jbM/KJr3RSXOICZ05n5CmY+n5nPY+aP/R1bHjl+XP7LDRv6djGFKg9TUXjzTZkfOCzYR3pWqSItzGBmPguW//s/mWjajnEvjRkjffr37ZPlnBzgllvEx/7TT+Ji8qyIDVWqSCt6/nzZj0hcPd26iUUSKJVtMAJhnoMRiPvvF4vHV5mMu8e0qAFvcXDCnO9M848PGCCWyLRpMuq6bVsR2pwc98p22DBRAWbgiisQHS27+BWIQJh7btnSfyuqSRNxMW3cKKJjcscb7AOCfOWRj4gIY07y8ouOpA4zxkKoXdt/DKLEOXkSdPhQeM6dlCR/ONOibdnSPafQnj3++9j7g1kq+ylT3OMaq1bJda67TpaNFfHKK+J6qFZNXCD2MQROXHGFlHXuXKmco6KsY7t29V+24ghEIIxA2K2DYDD3eKbpd43bqaBAxgYMHeo8J2zduhKjqFYN6NcPUVFiQfiMQQSDuWd7/MEJ42LasEEEzPNidoEoyXlsKwAqEGHGCECtWiIQzM7bS5z77pMJTMJBUpL41k0K4pYtrYoxM1P8vJMmFe/cKSkiMHl57ibQqlVSoSQkiBovXiy++xdeELfMqFHA11+LQPhqrQOWyyM52b+QOGHyqPvDPAdT8QfCWAClJRCNG4svvGdPCQqbAWGAd2v8zTelF1bNml4WRLHcmeae7fEHX2U8fFjiEk6TXcfEiNVFJAKiBI0KRJixC0RBgXca/lITiG3bxG9f3JY8IDc0f750VTQ3xiyVqz2RWGysVIzMct0//yz+DGfGMoiKsjJonjolrdouXcRN1KePjIq94AJ58G+8IT7yzEyrZ5Ivzj7bqviKKhAmSG3yBTmRmiqVVbDdx7p3l0BxoErSk06dRCgLZzg6A777Dvjf/+TzhRdava88J25u3lwmxgEKLYgzcjH17Cn3YHpu+aJJE+u3ZU/CZyASKyIurmT7k1cAwtmLSYEIQEyMNdlTZqb0zAOsP1CpCMSBA1bO7+L03Ni9W9wPJmVxXJykz05JkdacXSBathQBOXrUPa1yIJiBX34R/3e3bmL1LFokldPQoZKDPydHWo7MVovz9tslY+qIETItZMOGUok0by7dVwNV/AMGiOD4szSciIkRcTh+3LcAmDEQwQZDhw+XbqRFDZ42beo72VxRsQtBZKR0W7blPnIiOjoEAtG4cXD3YB/M42RBADJ2xZ9wK46oBRFCvvlGutHbMUFo0xHGHocIR6rvoNm/X96dsok6wexu/nz5pZXvvnVr8dED1ru9y6Txt6emWgKxY4f3VJmejBol/dKnT5f8OOnp1mxgw4ZJv+FFiyyxMUHNG24QN9fDD4s4AFKxDR8unwNV/MbNVBwXE+A/DrFpk9XnPljKWs+aCRMCBuyjokIQpA4We856XwIxcaLv5GSKT1QgQsjcuTLY9uhRa53dxQS4j4UIR6K+oMjMtJKrma6Bx46JG+G775xFY+ZMaZWam1u1Svzjo0ZJD5+ffpLg7jvvSJZQu6/XLhD2rKFr1sj7li3eg0Sys2Xe1JEjxULIyxMLIiVFBKJ/f4lxPPaYuLgaN7YSnvni8ccl9hGogh4wQPzpw4b538+TQAKRlSXjB4oaTyiHGAvCBKnD6tkxFkREhO9eSkqxUIEIIcYaNr08mb0Fwm5BlJpAGOsBsATi4Yelf/0118hoXPvE94C4ek6etGIHJigMiEAUFIg7Jy1NervY8bQgzJ/YZKvs1k3cKPYI/sqVEi+4/nrpA3/rrRJkBkQgoqMlYLp+vfiq58wJ3NJu1EjSTAfar0oV6X5a1EngjbXiK1C9bp2MgagkAlHiFkTr1sF1AVaCRgUihJhGsElDlJUlMWBfAmEmuSpxgTB5a2rWFGuhoEDSKJtUzCdPes8PYITk99+9W8IdOsjnn36SgPTVV7sf26SJVLppaSIQffvKn3rVKhl0deqUXP+rr6xjjBBdeKG8P/mkuInq17cCtu++K2I3Z06ZGHUa0IIwg/nsYxoqKCEJUgdLvXrSvdaXe0kpNioQIcRTIOwWglMM4sMP5Xdd1FjoGWMsiD59xL2zapWIxvXXS6oJwDuIbARi6VJpCRcUuFd0ZoKTMWNEDOxERkqAeN06qTzbtRNBWbVKYhZxcbJsn8Xr99/lwRj3QZs2kjTtwQetdAw1aohVUFZwEoiJE8VdBcj91q1b9NhGOSQkQepgIZJ5EuyT7CghQQUihPgTCM8YxPz5ktZnwgQr7U9Y+fNPK8hsLIhLLxUTZ/JkWb78chlIFBXlLhBHjsgx1avL2AJzg3ZXyR13AOPHiwvHiZYtrS6q55wj4rJhg/Sbv/lmGfi2b58EEplFiIz1YJg4UaadLKvUrCnPzghEZibw0kuSgO/0aXmmCQllL+gcBkyQ2vzkwj5IefJkryy7ypmjAhFCTOM3PV1SETkJRGam/GnuvVca0g5zvoeH66+3Wlj790slZTJXfvKJ+PmbN5fkcOefb7lDAMt6uOEGEZrp0+Wm7CNU69eXFAy+une2bGmpo7Eg8vLEErn5ZqBHDwl4T54M/PGHlLFXrxA+gBKASCwe0/V3/nypJU0HgLVrK4V7CbCC0pmZYkB6GpVK+UAFIoRkZFj//6Qk3wLx5ZfSy3PSpBIat5OXZ40sBsQaaNTISoCWk2OldgYs948JGhuBMNlYk5KK3hI2geqICHEdGesjIcHyHT/1lJTFnrq6vDFsmExTefCgxFfq1xfX03PPScugEgSoAet3feKEpjgqz6hAhJCMDBlIGhnpLRDR0bI+M1M8K1WrBh4gekZMnmzNI7Bpk7T89+6VQu7fLy3dmjUtK8CeVTMhQbqzmrQQGzfKvr17W6kbilrRmdQSZ50lNUbbtpK64YEHrH3atRNrYts2uZ5nBs/ywNix4rabOlWshquvFteH6dJbSQTCiIIKRPlGBSJEnD4tjd8mTaReS0pyHwhHJFZERoZ0AGrXLgRmd16edEv94gv39czS6+fZZ2XZxAwA6Z104IAV+OjYUdTLlSIBgFWJmTjEhg2yX0SE1aovqqvEWBAm02ZEhJTrttvc93vqKdl2wQXl0y8RHy/K/+KLIrJDhlhzU1SrVrrzDZQgdgtCs1uUX1QgHLjuOskoXRSMe712bXGnL1hgDQcw6bxNwr7Nm0M0nueTT8RKePll9/X794v5snKluDrsArFli2VBABIlnzLFvf94p06iaEYgNm603EC9e8t7UXP8GIEINEitfXtpfZflYHQg7r1XuvBERYnrrlcvsdQ6dRLTsRKgFkTFoBw20cLPsmUyYHfChOCPsQvE44/LIOOCAvGkmBZUrVoSr9yxA7j22jMsZF6ejFmIjJSReVu3Wq1z+8xECxbI9t69pevo5s3uFkSfPt5TaNasKedavVoKvG+fJRB33SVuIqekaP6Ii5PKsXPnwPveeWfRzl3WGDxYXGpdu1rBp2++CeP0fWUP85s/eVIFojyjAuFAdrZ0OMnODt48tgtE69aWd8dO7driis7LC0Fa+hkzpLfMW29J99JPP5VuoIAlEDVqSMB0zRoZKX3ggASqs7PdE5w50aWL5DkyWTyNINSsWTx1a9hQXFWVYAwAqlYVMTZZGYFK03vJYLcgzABzpfxReZo0RSAnRypxE1cMBtPFtU4d3/vUqiUTlQFnKBAFBWI9dO4M3HOPTIP56adWr6MNG6S76TXXSJep3FzJrtq+PfDbb7JPoMEXN94o7qlRo2Q5FKNUQxJ4KSfExgaf0rsCojGIioEKhANm9KfddR8IuwXhC3tqnzOKQSQnSyzhoYckVjBypPT8MUmgTMxgwADJ/QOIQMTHW0O5A1kQw4bJxDzPPSciZOb1VZQgsI+DUBdT+UUFwoP8fCtPXbgEolmzM5yHevZsiT1cc40sX3ed9JAxVoTpdXT55bK9USMJEttVKZjh2y1aSLB48uRK5T9Xzhy7KKhAlF/0X++BsR6AoglEMC4mIx5n3INp9mzg4ostF0a9esCgQRKX2L9fuld27Chujm7dZF8id79WieT3UCordreSCkT5JawCQUQDiWgLEW0nIq+kEkT0KBGtdr3WE1E+ETVwbUshonWubcnhLKcdIxANG0qHn2An5SqKBXFG8Yft28VCsM8NDEhf+/37rbmeTcxg/nyZkc1+4chIjRwqYcUuChqDKL+ETSCIKBLAWwCuBNARwAgicot0MvMrzJzAzAkAJgBYzMy26XZwiWt7YrjK6YkRiN69xVuzYkVwx5WYQJh5mD0FYtAgMV9M5lDT66hBA8usiYmR1A+NG6vLSAkrakFUDMJZS/QAsJ2ZdzLzaQAzAAzxs/8IAJ+FsTxBYQTCDA2wu5ns2Sk9yciQP4W/TjohE4hOndwT5QEy0O3aa2Vuhbp1JdDhiXEzqXtJCTMag6gYhFMgWgBItS2nudZ5QUQ1AAwEYJsxBgxgPhGtIKIxvi5CRGOIKJmIkg8dOnTGhTZTJLZoIXWw3YIYPlwyUuTmeh938qT/+AMgDXeioo8xKyQ9XbqpeloPBpPSoWNH34n03njDsjIUJUyoBVExCKdAONVQ7LAOAK4B8JuHe6k3M3eFuKjGEdHFTgcy81RmTmTmxEYhmDzGPsHJeedJnjvD8uUiGE71a0aGf/cSIAKzfLmVt84nBQXABx9YamV47z1rak8nLr1UVM3f7Go9erjnXVKUMGAXCI1BlF/CKRBpAFralmMBpPvYdzg83EvMnO56PwjgG4jLKuwYgYiOFm/M1q3S9fXkSWnAR0XJKOndu92PC0YgoqMlgWlAli4Fbr9dptI05OYC77wjYxvatHE+LjJS0mP8859BXERRwke1atZntSDKL+EUiCQA7YgojoiqQURgjudORFQXQF8As23rahJRbfMZwBUA1oexrIXYLYj4eFnevVvGpQFW3es50c/Jk4EFImiM2WJXoW+/FYUyGQB9Ubeu+79TUUqBiAjrZ6gCUX4JW94DZs4jovEA5gGIBDCNmTcQ0VjX9imuXYcBmM/Mp2yHNwHwDYkfvQqAT5n5h3CV1Y7x6kRFWeMVtmyRWTcBacAvXiy5muxkZDjHhYuFUaNUWwjn7bdlsNugQSG6iKKEl6goSYOvAlF+CWtiHGaeC2Cux7opHssfAPjAY91OAEGk/Qw9dguidWv5vHmzCERkpKyrW9fq1mrIyLCSqZ4xmzfLuxGIAwdk7ubnnpNCKEo5IDra6t2nlE8qSea04LHHIGJirAFzR46I679aNXElOQlEyFxMnhaEWe7ZM0QXUJTwY4RBLYjyiwqEB3YLApA4hBEIM37BCASz1Zs0mG6uQRfApHxNS5P3HTvk3VdwWlHKIOY/pAJRftHhtB7YYxCAiMKGDZIs1S4Q+fnWoLn8fJnyOSQWxPbt0pW1fXtxLeXkiEBERspEPYpSTlALovyjAuGBpwXRvr1YD6dPWwJhLAXjZjIZtEMiEMaddNll8r53r4jG2WdXmukqlYqB+Q9pDKL8ogLhgZOLyWB6NRkhMAIRTB6moDEB6v795T01VSwIdS8p5Qy1IMo/KhAe2IPUgH+BMJleg0n1HTSbN0uejw4dZNkIRNu2ITi5opQcGoMo/2iQ2gPPGERcnHh26tWzMmR7uphCakFs2SKq1NI1CH3tWuDYMbUglHKHWhDlH7UgPMjJkXiwGW5QpYqMbzANeiCMLiZmsSDatwdq1pTU3IsXyzYVCKWcYQRCYxDlF7UgPMjJ8W7xvP+++7piu5jy8kQAzjvPefuBA3Iy49dq2dJKJ6sCoZQz1MVU/lELwoOcHO8WT/fuMgWDodgupkmTgM6dgV27nLdPcQ0yNxeLjZU+tIA1rFtRygnqYir/qEB4kJ0d+AddbBfTV1/JGIeff3be9txzwK23yhzSgBWHaNZMXE6KUo5QC6L8E5RAENFXRDSIiCq8oDi5mDwxdXVAgVi0SCaByM0FDh6UyX4AK65g2LVLhKFnT0npbYZnG4FQ95JSDtEYRPkn2BjE2wBuB/BvIvoCwAfMvDl8xSo9ghGIiAiZPtQeg6ha1eG42bOBzz8HrrhClpklAO0pELNny1DsTz5x/zepQCjlGHUxlX+CsgiYeSEzjwTQFUAKgAVEtJSIbieiCjW81ykG4USdOu4WRO3aDrN8mmR7L74oLqSzzpL5HHbvBlJSrP0WLRIR8IwzGIHQMRBKOURdTOWfoF1GRNQQwG0A/gJgFYA3IYKxICwlKyWCiUEA7hldjx+XFOBepKWJkuzcCcydCwweDFxyiWwzVkRBAbBkCdC3r/fx8fGSPjaoaegUpWxx3nnyE65Ro7RLohSXYGMQXwP4BUANANcw82Bm/pyZ7wNQK5wFLGmCcTEBIhDGxXTgANC4scNOqanAtdcCCQmyPHQocO65QIMGlkCsWycD4fr18z6+WTPg0CFg4MCi34iilDLXXy+TI+oUJuWXYGMQk5j5J6cNzFyhmrc5OcF1GLK7mA4eBFq18tghNxfYt0/cSrffLl1cL75YAhgXX2wJhHl3siDMhRRFUUqBYF1MHYionlkgovpEFGBy5PJJsDEIu4vpwAGgSROPHdLTJSjdsqUIwsyZVjbWfv3E7fTrrxJ/iIvTVN6KopQ5ghWIu5j5uFlg5mMA7gpLiUqZosYg8vPFC+QlECZAbQLNdm69VYLS118vYyJ8WQ+KoiilSLACEUFk9dEhokgA1cJTpNKlqDGII0ckzuwVg/AnEPXrA3PmSNfW48dVIBRFKZMEKxDzAMwkov5EdCmAzwD8EOggIhpIRFuIaDsRPe6w/VEiWu16rSeifCJqEMyx4SJYgTAxiIMHZblIFgQAdOwoYyTOPVeD0IqilEmCFYi/AfgJwD0AxgH4EcBj/g5wWRlvAbgSQEcAI4ioo30fZn6FmROYOQHABACLmfloMMeGi6JYEKdPWzrgKBB16vjPv3HllcD69UDTpsUur6IoSrgIqhcTMxdARlO/XYRz9wCwnZl3AgARzQAwBMBGH/uPgFgmxTk2ZGRnBx+kBmQ2UMAlEJmZ0mW1ZUsZA+HLelAURSkHBDsOoh0RfUlEG4lop3kFOKwFgFTbcpprndP5awAYCOCrYhw7hoiSiSj50KFDwdyOX4riYgIsgWjcGDJiOiFBTpKaqgKhKEq5JlgX0/sQ6yEPwCUAPgTwUYBjPBNPAAD72PcaAL8x89GiHsvMU5k5kZkTGzVqFKBI/mEWt1GwLiZABKJqVYk7IzUVOHpUuq6qQCiKUs4JViCqM/OPAIiZdzPzRACXBjgmDYC9howFkO5j3+Gw3EtFPTZknD4t70UViMaNXXmYjh+XlTNnSvRaBUJRlHJMsAKR7Ur1vY2IxhPRMABOySXsJAFoR0RxRFQNIgJzPHcioroA+gKYXdRjQ42ZjzrYZH2AZOouDFAbgfjMpXWxsaEsnqIoSokSrEA8CMnDdD+AbgBuATDa3wHMnAdgPKSL7CYAM5l5AxGNJaKxtl2HAZjPzKcCHRtkWYtNTo68F8WCyM21jYE4dkyS62VlybJaEIqilGMC9mJydTm9kZkfBZAJmRciKJh5LoC5HuumeCx/AOCDYI4NN8URCMDDgrjqKuDbb2WItQqEoijlmIAWBDPnA+hmH0ldUQmJQLRpA/TpI8sqEIqilGOCzea6CsBs12xydlfQ12EpVSlRlBiEl0CcPi2pM+rVAx55RCb/0UT4iqKUY4IViAYAjsC95xIDqFACURQLokoVoHp1CTc0aQIrQF2/PnD11fJSFEUpxwQ7kjrouEN5pigCAYgVkZXlClIbgahXLwwlUxRFKXmCEggieh8OA9WY+Y6Ql6gUKapA1Kkjwx3cLAgVCEVRKgjBupi+s32OhnRNDfvAtZKmKDEIwIpDNGkCYM1xWahfP9TFUhRFKRWCdTF9ZV8mos8ALAxLiUqR4riYiICYGMgYCEAtCEVRKgzBDpTzpB2ACjdHZnFcTDExrknZ1cWkKEoFI9gYRAbcYxD7IXNEVCiKKhA9ekhPJgAqEIqiVDiCdTH5mfWm4mBiEMEKxNNP2xaOH5c0G4WKoSiKUr4Jdj6IYa6kema5HhENDVupSgljQQQbpHbj2DGxHir+gHNFUSoJwcYgnmXmE2aBmY8DeDYsJSpFArqYcnMlx5ITx4+re0lRlApFsALhtF+wXWTLDQEF4qabgOHDnbepQCiKUsEItpJPJqLXALwFCVbfB2BF2EpVSpgYRNWqDhtPnQL+9z+ghePMpyIQOgZCUZQKRLAWxH0ATgP4HMBMAFkAxoWrUKVFTo7EHxzDCEuWSEK+1FRnN5OJQSiKolQQgu3FdArA42EuS6mTk+PHvTRvnrzn5QHp6d6pvNXFpChKBSPYXkwLiKiebbk+Ec0LW6lKCb8CMX8+UKuWfE5Jcd/GrAKhKEqFI1gXU4yr5xIAgJmPIfCc1OWO7GwfApGaCmzaBIwcKctGIPbvB7ZvlwNPn9YYhKIoFYpgBaKAiApTaxBRKzhkdy3vmBiEF/Pny/tdd8m7EYjx44HLLtM8TIqiVEiC7cX0JIBfiWixa/liAGPCU6TSw6eLaf58oHlzoGtXoGlTYPduWb98uVgXK1wdulQgFEWpQARlQTDzDwASAWyB9GT6K6Qnk1+IaCARbSGi7UTkGOQmon5EtJqINtgECESUQkTrXNuSg7qbM8SnQGzcCHTvLt2bWrUSC+LIEREHAJg9W95VIBRFqUAEm6zvLwAeABALYDWAngB+h/sUpJ7HRELGTVwOIA1AEhHNYeaNtn3qAZgMYCAz7yEiz7jGJcx8OOi7OUN8xiAOHwZ69pTPrVoBSUnA6tXW9m+/lXeNQSiKUoEINgbxAIDuAHYz8yUAugA4FOCYHgC2M/NOZj4NYAaAIR773Azga2beAwDMfDDokocBRwuCWQQiJkaWzz4b2LPHciv16yfTygFqQSiKUqEIViCymTkbAIgoipk3A2gf4JgWAFJty2mudXbOAVCfiBYR0QoiutW2jQHMd60vkXiHY5D65EkZ+2AEolUryck0dy4QGwtcd521rwqEoigViGCD1Gkud9AsAAuI6BgCTznqNB7Zs+dTFQDdAPQHUB3A70S0jJm3AujNzOkut9MCItrMzEu8LiLiMQYAzjrrzOYwcrQgDrs8XHaBAIBffgEGDQL69rX2VYFQFKUCEexI6mGujxOJ6GcAdQH8EOCwNAD24cax8BaVNACHXSO1TxHREgCdAWxl5nTXtQ8S0TcQl5WXQDDzVABTASAxMfGMut46xiCOHJF3u4sJAAoKgC5dgHPPBRo0kIOrVTuTyyuKopQpijzlKDMvZuY5rriCP5IAtCOiOCKqBmA4gDke+8wGcBERVSGiGgAuALCJiGoSUW0AIKKaAK4AsL6oZS0qQVkQRiAAEYiICOCSS4BGjcJdPEVRlBIlbCm7mTmPiMYDmAcgEsA0Zt5ARGNd26cw8yYi+gHAWgAFAN5j5vVE1BrANyRZ86oA+NTV1TYs9OkjBkB6uh+BaNhQ3mvUABo3lsB0ly6y7o03rEC1oihKBSGsczow81wAcz3WTfFYfgXAKx7rdkJcTSVCkyZiPTRr5jDdg6cFAYgVkZsLmJhHbKy8FEVRKhAVbtKf4vDVV342Hj4MREYCdeta6266CTh0SKcXVRSlQqMCEYgjR8R6sIvBX/9aeuVRFEUpIYocpK502AfJKYqiVCJUIAJx+LAVoFYURalEqEAEQi0IRVEqKSoQgTAxCEVRlEqGCoQ/PBP1KYqiVCJUIPxx4gSQn68CoShKpUQFwh9Og+QURVEqCSoQ/vBMs6EoilKJUIHwh2cmV0VRlEqECoQ/1MWkKEolRgXCHyoQiqJUYlQg/HH4MFC1KlC7dmmXRFEUpcRRgfCHU6I+RVGUSoIKhD80D5OiKJUYFQh/6ChqRVEqMSoQ/khNlenmFEVRKiEqEL5ITQVSUoALLyztkiiKopQKKhC+WLxY3vv2Ld1yKIqilBIqEL5YvBioVw84//zSLomiKEqpEFaBIKKBRLSFiLYT0eM+9ulHRKuJaAMRLS7KsWFl8WLg4ouByMgSv7SiKEpZIGwCQUSRAN4CcCWAjgBGEFFHj33qAZgMYDAznwvghmCPDSvp6cC2bepeUhSlUhNOC6IHgO3MvJOZTwOYAWCIxz43A/iamfcAADMfLMKx4UPjD4qiKGEViBYAUm3Laa51ds4BUJ+IFhHRCiK6tQjHAgCIaAwRJRNR8qFDh0JT8sWLgTp1gISE0JxPURSlHFIljOd2yk/BDtfvBqA/gOoAfieiZUEeKyuZpwKYCgCJiYmO+xSZX38F+vTR+IOiKJWacFoQaQBa2pZjAaQ77PMDM59i5sMAlgDoHOSx4SMtDWjbtsQupyiKUhYJp0AkAWhHRHFEVA3AcABzPPaZDeAiIqpCRDUAXABgU5DHhofTp2Uuak2xoShKJSdsLiZmziOi8QDmAYgEMI2ZNxDRWNf2Kcy8iYh+ALAWQAGA95h5PQA4HRuusrphZpFr1KhELqcoilJWCWcMAsw8F8Bcj3VTPJZfAfBKMMeWCDpJkKIoCgAdSe2N6QmlFoSiKJUcFQhP1IJQFEUBoALhjVoQiqIoAFQgvDEWRIMGpVsORVGUUkYFwpNDh0QcqoQ1fq8oilLmUYHwRKcZVRRFAaAC4c2hQyoQiqIoUIHw5vBhDVAriqJABcIbtSAURVEAqEC4w6wWhKIoigsVCDsZGUBurloQiqIoUIFwRwfJKYqiFKICYUfTbCiKohSiAmFHLQhFUZRCdLiwHbUgFKXY5ObmIi0tDdnZ2aVdFMWB6OhoxMbGomrVqkEfowJhRy0IRSk2aWlpqF27Nlq1agUip2nlldKCmXHkyBGkpaUhLi4u6OPUxWTn8GEgKgqoWbO0S6Io5Y7s7Gw0bNhQxaEMQkRo2LBhka07FQg7ZpCc/sAVpVioOJRdivPdqEDY0UFyiqIohahA2NFMropSLjly5AgSEhKQkJCApk2bokWLFoXLp0+f9ntscnIy7r///oDX6NWrV6iKW24Ia5CaiAYCeBNAJID3mPklj+39AMwGsMu16mtm/rtrWwqADAD5APKYOTGcZQUgLqZWrcJ+GUVRQkvDhg2xevVqAMDEiRNRq1YtPPLII4Xb8/LyUMXHHC+JiYlITAxcvSxdujQkZS1PhE0giCgSwFsALgeQBiCJiOYw80aPXX9h5qt9nOYSZj4crjJ6cfCgupgUJRQ8+CDgqrBDRkIC8MYbQe9+2223oUGDBli1ahW6du2Km266CQ8++CCysrJQvXp1vP/++2jfvj0WLVqEV199Fd999x0mTpyIPXv2YOfOndizZw8efPDBQuuiVq1ayMzMxKJFizBx4kTExMRg/fr16NatGz7++GMQEebOnYuHH34YMTEx6Nq1K3bu3InvvvvOrVwpKSkYNWoUTp06BQCYNGlSoXXy8ssv46OPPkJERASuvPJKvPTSS9i+fTvGjh2LQ4cOITIyEl988QXatGkTkkcaiHBaED0AbGfmnQBARDMADAHgKRBlg1OngJMngWbNSrskiqKEiK1bt2LhwoWIjIzEyZMnsWTJElSpUgULFy7EE088ga+++srrmM2bN+Pnn39GRkYG2rdvj3vuucdr7MCqVauwYcMGNG/eHL1798Zvv/2GxMRE3H333ViyZAni4uIwYsQIxzI1btwYCxYsQHR0NLZt24YRI0YgOTkZ33//PWbNmoU//vgDNWrUwNGjRwEAI0eOxOOPP45hw4YhOzsbBQUFoX9QPginQLQAkGpbTgNwgcN+FxLRGgDpAB5h5g2u9QxgPhExgHeYearTRYhoDIAxAHDWWWcVv7T79sl78+bFP4eiKEIRWvrh5IYbbkBkZCQA4MSJExg9ejS2bdsGIkJubq7jMYMGDUJUVBSioqLQuHFjHDhwALGxsW779OjRo3BdQkICUlJSUKtWLbRu3bpwnMGIESMwdap3tZWbm4vx48dj9erViIyMxNatWwEACxcuxO23344aNWoAABo0aICMjAzs3bsXw4YNAyCD3UqScAqEU58q9lheCeBsZs4koqsAzALQzrWtNzOnE1FjAAuIaDMzL/E6oQjHVABITEz0PH/wGIFQC0JRKgw1bWOann76aVxyySX45ptvkJKSgn79+jkeExUVVfg5MjISeXl5Qe3DHFz18/rrr6NJkyZYs2YNCgoKCit9ZvbqihrsOcNFOHsxpQFoaVuOhVgJhTDzSWbOdH2eC6AqEcW4ltNd7wcBfANxWYUPFQhFqdCcOHECLVq0AAB88MEHIT9/fHw8du7ciZSUFADA559/7rMczZo1Q0REBD766CPk5+cDAK644gpMmzYNf/75JwDg6NGjqFOnDmJjYzFr1iwAQE5OTuH2kiCcApEEoB0RxRFRNQDDAcyx70BETcklmUTUw1WeI0RUk4hqu9bXBHAFgPVhLCuQ7tIudTEpSoXksccew4QJE9C7d+/CSjmUVK9eHZMnT8bAgQPRp08fNGnSBHXr1vXa795778X06dPRs2dPbN26tdDKGThwIAYPHozExEQkJCTg1VdfBQB89NFH+Pe//41OnTqhV69e2L9/f8jL7gsKpwnjchu9AenmOo2ZXySisQDAzFOIaDyAewDkAcgC8DAzLyWi1hCrARA32KfM/GKg6yUmJnJycnLxCvu3vwFvvglkZelIakUpBps2bUKHDh1KuxilSmZmJmrVqgVmxrhx49CuXTs89NBDpV2sQpy+IyJa4WsYQVjHQbjcRnM91k2xfZ4EYJLDcTsBdA5n2bzYtw9o2lTFQVGUYvPuu+9i+vTpOH36NLp06YK77767tIt0Rmg2V0N6urqXFEU5Ix566KEyZTGcKZpqw7BvnwaoFUVRbKhAGNLTVSAURVFsqEAAEpg+flxdTIqiKDZUIADAdBtTC0JRFKUQFQjAGgOhAqEo5ZJ+/fph3rx5buveeOMN3HvvvX6PMd3ir7rqKhw/ftxrn4kTJxaOR/DFrFmzsHGjlWLumWeewcKFC4tQ+rKLCgSgeZgUpZwzYsQIzJgxw23djBkzfCbM82Tu3LmoV69esa7tKRB///vfcdlllxXrXGUN7eYKaJoNRQkxJZ3t+/rrr8dTTz2FnJwcREVFISUlBenp6ejTpw/uueceJCUlISsrC9dffz2ee+45r+NbtWqF5ORkxMTE4MUXX8SHH36Ili1bolGjRujWrRsAGeMwdepUnD59Gm3btsVHH32E1atXY86cOVi8eDFeeOEFfPXVV3j++edx9dVX4/rrr8ePP/6IRx55BHl5eejevTvefvttREVFoVWrVhg9ejS+/fZb5Obm4osvvkB8fLxbmcpCWnC1IABxMVWpAjRsWNolURSlGDRs2BA9evTADz/8AECsh5tuuglEhBdffBHJyclYu3YtFi9ejLVr1/o8z4oVKzBjxgysWrUKX3/9NZKSkgq3XXvttUhKSsKaNWvQoUMH/Pe//0WvXr0wePBgvPLKK1i9erVbhZydnY3bbrsNn3/+OdatW4e8vDy8/fbbhdtjYmKwcuVK3HPPPY5uLJMWfOXKlfj8888L56WwpwVfs2YNHnvsMQCSFnzcuHFYs2YNli5dimYhaPCqBQFYYyAiVC8VJRSURrZv42YaMmQIZsyYgWnTpgEAZs6cialTpyIvLw/79u3Dxo0b0alTJ8dz/PLLLxg2bFhhyu3BgwcXblu/fj2eeuopHD9+HJmZmRgwYIDf8mzZsgVxcXE455xzAACjR4/GW2+9hQcffBCACA4AdOvWDV9//bXX8WUhLbgKBKCD5BSlAjB06FA8/PDDWLlyJbKystC1a1fs2rULr776KpKSklC/fn3cdtttyM7O9nsez5Tbhttuuw2zZs1C586d8cEHH2DRokV+zxMoz51JGe4rpXhZSAuuTWZAB8kpSgWgVq1a6NevH+64447C4PTJkydRs2ZN1K1bFwcOHMD333/v9xwXX3wxvvnmG2RlZSEjIwPffvtt4baMjAw0a9YMubm5+OSTTwrX165dGxkZGV7nio+PR0pKCrZv3w5AsrL27ds36PspC2nBVSAAsSC0B5OilHtGjBiBNWvWYPjw4QCAzp07o0uXLjj33HNxxx13oHfv3n6PN3NXJyQk4LrrrsNFF11UuO3555/HBRdcgMsvv9wtoDx8+HC88sor6NKlC3bs2FG4Pjo6Gu+//z5uuOEGnH/++YiIiMDYsWODvpeykBY8rOm+S5pipfsuKABGjwYGDABuuSU8BVOUSoCm+y77lKl03+WCiAjgo49KuxSKoihlDnUxKYqiKI6oQCiKEjIqksu6olGc70YFQlGUkBAdHY0jR46oSJRBmBlHjhwp8vgIjUEoihISYmNjkZaWhkOHDpV2URQHoqOjERsbW6RjVCAURQkJVatWRVxcXGkXQwkh6mJSFEVRHFGBUBRFURxRgVAURVEcqVAjqYnoEIDdRTwsBsDhMBQnlJT1Mpb18gFaxlChZQwNZamMZzNzI6cNFUogigMRJfsaZl5WKOtlLOvlA7SMoULLGBrKQxkBdTEpiqIoPlCBUBRFURxRgQCmlnYBgqCsl7Gslw/QMoYKLWNoKA9l1BiEoiiK4oxaEIqiKIojKhCKoiiKI5VWIIhoIBFtIaLtRPR4aZcHAIioJRH9TESbiGgDET3gWt+AiBYQ0TbXe/0yUNZIIlpFRN+VxTISUT0i+pKINrue54VlqYxE9JDrO15PRJ8RUXRZKB8RTSOig0S03rbOZ7mIaILrP7SFiAaUUvlecX3Pa4noGyKqV1rl81VG27ZHiIiJKKY0yxgslVIgiCgSwFsArgTQEcAIIupYuqUCAOQB+CszdwDQE8A4V7keB/AjM7cD8KNrubR5AMAm23JZK+ObAH5g5ngAnSFlLRNlJKIWAO4HkMjM5wGIBDC8jJTvAwADPdY5lsv12xwO4FzXMZNd/62SLt8CAOcxcycAWwFMKMXy+SojiKglgMsB7LGtK60yBkWlFAgAPQBsZ+adzHwawAwAQ0q5TGDmfcy80vU5A1KptYCUbbprt+kAhpZKAV0QUSyAQQDes60uM2UkojoALgbwXwBg5tPMfBxlqIyQTMrViagKgBoA0lEGysfMSwAc9Vjtq1xDAMxg5hxm3gVgO+S/VaLlY+b5zJznWlwGwOS0LvHy+Sqji9cBPAbA3jOoVMoYLJVVIFoASLUtp7nWlRmIqBWALgD+ANCEmfcBIiIAGpdi0QDgDcgPvcC2riyVsTWAQwDed7nB3iOimmWljMy8F8CrkJbkPgAnmHl+WSmfA77KVRb/R3cA+N71ucyUj4gGA9jLzGs8NpWZMjpRWQWCHNaVmf6+RFQLwFcAHmTmk6VdHjtEdDWAg8y8orTL4ocqALoCeJuZuwA4hdJ3eRXi8uEPARAHoDmAmkR0S+mWqliUqf8RET0JcdN+YlY57Fbi5SOiGgCeBPCM02aHdWWmLqqsApEGoKVtORZi4pc6RFQVIg6fMPPXrtUHiKiZa3szAAdLq3wAegMYTEQpENfcpUT0McpWGdMApDHzH67lLyGCUVbKeBmAXcx8iJlzAXwNoFcZKp8nvspVZv5HRDQawNUARrI1uKuslK8NpDGwxvW/iQWwkoiaouyU0ZHKKhBJANoRURwRVYMEieaUcplARATxm29i5tdsm+YAGO36PBrA7JIum4GZJzBzLDO3gjy3n5j5FpStMu4HkEpE7V2r+gPYiLJTxj0AehJRDdd33h8Sbyor5fPEV7nmABhORFFEFAegHYDlJV04IhoI4G8ABjPzn7ZNZaJ8zLyOmRszcyvX/yYNQFfX77RMlNEnzFwpXwCugvR42AHgydIuj6tMfSDm5VoAq12vqwA0hPQe2eZ6b1DaZXWVtx+A71yfy1QZASQASHY9y1kA6pelMgJ4DsBmAOsBfAQgqiyUD8BnkLhILqQiu9NfuSCukx0AtgC4spTKtx3ixzf/mSmlVT5fZfTYngIgpjTLGOxLU20oiqIojlRWF5OiKIoSABUIRVEUxREVCEVRFMURFQhFURTFERUIRVEUxREVCEUpRYion8mIqyhlDRUIRVEUxREVCEUJAiK6hYiWE9FqInrHNR9GJhH9i4hWEtGPRNTItW8CES2zzU9Q37W+LREtJKI1rmPauE5fi6y5Kz5xja4GEb1ERBtd53m1lG5dqcSoQChKAIioA4CbAPRm5gQA+QBGAqgJYCUzdwWwGMCzrkM+BPA3lvkJ1tnWfwLgLWbuDMm9tM+1vguAByFzk7QG0JuIGgAYBuBc13leCOc9KooTKhCKEpj+ALoBSCKi1a7l1pB055+79vkYQB8iqgugHjMvdq2fDuBiIqoNoAUzfwMAzJzNVt6g5cycxswFkFQRrQCcBJAN4D0iuhaAPceQopQIKhCKEhgCMJ2ZE1yv9sw80WE/f3lrnNI6G3Jsn/MBVGGZAKcHJLPvUAA/FK3IinLmqEAoSmB+BHA9ETUGCudoPhvy/7netc/NAH5l5hMAjhHRRa71owAsZpnXI42IhrrOEeWaJ8AR15wgdZl5LsT9lBDyu1KUAFQp7QIoSlmHmTcS0VMA5hNRBCRL5zjIRETnEtEKACcgcQpAUmJPcQnATgC3u9aPAvAOEf3ddY4b/Fy2NoDZRBQNsT4eCvFtKUpANJurohQTIspk5lqlXQ5FCRfqYlIURVEcUQtCURRFcUQtCEVRFMURFQhFURTFERUIRVEUxREVCEVRFMURFQhFURTFkf8HIoVoj8u53K4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info() # test 데이터는 위에서 사용한 변수중 Age와 Fare에 nan값이 존재하는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Test 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data의 Age의 nan값의 개수 : 86\n"
     ]
    }
   ],
   "source": [
    "print('test data의 Age의 nan값의 개수 : {}'.format(test.Age.isna().sum())) # train_data.nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test의 Age의 nan값의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "test['Age']=test[['Age','Pclass']].apply(nanAge,axis=1)\n",
    "\n",
    "print('test의 Age의 nan값의 개수 : {}'.format(test.Age.isna().sum())) # train_data.Age의 nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(test['Fare'].mode()[0], inplace = True) # test 데이터의 Fare값은 1개. 이를 첫번째 데이터와 같다고 보았음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=predata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0 3 1 0]\n",
      " [2 0 1 3 2 0]\n",
      " [3 1 0 2 1 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 3 2 2]\n",
      " [0 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 1 2 2 3]\n",
      " [1 0 0 3 0 0]\n",
      " [1 1 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 1 1 2 4]\n",
      " [3 1 1 2 2 3]\n",
      " [2 0 1 1 2 4]\n",
      " [1 0 1 2 0 3]\n",
      " [2 1 0 2 1 2]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 1 3 2 0]\n",
      " [2 0 0 3 0 0]\n",
      " [3 1 1 1 0 4]\n",
      " [0 1 1 3 2 0]\n",
      " [2 0 0 1 2 3]\n",
      " [1 1 1 1 0 4]\n",
      " [2 0 1 1 0 4]\n",
      " [3 1 1 3 2 2]\n",
      " [1 0 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 1 3 0 3]\n",
      " [3 1 1 2 2 3]\n",
      " [1 1 1 2 2 3]\n",
      " [2 0 1 3 2 2]\n",
      " [1 0 1 3 2 3]\n",
      " [1 1 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 0 3 2 1]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 4]\n",
      " [2 1 1 3 0 2]\n",
      " [2 1 0 1 2 3]\n",
      " [2 1 0 3 2 0]\n",
      " [1 0 0 2 2 2]\n",
      " [2 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 1 0]\n",
      " [3 0 0 1 0 4]\n",
      " [2 0 1 3 2 2]\n",
      " [1 1 1 1 2 4]\n",
      " [1 1 0 2 0 2]\n",
      " [1 0 1 2 2 3]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 2 0 2]\n",
      " [0 1 1 3 1 3]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 3 2 2]\n",
      " [2 0 0 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 1 0]\n",
      " [0 1 1 1 0 4]\n",
      " [1 0 0 2 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [2 1 0 1 2 4]\n",
      " [1 1 0 1 0 3]\n",
      " [3 0 1 1 2 4]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 1 0 3]\n",
      " [2 0 0 1 0 4]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [3 0 1 1 2 3]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [0 1 1 3 0 2]\n",
      " [4 1 1 1 2 4]\n",
      " [3 1 0 1 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 1 1]\n",
      " [1 1 1 3 0 2]\n",
      " [1 0 0 3 1 0]\n",
      " [1 0 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [0 1 1 2 2 3]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [4 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 0 3 2 1]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 1 2 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 3 0 1]\n",
      " [1 1 0 3 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 0 2 0 2]\n",
      " [1 0 0 3 1 0]\n",
      " [2 0 0 1 0 3]\n",
      " [1 0 0 3 1 0]\n",
      " [3 0 1 1 2 4]\n",
      " [1 1 1 3 0 2]\n",
      " [1 1 0 3 0 0]\n",
      " [0 0 1 3 2 2]\n",
      " [2 1 0 1 0 4]\n",
      " [1 0 1 2 2 3]\n",
      " [0 0 0 2 2 2]\n",
      " [1 1 1 3 1 0]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 3 1 3]\n",
      " [2 1 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [3 1 0 1 0 3]\n",
      " [1 0 1 3 2 3]\n",
      " [1 1 1 3 0 0]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 0 3 2 1]\n",
      " [2 1 1 3 2 4]\n",
      " [0 0 1 3 2 4]\n",
      " [2 0 0 1 2 4]\n",
      " [3 1 1 1 0 4]\n",
      " [1 1 0 2 2 3]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 1 3 2 2]\n",
      " [2 1 0 1 2 4]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [1 1 1 2 2 3]\n",
      " [1 0 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [3 1 0 3 2 0]\n",
      " [2 0 1 3 2 2]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 1 2 4]\n",
      " [1 0 0 3 2 0]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 1 3 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [0 1 1 3 0 2]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 1 3 2 3]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 1 3 2 3]\n",
      " [2 0 0 1 0 3]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 1 3 2 2]\n",
      " [1 1 0 3 0 0]\n",
      " [2 1 1 3 2 3]\n",
      " [0 0 1 2 2 3]\n",
      " [1 0 0 2 2 3]\n",
      " [3 1 1 1 0 4]\n",
      " [2 0 1 2 2 3]\n",
      " [3 0 1 1 0 4]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 1 1 0 4]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 1 1 0 4]\n",
      " [2 1 0 2 2 2]\n",
      " [1 0 1 2 2 2]\n",
      " [1 1 1 3 2 1]\n",
      " [1 0 1 3 2 4]\n",
      " [2 1 0 2 2 2]\n",
      " [2 1 1 2 2 3]\n",
      " [2 1 0 1 2 3]\n",
      " [0 1 1 3 2 2]\n",
      " [3 1 0 2 1 2]\n",
      " [0 1 1 2 2 3]\n",
      " [2 1 0 3 2 0]\n",
      " [0 1 1 1 0 4]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 2 2 1]\n",
      " [1 0 0 3 2 1]\n",
      " [1 0 0 3 1 2]\n",
      " [0 1 1 3 2 2]\n",
      " [2 1 1 1 0 4]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [2 1 0 1 0 3]\n",
      " [2 0 0 3 1 0]\n",
      " [1 1 0 2 2 1]\n",
      " [2 0 0 1 0 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 2 4]\n",
      " [3 0 1 2 2 3]\n",
      " [2 0 1 3 2 0]\n",
      " [2 1 0 1 2 4]\n",
      " [1 0 0 3 1 0]\n",
      " [3 1 1 1 2 4]\n",
      " [3 0 1 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 2 0 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [3 0 0 1 0 3]\n",
      " [1 0 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 1 0]\n",
      " [2 1 0 3 2 2]\n",
      " [2 1 0 2 2 2]\n",
      " [0 1 0 2 2 4]\n",
      " [1 0 0 1 2 3]\n",
      " [1 1 1 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [2 1 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 1 1 0 4]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 1 2 2 2]\n",
      " [2 0 1 1 0 4]\n",
      " [3 0 0 1 0 3]\n",
      " [2 0 1 2 2 3]\n",
      " [2 1 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 3 2 3]\n",
      " [2 1 1 1 2 4]\n",
      " [1 0 0 2 2 2]\n",
      " [2 1 1 2 2 3]\n",
      " [1 0 1 2 2 3]\n",
      " [1 0 1 3 0 2]\n",
      " [0 0 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 1 0 4]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 1 3 2 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 1 2 2 3]\n",
      " [0 0 1 3 2 2]\n",
      " [1 1 0 2 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [2 1 0 1 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 0 0 3 2 1]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 1 1 0 4]\n",
      " [1 0 1 3 1 2]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 1 2 2 3]\n",
      " [1 1 0 2 2 1]\n",
      " [2 1 1 2 2 3]\n",
      " [1 1 1 2 2 2]\n",
      " [1 1 0 2 2 1]\n",
      " [1 0 0 3 2 1]\n",
      " [0 1 1 3 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [0 0 1 3 0 2]\n",
      " [0 0 1 3 2 2]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 1 2 4]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 1]\n",
      " [2 1 0 1 2 3]\n",
      " [1 0 0 3 1 0]\n",
      " [1 1 0 3 0 0]\n",
      " [3 1 1 1 2 4]\n",
      " [2 1 0 3 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 2 0 4]\n",
      " [1 1 1 3 0 3]\n",
      " [1 1 0 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 2 0 2]\n",
      " [2 1 1 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 0 3 1 0]\n",
      " [3 0 1 1 2 3]\n",
      " [1 1 1 1 2 4]\n",
      " [0 1 1 3 2 1]\n",
      " [3 1 1 1 2 4]\n",
      " [2 0 1 3 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 3 2 0]\n",
      " [2 0 0 3 1 0]\n",
      " [3 0 0 1 0 4]\n",
      " [1 0 0 3 1 0]\n",
      " [3 1 1 1 0 4]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 2 2 3]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 0 1 2 3]\n",
      " [2 0 0 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [0 0 1 2 2 3]\n",
      " [2 1 0 1 0 4]\n",
      " [1 1 1 2 2 3]\n",
      " [1 1 0 2 2 2]\n",
      " [2 0 1 2 2 3]\n",
      " [2 1 0 1 0 3]\n",
      " [1 1 0 3 0 0]\n",
      " [1 0 1 3 0 2]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 1 2 3]\n",
      " [1 1 0 2 2 2]\n",
      " [2 1 1 3 0 0]\n",
      " [1 1 0 2 2 3]\n",
      " [1 1 0 3 0 0]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 1 3 2 4]\n",
      " [3 0 1 1 0 4]\n",
      " [1 1 1 3 2 2]\n",
      " [0 0 0 3 2 0]\n",
      " [1 1 0 2 2 2]\n",
      " [2 0 0 3 0 0]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 0 2 2 2]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 2 2 1]\n",
      " [1 1 0 2 2 4]\n",
      " [3 1 1 2 2 4]\n",
      " [0 0 1 3 2 2]\n",
      " [3 1 0 1 2 3]\n",
      " [3 0 1 1 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 1 3 2 2]\n",
      " [0 1 1 3 2 4]\n",
      " [1 0 1 2 0 3]\n",
      " [1 0 0 2 2 2]\n",
      " [1 1 0 3 2 1]\n",
      " [1 0 1 1 0 4]\n",
      " [1 0 1 3 2 4]\n",
      " [1 1 1 3 0 2]\n",
      " [1 0 0 3 2 3]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 2 0 2]\n",
      " [1 1 1 2 2 2]\n",
      " [1 0 0 1 0 4]\n",
      " [3 1 0 1 2 0]\n",
      " [2 1 0 2 2 2]\n",
      " [3 0 1 1 2 4]\n",
      " [2 0 0 1 0 4]\n",
      " [1 0 1 3 2 1]\n",
      " [1 1 0 2 2 2]\n",
      " [3 1 0 1 2 4]\n",
      " [0 1 1 3 2 3]\n",
      " [1 1 0 3 1 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 0 3 2 2]\n",
      " [1 0 1 3 2 2]\n",
      " [1 1 0 2 2 2]\n",
      " [1 0 1 2 2 4]\n",
      " [1 1 0 3 2 0]\n",
      " [3 1 0 2 2 2]\n",
      " [1 1 0 3 1 0]\n",
      " [0 1 1 3 2 2]\n",
      " [1 1 0 1 2 4]\n",
      " [3 0 1 1 2 3]\n",
      " [0 1 1 3 2 2]\n",
      " [2 1 0 2 2 1]\n",
      " [1 1 1 3 2 3]\n",
      " [1 0 1 1 2 4]\n",
      " [1 1 0 3 1 0]\n",
      " [2 0 1 1 0 4]\n",
      " [1 1 0 3 2 0]\n",
      " [1 1 0 3 1 0]\n",
      " [1 0 0 1 2 4]\n",
      " [2 1 1 2 2 2]\n",
      " [1 0 1 1 0 4]\n",
      " [1 1 0 1 2 4]\n",
      " [2 1 1 1 0 3]\n",
      " [1 1 0 2 0 2]\n",
      " [1 1 1 2 2 1]\n",
      " [3 1 1 1 0 4]\n",
      " [1 0 0 3 1 0]\n",
      " [0 0 1 3 2 2]\n",
      " [1 0 0 3 1 0]\n",
      " [2 0 1 1 1 4]\n",
      " [1 0 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [2 0 0 1 0 4]\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(X_t) # test를 진행한 test 데이터를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 23:05:58.437091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(X_t) # model에 이 test data를 집어넣어 Survived or dead를 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=(predict>0.5).astype(int).ravel() # sigmoid는 0또는 1을 출력하는 것이 아니기 때문에 반올림을 해주어야 함 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=predict.tolist() # array로 진행을 하였기 때문에 이를 list로 변환 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict  # Survived or Dead를 1차원 list로 출력하는것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=pd.DataFrame({\"PassengerID\":test.PassengerId,\"Survived\":predict}) \n",
    "submit.to_csv(\"final_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/  # bias-variance decomposition에 대한 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network(nn)을 택한 이유는 epoch, batch_size, optimizer, regulation, kernal_initializer을 계속해서 바꾸어주면서 train을 진행해 볼 수 있기 때문이었다.\n",
    "sklearn을 활용하여 decision tree, SVC, perceptron, K-Means 등 많은 분류 문제 풀이 방법을 활용하여 간단하게 모델을 구현 할 수 있지만, nn의 구조와 파라미터들의 변화 양상을 알 수 없기 때문에 nn을 활용하기위해 pytorch와 tensorflow중 고민하다 pytorch는 익숙하지 않아 tensorflow를 채택하여 사용하였다.\n",
    "\n",
    "이 타이타닉 데이터를 이용한 Survived or Dead 문제를 풀기 위해선 데이터 전처리과정과 모델을 구현하는데 있어서 많은 시행착오가 필요하였다. 같은 전처리과정을 Dropout과 같은 것을 추가만 하여도 정확도가 크게 바뀌었고, 모델의 acc와 loss가 아무리 잘 나왔다 치더라도, kaggle에 제출하였을 땐 스코어가 낮은 경우도 허다하였기 때문에 어떤 데이터가 연관이 있을지 없을지를 생각하고, 모델을 최대한 다양한 방법으로 구현해야만 했다. 또한 optimizer도 SGD를 이용했을때와 Adam을 이용했을 때 loss가 떨어지는게 전혀 달랐고, optimizer의 learning_rate를 조절하여 최적의 조건을 찾는것도 쉽지 않았다. \n",
    "\n",
    "모델을 아주 작고 간단하게 구성하였을 때 train이 아주 잘되었는데, hidden layer을 증가하면 할수록 모델의 variance가 증가하여 validation loss와 acc가 계속해서 진동하는 현상이 발생하였는데, 이를 해결해 가면서 모델을 구현해 보고 싶어 hidden layer의 크기를 계속해서 늘려가면서 relu를 넣어 모델을 크게 만드는 대신 weight decay를 줘 모델을 스무딩 시켜주는 방법으로 진행하였다. 모델의 크기를 키울수록 kaggle의 score도 증가함을 확인하였다.\n",
    "\n",
    "데이터 전처리 과정에서 Cabin, Name, Ticket는 아에 이 문제에서 필요하지 않다고 판단하고 제거하였지만, kaggle에 있는 스코어가 높은 코드들은 이들까지 포함하여 트레인을 한 경우도 있었다. 또한 각각의 데이터를 분류하는것이 아닌 Age-Sex, Age-Pclass, Fare-Pclass 등 두 가지 이상의 데이터를 묶어서 관계성을 따지는 방법도 꽤 많이 존재하였다.\n",
    "\n",
    "지금 만든 데이터 전처리에서 Sex, Pclass, Embarked 등은 one-hot encoding을 통해 데이터를 더 세부적으로 나눈 후 모델을 차라리 hidden layer을 축소시키는 과정으로 정확도를 더 높일 수 있을거라고 생각된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac5ba461e022a46822591661efbc09da50068d8326506c82c6f426d61e442761"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
