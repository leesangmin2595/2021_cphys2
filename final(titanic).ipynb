{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#np.set_printoptions(threshold=np.inf,linewidth=np.inf) # numpy array를 생략하지않고 전체 출력\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/leesangmin/Desktop/a/train.csv')\n",
    "test=pd.read_csv('/Users/leesangmin/Desktop/a/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info() # 데이터의 NAN 개수를 확인 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 Age의 nan값의 개수 : 177\n"
     ]
    }
   ],
   "source": [
    "print('train data의 Age의 nan값의 개수 : {}'.format(train_data.Age.isna().sum())) # train_data.nan 값의 개수를 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Age'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='Pclass',y='Age',data=train_data) # Pclass에 따른 나이를 그래프로 확인, 나이의 nan값을 채워주기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-1. Age를 처리하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Age가 nan 값인 데이터를 채워주는 과정. 위의 Pclass와 Age와의 관계 그래프를 통해 집어넣어줌\n",
    "def nanAge(data): \n",
    "    \n",
    "    if np.isnan(data.Age):\n",
    "\n",
    "        if data.Pclass==1:\n",
    "            return 36\n",
    "        \n",
    "        elif data.Pclass==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 25\n",
    "\n",
    "    else:\n",
    "        return data.Age\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 Age의 nan값의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "train_data['Age']=train_data[['Age','Pclass']].apply(nanAge,axis=1) # Age의 nan값을 넣어줌\n",
    "\n",
    "print('train data의 Age의 nan값의 개수 : {}'.format(train_data.Age.isna().sum())) # train_data.Age의 nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info() # train_data의 Age에 nan값이 없음을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-2. train data Embarked를 처리  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train_data의 Embarked에도 두개의 nan값이 있음.데이터가 2개뿐이니 Embarked의 첫번째 값과 같다고 놓았음(S와 같아짐)\n",
    "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace = True) \n",
    "\n",
    "\n",
    "max(train_data['Age']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.854, 10.5]        184\n",
       "(21.679, 39.688]     180\n",
       "(-0.001, 7.854]      179\n",
       "(39.688, 512.329]    176\n",
       "(10.5, 21.679]       172\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fare을 5구간으로 나누기 위해 구간을 확\n",
    "pd.qcut(train_data['Fare'],5).value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-3. 사용할 변수들을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas의 각 열을 제거해서 data로 활용하여도 되지만, numpy array형태로 바꿔주었음. Survived or dead를 분석하기위해 Pclass, Sex, Age, Embarked, Fare, SibSp, Parch를 사용\n",
    "def predata(data):\n",
    "    sex=[]\n",
    "    embark=[]\n",
    "    age=[]\n",
    "    family=[]\n",
    "    fare=[]\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.Sex[i]=='male': # Sex는 문자열 데이터이므로, 정수형 숫자로 변경을해줌\n",
    "            a=1\n",
    "        else:\n",
    "            a=0\n",
    "\n",
    "        if data.Age[i]<=16: # 나이를 5등분을 함. train_data의 Age의 데이터의 최대값이 80이므로, 이를 5등분함\n",
    "            b=0\n",
    "        \n",
    "        elif data.Age[i]<=32: # 나이의 데이터는 0~80까지 넓은 분포를 가지기 때문에 구간을 나누어서 해야만 했음\n",
    "            b=1\n",
    "        \n",
    "        elif data.Age[i]<=48:\n",
    "            b=2\n",
    "        elif data.Age[i]<=64:\n",
    "            b=3\n",
    "        else:\n",
    "            b=4\n",
    "\n",
    "            \n",
    "        if data.Embarked[i]==\"C\": # Embarked는 총 3개의 문자열로 되어있음. 이를 정수형 숫자로 변경\n",
    "            c=0\n",
    "        elif data.Embarked[i]==\"Q\":\n",
    "            c=1\n",
    "        else:\n",
    "            c=2\n",
    "\n",
    "\n",
    "        if data.SibSp[i]+data.Parch[i]+1 ==1: # SibSp는 동반한 형제/자매/배우자를 의미. Parch는 동반한 부모/자식 수 이므로 둘을 합쳐 가족으로함. 혼자 온 사람과 안온사람의 구분을 지음\n",
    "            d=0\n",
    "        else:\n",
    "            d=1\n",
    "\n",
    "        if data.Fare[i]<=8: # Fare은 요금으로,5구간으로 나눠주었음\n",
    "            e=0\n",
    "        elif data.Fare[i]<=11:\n",
    "            e=1\n",
    "        elif data.Fare[i]<=21.2:\n",
    "            e=2\n",
    "        elif data.Fare[i]<=40:\n",
    "            e=3\n",
    "        else:\n",
    "            e=4\n",
    "\n",
    "        ## 빈 list에 값들을  채워넣음\n",
    "        sex.append(a)\n",
    "        age.append(b)\n",
    "        embark.append(c)\n",
    "        family.append(d)\n",
    "        fare.append(e)\n",
    "\n",
    "    ## 사용할 변수들을 추출하여 한 열의 array로 변경해주는 과정 \n",
    "    family=np.array(family).reshape(-1,1)\n",
    "    sex=np.array(sex).reshape(-1,1)\n",
    "    fare=np.array(fare).reshape(-1,1)\n",
    "    pclass=np.array(data.Pclass).reshape(-1,1) # Pclass는 변경하지않아도 정수형데이터로 총 3개 존재하기 때문에 if문을 사용하지 않음\n",
    "    age=np.array(age).reshape(-1,1)\n",
    "    embark=np.array(embark).reshape(-1,1)\n",
    "\n",
    "    ## 사용할 변수들을 모두 하나의 열로 추출하였으니 이를 하나의 array로 합치는 과정\n",
    "    X=np.concatenate((age,sex,family,pclass,embark,fare),axis=1) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 3 2 0]\n",
      " [2 0 1 1 0 4]\n",
      " [1 0 0 3 2 0]\n",
      " ...\n",
      " [1 0 1 3 2 3]\n",
      " [1 1 0 1 0 3]\n",
      " [1 1 0 3 1 0]]\n"
     ]
    }
   ],
   "source": [
    "## X는 위의 predata 함수로 추출한 사용할 변수들을 array로 추출한것, y는 target으로 Survived or Dead를 의미 \n",
    "X=predata(train_data)\n",
    "y=np.array(train_data.Survived).reshape(-1,1)\n",
    "\n",
    "print(X) # 각 열이 x_n으로 neural network를 만들기 위함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model(input=6, output=1,) Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:07:44.540033: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-21 15:07:44.540597: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 617,153\n",
      "Trainable params: 615,153\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epoch=150\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 32, input_shape = (6,), activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer = 'he_normal')) # kernal_initializer은 weight를 초기화하는방법. 그중 he_normal을 택함\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization()) # 학습 과정을 안정화 시키기 위하여 BatchNormalization을 진행\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 256, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 512, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 512, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 256, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2)) # overfitting이 많이 일어나므로, Dropout을 여러층을 이용하였음\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 16, activation = 'relu',kernel_regularizer=tf.keras.regularizers.L2(0.01))) # L2 regulation을 사용함\n",
    "model.add(tf.keras.layers.Dense(units = 8, activation = 'relu',kernel_initializer = 'he_normal'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units =1 , activation = 'sigmoid')) # 0과 1을 분류하는 문제와 같으므로(Survived or Dead) sigmoid를 이용하여 분류함\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss and Optimizer (loss= binary CE , optimizer= SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0-1을 분류하는것이므로 binary_CE를 loss function으로 이용, optimizer은 Adam,SGD를 learning_rate를 바꾸어가며 설정 할 수도 있음\n",
    "model.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train (validation=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:07:45.032150: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-21 15:07:45.035435: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-21 15:07:45.667799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.1262 - accuracy: 0.5393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:07:47.822491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 76ms/step - loss: 1.1262 - accuracy: 0.5393 - val_loss: 1.4046 - val_accuracy: 0.3464\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.9856 - accuracy: 0.6011 - val_loss: 1.0071 - val_accuracy: 0.5475\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.9469 - accuracy: 0.6320 - val_loss: 0.9966 - val_accuracy: 0.4581\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.9131 - accuracy: 0.6067 - val_loss: 0.8229 - val_accuracy: 0.6648\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.8643 - accuracy: 0.6447 - val_loss: 0.8361 - val_accuracy: 0.6983\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.8408 - accuracy: 0.6699 - val_loss: 0.7961 - val_accuracy: 0.7095\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.8653 - accuracy: 0.6756 - val_loss: 0.8293 - val_accuracy: 0.6648\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.7826 - accuracy: 0.7149 - val_loss: 0.8194 - val_accuracy: 0.6704\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.8022 - accuracy: 0.6854 - val_loss: 0.7593 - val_accuracy: 0.6983\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.8114 - accuracy: 0.6924 - val_loss: 0.8206 - val_accuracy: 0.6648\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.7848 - accuracy: 0.6952 - val_loss: 0.7383 - val_accuracy: 0.7374\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.7687 - accuracy: 0.7051 - val_loss: 0.7280 - val_accuracy: 0.7263\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.7871 - accuracy: 0.7191 - val_loss: 0.7105 - val_accuracy: 0.7598\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7357 - accuracy: 0.7289 - val_loss: 0.7051 - val_accuracy: 0.7263\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7685 - accuracy: 0.7121 - val_loss: 0.6535 - val_accuracy: 0.7765\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7669 - accuracy: 0.7275 - val_loss: 0.6028 - val_accuracy: 0.8156\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.7530 - accuracy: 0.7374 - val_loss: 0.6082 - val_accuracy: 0.8101\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.7366 - accuracy: 0.7388 - val_loss: 0.6187 - val_accuracy: 0.8045\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.7147 - accuracy: 0.7458 - val_loss: 0.6418 - val_accuracy: 0.8045\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7228 - accuracy: 0.7444 - val_loss: 0.6099 - val_accuracy: 0.8212\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.7032 - accuracy: 0.7528 - val_loss: 0.6093 - val_accuracy: 0.8101\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.7272 - accuracy: 0.7556 - val_loss: 0.6030 - val_accuracy: 0.8156\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6929 - accuracy: 0.7612 - val_loss: 0.5914 - val_accuracy: 0.8380\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.6845 - accuracy: 0.7767 - val_loss: 0.5794 - val_accuracy: 0.8324\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.7079 - accuracy: 0.7626 - val_loss: 0.5774 - val_accuracy: 0.8324\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6782 - accuracy: 0.7612 - val_loss: 0.5759 - val_accuracy: 0.8324\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6796 - accuracy: 0.7795 - val_loss: 0.6003 - val_accuracy: 0.8101\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6969 - accuracy: 0.7612 - val_loss: 0.5804 - val_accuracy: 0.8212\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6858 - accuracy: 0.7739 - val_loss: 0.5713 - val_accuracy: 0.8156\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6711 - accuracy: 0.7767 - val_loss: 0.5778 - val_accuracy: 0.8045\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6543 - accuracy: 0.7753 - val_loss: 0.5882 - val_accuracy: 0.8101\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6493 - accuracy: 0.7921 - val_loss: 0.5843 - val_accuracy: 0.8212\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6747 - accuracy: 0.7626 - val_loss: 0.5725 - val_accuracy: 0.8324\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6465 - accuracy: 0.7907 - val_loss: 0.5681 - val_accuracy: 0.8324\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6780 - accuracy: 0.7781 - val_loss: 0.5729 - val_accuracy: 0.8212\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6581 - accuracy: 0.7809 - val_loss: 0.5790 - val_accuracy: 0.8101\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.6504 - accuracy: 0.7851 - val_loss: 0.5820 - val_accuracy: 0.8101\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.6430 - accuracy: 0.7781 - val_loss: 0.5721 - val_accuracy: 0.7989\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6177 - accuracy: 0.8034 - val_loss: 0.5693 - val_accuracy: 0.8156\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.6451 - accuracy: 0.7893 - val_loss: 0.5616 - val_accuracy: 0.8324\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6268 - accuracy: 0.7907 - val_loss: 0.5714 - val_accuracy: 0.8212\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.6512 - accuracy: 0.7851 - val_loss: 0.5813 - val_accuracy: 0.7989\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6635 - accuracy: 0.7781 - val_loss: 0.5929 - val_accuracy: 0.7933\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.6512 - accuracy: 0.7865 - val_loss: 0.5676 - val_accuracy: 0.8101\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.6224 - accuracy: 0.7978 - val_loss: 0.5621 - val_accuracy: 0.8101\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6492 - accuracy: 0.7669 - val_loss: 0.5613 - val_accuracy: 0.8156\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.6404 - accuracy: 0.7767 - val_loss: 0.7053 - val_accuracy: 0.7095\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6253 - accuracy: 0.7893 - val_loss: 0.6708 - val_accuracy: 0.7207\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.6255 - accuracy: 0.7809 - val_loss: 0.5871 - val_accuracy: 0.7821\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6293 - accuracy: 0.7893 - val_loss: 0.5603 - val_accuracy: 0.8156\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.6210 - accuracy: 0.7753 - val_loss: 0.5622 - val_accuracy: 0.8045\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6041 - accuracy: 0.8132 - val_loss: 0.5523 - val_accuracy: 0.8156\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6095 - accuracy: 0.7893 - val_loss: 0.5499 - val_accuracy: 0.8212\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6199 - accuracy: 0.7978 - val_loss: 0.5615 - val_accuracy: 0.8045\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.6009 - accuracy: 0.8104 - val_loss: 0.5432 - val_accuracy: 0.8156\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6267 - accuracy: 0.7879 - val_loss: 0.5333 - val_accuracy: 0.8212\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6202 - accuracy: 0.7921 - val_loss: 0.5394 - val_accuracy: 0.8268\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6123 - accuracy: 0.7795 - val_loss: 0.5389 - val_accuracy: 0.8268\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5983 - accuracy: 0.8006 - val_loss: 0.5456 - val_accuracy: 0.8156\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5877 - accuracy: 0.8062 - val_loss: 0.5454 - val_accuracy: 0.8156\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6052 - accuracy: 0.7879 - val_loss: 0.5380 - val_accuracy: 0.8268\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6090 - accuracy: 0.8006 - val_loss: 0.5295 - val_accuracy: 0.8268\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5857 - accuracy: 0.8132 - val_loss: 0.5238 - val_accuracy: 0.8324\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5963 - accuracy: 0.7963 - val_loss: 0.5234 - val_accuracy: 0.8268\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.6016 - accuracy: 0.7935 - val_loss: 0.5276 - val_accuracy: 0.8268\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5781 - accuracy: 0.8174 - val_loss: 0.5277 - val_accuracy: 0.8156\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5709 - accuracy: 0.8132 - val_loss: 0.5478 - val_accuracy: 0.8101\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5668 - accuracy: 0.8006 - val_loss: 0.5395 - val_accuracy: 0.8045\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 1s 50ms/step - loss: 0.5749 - accuracy: 0.7921 - val_loss: 0.5327 - val_accuracy: 0.8324\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5883 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.8101\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6122 - accuracy: 0.7809 - val_loss: 0.5156 - val_accuracy: 0.8101\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6019 - accuracy: 0.7697 - val_loss: 0.5200 - val_accuracy: 0.8101\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.5848 - accuracy: 0.8188 - val_loss: 0.5249 - val_accuracy: 0.8156\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5579 - accuracy: 0.8160 - val_loss: 0.5077 - val_accuracy: 0.8156\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5557 - accuracy: 0.8118 - val_loss: 0.5179 - val_accuracy: 0.8156\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5706 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.8156\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5962 - accuracy: 0.7907 - val_loss: 0.5177 - val_accuracy: 0.8156\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5675 - accuracy: 0.7949 - val_loss: 0.5121 - val_accuracy: 0.8101\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.5822 - accuracy: 0.7949 - val_loss: 0.5076 - val_accuracy: 0.8380\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5689 - accuracy: 0.7963 - val_loss: 0.5158 - val_accuracy: 0.8212\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5661 - accuracy: 0.7992 - val_loss: 0.5099 - val_accuracy: 0.8212\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5785 - accuracy: 0.7978 - val_loss: 0.5055 - val_accuracy: 0.8268\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5665 - accuracy: 0.8020 - val_loss: 0.5019 - val_accuracy: 0.8268\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5488 - accuracy: 0.8076 - val_loss: 0.5062 - val_accuracy: 0.8268\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5578 - accuracy: 0.8020 - val_loss: 0.4981 - val_accuracy: 0.8268\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5639 - accuracy: 0.8118 - val_loss: 0.5007 - val_accuracy: 0.8268\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5501 - accuracy: 0.8062 - val_loss: 0.4924 - val_accuracy: 0.8380\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5607 - accuracy: 0.7921 - val_loss: 0.4875 - val_accuracy: 0.8380\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5592 - accuracy: 0.7992 - val_loss: 0.4844 - val_accuracy: 0.8380\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5731 - accuracy: 0.8034 - val_loss: 0.4882 - val_accuracy: 0.8436\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5843 - accuracy: 0.7879 - val_loss: 0.4873 - val_accuracy: 0.8436\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5461 - accuracy: 0.8174 - val_loss: 0.4964 - val_accuracy: 0.8380\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5416 - accuracy: 0.8160 - val_loss: 0.5063 - val_accuracy: 0.8324\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5543 - accuracy: 0.8034 - val_loss: 0.4961 - val_accuracy: 0.8268\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5485 - accuracy: 0.8132 - val_loss: 0.4926 - val_accuracy: 0.8156\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5374 - accuracy: 0.8146 - val_loss: 0.4874 - val_accuracy: 0.8212\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.5573 - accuracy: 0.7963 - val_loss: 0.4906 - val_accuracy: 0.8212\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5379 - accuracy: 0.8160 - val_loss: 0.4951 - val_accuracy: 0.8212\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5726 - accuracy: 0.7963 - val_loss: 0.5006 - val_accuracy: 0.8212\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5377 - accuracy: 0.8020 - val_loss: 0.4938 - val_accuracy: 0.8212\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5463 - accuracy: 0.8118 - val_loss: 0.4908 - val_accuracy: 0.8212\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5298 - accuracy: 0.8062 - val_loss: 0.4928 - val_accuracy: 0.8212\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5383 - accuracy: 0.7907 - val_loss: 0.4949 - val_accuracy: 0.8212\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5269 - accuracy: 0.8315 - val_loss: 0.5004 - val_accuracy: 0.8156\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5472 - accuracy: 0.8076 - val_loss: 0.4890 - val_accuracy: 0.8212\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5442 - accuracy: 0.8048 - val_loss: 0.4877 - val_accuracy: 0.8268\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5505 - accuracy: 0.7949 - val_loss: 0.4814 - val_accuracy: 0.8268\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5434 - accuracy: 0.8034 - val_loss: 0.4767 - val_accuracy: 0.8268\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5272 - accuracy: 0.8160 - val_loss: 0.4788 - val_accuracy: 0.8212\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5193 - accuracy: 0.8132 - val_loss: 0.4667 - val_accuracy: 0.8268\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5228 - accuracy: 0.8118 - val_loss: 0.4710 - val_accuracy: 0.8268\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5236 - accuracy: 0.8174 - val_loss: 0.4723 - val_accuracy: 0.8268\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5376 - accuracy: 0.8076 - val_loss: 0.4850 - val_accuracy: 0.8212\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5535 - accuracy: 0.8034 - val_loss: 0.4810 - val_accuracy: 0.8156\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.5194 - accuracy: 0.8132 - val_loss: 0.4855 - val_accuracy: 0.8268\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5228 - accuracy: 0.8174 - val_loss: 0.4837 - val_accuracy: 0.8268\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5284 - accuracy: 0.8048 - val_loss: 0.4877 - val_accuracy: 0.8268\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5304 - accuracy: 0.8160 - val_loss: 0.4780 - val_accuracy: 0.8324\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5195 - accuracy: 0.8272 - val_loss: 0.4841 - val_accuracy: 0.8268\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5247 - accuracy: 0.7949 - val_loss: 0.4759 - val_accuracy: 0.8324\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.4960 - accuracy: 0.8230 - val_loss: 0.4721 - val_accuracy: 0.8212\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5294 - accuracy: 0.8006 - val_loss: 0.4794 - val_accuracy: 0.8268\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5229 - accuracy: 0.8160 - val_loss: 0.4799 - val_accuracy: 0.8324\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5067 - accuracy: 0.8104 - val_loss: 0.4767 - val_accuracy: 0.8268\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.5383 - accuracy: 0.8090 - val_loss: 0.4708 - val_accuracy: 0.8268\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5063 - accuracy: 0.8132 - val_loss: 0.4716 - val_accuracy: 0.8324\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.4977 - accuracy: 0.8090 - val_loss: 0.4677 - val_accuracy: 0.8324\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.4925 - accuracy: 0.8160 - val_loss: 0.4702 - val_accuracy: 0.8268\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5265 - accuracy: 0.8104 - val_loss: 0.4850 - val_accuracy: 0.8212\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.5059 - accuracy: 0.8160 - val_loss: 0.4795 - val_accuracy: 0.8324\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5072 - accuracy: 0.8076 - val_loss: 0.4836 - val_accuracy: 0.8324\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5108 - accuracy: 0.8230 - val_loss: 0.4823 - val_accuracy: 0.8212\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5117 - accuracy: 0.8188 - val_loss: 0.4944 - val_accuracy: 0.8156\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.4906 - accuracy: 0.8048 - val_loss: 0.4762 - val_accuracy: 0.8212\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5016 - accuracy: 0.8132 - val_loss: 0.4658 - val_accuracy: 0.8212\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5035 - accuracy: 0.8104 - val_loss: 0.4639 - val_accuracy: 0.8268\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5272 - accuracy: 0.8062 - val_loss: 0.4750 - val_accuracy: 0.8268\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5129 - accuracy: 0.8076 - val_loss: 0.4641 - val_accuracy: 0.8212\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5046 - accuracy: 0.8062 - val_loss: 0.4597 - val_accuracy: 0.8268\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5095 - accuracy: 0.8062 - val_loss: 0.4602 - val_accuracy: 0.8212\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 0.4921 - accuracy: 0.8118 - val_loss: 0.4557 - val_accuracy: 0.8268\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5088 - accuracy: 0.8118 - val_loss: 0.4606 - val_accuracy: 0.8212\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.4997 - accuracy: 0.8188 - val_loss: 0.4681 - val_accuracy: 0.8268\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5036 - accuracy: 0.8244 - val_loss: 0.4626 - val_accuracy: 0.8268\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 0.5059 - accuracy: 0.8132 - val_loss: 0.4630 - val_accuracy: 0.8212\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.4938 - accuracy: 0.8188 - val_loss: 0.4668 - val_accuracy: 0.8380\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5058 - accuracy: 0.8104 - val_loss: 0.4651 - val_accuracy: 0.8268\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5042 - accuracy: 0.8034 - val_loss: 0.4742 - val_accuracy: 0.8268\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.4916 - accuracy: 0.8230 - val_loss: 0.4747 - val_accuracy: 0.8324\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4899 - accuracy: 0.8160 - val_loss: 0.4528 - val_accuracy: 0.8268\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=epoch,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train 한 결과중 정확도, 손실을 출력 \n",
    "acc = history.history['accuracy'] \n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2894057f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=np.arange(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Acc plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x162a34e20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info() # test 데이터는 위에서 사용한 변수중 Age와 Fare에 nan값이 존재하는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Test 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data의 Age의 nan값의 개수 : 86\n"
     ]
    }
   ],
   "source": [
    "print('test data의 Age의 nan값의 개수 : {}'.format(test.Age.isna().sum())) # train_data.nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test의 Age의 nan값의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "test['Age']=test[['Age','Pclass']].apply(nanAge,axis=1)\n",
    "\n",
    "print('test의 Age의 nan값의 개수 : {}'.format(test.Age.isna().sum())) # train_data.Age의 nan 값의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(test['Fare'].mode()[0], inplace = True) # test 데이터의 Fare값은 1개. 이를 첫번째 데이터와 같다고 보았음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=predata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0 3 1 0]\n",
      " [2 0 1 3 2 0]\n",
      " [3 1 0 2 1 1]\n",
      " ...\n",
      " [2 1 0 3 2 0]\n",
      " [1 1 0 3 2 1]\n",
      " [1 1 1 3 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(X_t) # test를 진행한 test 데이터를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:11:06.657816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(X_t) # model에 이 test data를 집어넣어 Survived or dead를 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=(predict>0.5).astype(int).ravel() # sigmoid는 0또는 1을 출력하는 것이 아니기 때문에 반올림을 해주어야 함 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=predict.tolist() # array로 진행을 하였기 때문에 이를 list로 변환 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict  # Survived or Dead를 1차원 list로 출력하는것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=pd.DataFrame({\"PassengerID\":test.PassengerId,\"Survived\":predict}) \n",
    "submit.to_csv(\"final_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/  # bias-variance decomposition에 대한 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network(nn)을 택한 이유는 epoch, batch_size, optimizer, regulation, kernal_initializer을 계속해서 바꾸어주면서 train을 진행해 볼 수 있기 때문이었다.\n",
    "sklearn을 활용하여 decision tree, SVC, perceptron, K-Means 등 많은 분류 문제 풀이 방법을 활용하여 간단하게 모델을 구현 할 수 있지만, nn의 구조와 파라미터들의 변화 양상을 알 수 없기 때문에 nn을 활용하기위해 pytorch와 tensorflow중 고민하다 pytorch는 익숙하지 않아 tensorflow를 채택하여 사용하였다.\n",
    "\n",
    "이 타이타닉 데이터를 이용한 Survived or Dead 문제를 풀기 위해선 데이터 전처리과정과 모델을 구현하는데 있어서 많은 시행착오가 필요하였다. 같은 전처리과정을 Dropout과 같은 것을 추가만 하여도 정확도가 크게 바뀌었고, 모델의 acc와 loss가 아무리 잘 나왔다 치더라도, kaggle에 제출하였을 땐 스코어가 낮은 경우도 허다하였기 때문에 어떤 데이터가 연관이 있을지 없을지를 생각하고, 모델을 최대한 다양한 방법으로 구현해야만 했다. 또한 optimizer도 SGD를 이용했을때와 Adam을 이용했을 때 loss가 떨어지는게 전혀 달랐고, optimizer의 learning_rate를 조절하여 최적의 조건을 찾는것도 쉽지 않았다. \n",
    "\n",
    "모델을 아주 작고 간단하게 구성하였을 때 train이 아주 잘되었는데, hidden layer을 증가하면 할수록 모델의 variance가 증가하여 validation loss와 acc가 계속해서 진동하는 현상이 발생하였는데, 이를 해결해 가면서 모델을 구현해 보고 싶어 hidden layer의 크기를 계속해서 늘려가면서 relu를 넣어 모델을 크게 만드는 대신 weight decay를 줘 모델을 스무딩 시켜주는 방법으로 진행하였다. 모델의 크기를 키울수록 kaggle의 score도 증가함을 확인하였다.\n",
    "\n",
    "데이터 전처리 과정에서 Cabin, Name, Ticket는 아에 이 문제에서 필요하지 않다고 판단하고 제거하였지만, kaggle에 있는 스코어가 높은 코드들은 이들까지 포함하여 트레인을 한 경우도 있었다. 또한 각각의 데이터를 분류하는것이 아닌 Age-Sex, Age-Pclass, Fare-Pclass 등 두 가지 이상의 데이터를 묶어서 관계성을 따지는 방법도 꽤 많이 존재하였다.\n",
    "\n",
    "지금 만든 데이터 전처리에서 Sex, Pclass, Embarked 등은 one-hot encoding을 통해 데이터를 더 세부적으로 나눈 후 모델을 차라리 hidden layer을 축소시키는 과정으로 정확도를 더 높일 수 있을거라고 생각된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac5ba461e022a46822591661efbc09da50068d8326506c82c6f426d61e442761"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
